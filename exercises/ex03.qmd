---
title: "Exercise 3: inference on continuous spaces"
editor: 
  mode: source
---
  
{{< include ../_macros.qmd >}}

## Goals

- Introduce Monte Carlo integration in continuous spaces.
- Review the concept of importance sampling.


## TODO

- 1 - continuous MC on bounded space and uniform proposal✅
- 2 - continuous IS on unbounded space and e.g. exponential proposal✅
	-> bonus: something about 100x more samples needed for 1 more digits using log-log plot (maybe done in class instead?)
	-> bonus/challenge question? or maybe in class instead?: questions on ESS?
	-> bonus? an example where the expectation does not converge due to non-integrability
- 3 - guided steps to universal PPL (providing scaffold code)
	- test case: discrete model from last time (e.g. one for parameters posterior)
	- extending to cover predictive?
	- model with two variables? (can wait until regression)
	

## Q.1: functions on the unit interval

1. Write a function `mc_estimate` that takes a function $f:[0,1]\to\reals$ and 
outputs a Monte Carlo estimate of $\int_0^1 f(x)\dee x$ using $n=10000$ 
independent samples from $\distUnif(0,1)$.

2. Consider the function $f:[0,1]\to[0,\infty)$ given by
$$
f(x) = \frac{x^{-1/3}}{\sqrt{1-x}}.
$$
Show that
$$
\int_0^1 f(x)\dee x = \frac{\pi}{\sin\left(\frac{\pi}{3}\right)}.
$${#eq-integral}
Hint: look at the expression for the 
[density](https://en.wikipedia.org/wiki/Beta_distribution#Probability_density_function) 
of a $\distBeta(\alpha,\beta)$ distribution, and remember that it must integrate
to one. Then use the fact that for any $\gamma\in(0,1)$, the 
[gamma function satisfies](https://en.wikipedia.org/wiki/Gamma_function#General) 
$$
\Gamma(\gamma)\Gamma(1-\gamma) = \frac{\pi}{\sin\left(\gamma\pi\right)}.
$$
3. Test your implementation of `mc_estimate` by checking that it produces an
answer close to the value in @eq-integral.
4. In order to quantify the uncertainty inherent in the output of the previous 
step, we will construct a confidence interval[^1] for our Monte Carlo estimate
    a. Approximate the standard error of the estimator by computing the standard
       deviation of $K=30$ i.i.d. replications of `mc_estimate(f)`.
    b. Use the Central Limit Theorem to provide an asymptotically exact
       95% confidence interval.
    
[^1]: Yes, the frequentist concept! Monte Carlo simulation is one instance 
      where the assumptions of frequentist inference hold by design.

5. The following integral, known as the 
[sine integral])(https://en.wikipedia.org/wiki/Trigonometric_integral#Sine_integral),
$$
\int_0^1 \frac{\sin(t)}{t} \dee t.
$$
does not admit a closed-form expression. Provide a 95% confidence interval for
its value using `mc_estimate(f)`.


## Q.2: function on unbounded intervals

1. Write a function `is_exponential` that takes a function 
$f:[0,\infty)\to\reals$ and a number $\lambda>0$, and outputs a Monte Carlo estimate of
$\int_0^\infty f(x)\dee x$ using importance sampling with reference distribution
$\distExp(\lambda)$ and $n=10000$ i.i.d. samples.
2. Show that the function $f:[0,\infty)\to[0,\infty)$ given by
$$
f(x) = \frac{\exp(-\pi^2/x)}{x^3\sqrt{x}}.
$$
satisfies
$$
\int_0^\infty f(x)\dee x = \frac{3}{4\pi^4\sqrt{\pi}}.
$${#eq-integral-unbounded}
Hint: look at the expression for the 
[density of an Inverse Gamma distribution](https://en.wikipedia.org/wiki/Inverse-gamma_distribution#Probability_density_function).
Then use [the fact that](https://en.wikipedia.org/wiki/Gamma_function#General) for $n\in\nats$
$$
\Gamma\left(\frac{1}{2}+n\right) = \frac{(2n)!}{4^nn!}\sqrt{\pi}.
$$
3. Test your implementation of `is_exponential` with $\lambda=1$ by constructing
a 95% confidence interval for your estimate and checking that it contains the 
true value.
4. Re-do part 3 with $\lambda=20$ and compare both confidence intervals. Which
estimator is better?


## A minimal universal probabilistic programming language

In this question we will write a very short program that will nonetheless be
able to perform Bayesian inference on a wide range of Bayesian models
$$
\pi(x|y) = \frac{\pi(x)L(y|x)}{Z}
$$
The inference engine of our program will be self-normalizing importance sampling.
We will assume that the prior of our model is proper and that we can draw i.i.d.
samples from it.

1. Show that the importance weight of targeting the posterior distribution with
the prior as reference is proportional to the likelihood.
2. From now on we will focus on the [coin bag example from exercise 1](ex01.qmd).