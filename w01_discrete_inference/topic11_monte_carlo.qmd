---
title: "Simple Monte Carlo"
editor: 
  mode: source
---

{{< include ../_macros.qmd >}}



## Outline

### Topics 

- Simple Monte Carlo method
- Theoretical guarantee from the Law of Large Numbers

### Rationale

Simple Monte Carlo is the foundation for more complex Monte Carlo methods used by Bayesian practioners (e.g. Importance Sampling and Markov chain Monte Carlo (MCMC))


## Approximation of expectations using forward simulation


- As before, we want to compute an expectation $\ex[g(X, Y)]$
- Imagine a very large [decision tree](topic05_decision_diagrams.qmd), but where most branches have very low probability and only few have large probability
- In this case, instead of computing the exact expectation by iterating over each of the leaves as before, we will *approximate* expectations using forward simulation (a method know as **simple Monte Carlo**)
- This is done as follows:
    - Call your forward simulator $M$ times.
        - Denote the output at iteration $m \in \{1, 2, \dots M\}$ by:
    $$(X^\parm, Y^\parm) \sim p_{X, Y}(\cdot)$$
        - Compute $g$ on each, call each of the $M$ outputs $G^\parm$
    $$G^\parm = g(X^\parm, Y^\parm).$$
    - Return the average
    $$\hat G_M = \frac{1}{M} \sum_{m=1}^M G^\parm.$$
    
Intuitively, the output $\hat G_M$ has the nice property: 
$$\hat G_M \approx \ex[g(X, Y)].$${#eq-mc}

## Example 1

[Question 1.2 in the exercise.](../exercises/ex01.qmd#sec-q1)


## Example 2

{{< include ../blocks/_censored_dice.qmd >}}

Let us use Monte Carlo to estimate $\ex[X^Y]$:

```{r}
require(extraDistr)
set.seed(4)

# Recall our forward simulation code from earlier:
forward_simulate_roll_and_pick <- function() {
  x <- rdunif(1, min=1, max=4) # 1 uniform between 1-6, i.e. a dice
  y <- rdunif(1, min=1, max=x)
  c(x, y) # return a vector with these two realizations
}

sum <- 0.0
n_iterations <- 10000
for (iteration in 1:n_iterations) {
  sample <- forward_simulate_roll_and_pick()
  sum <- sum + sample[1]^sample[2]
}
print(sum/n_iterations)
```


## Guarantees from the Law of Large Numbers {#sec-lln}

**Question:** How can we make $\approx$ more formal in @eq-mc?

**Proposition (Law of Large Numbers, LLN):** if $Z_1, Z_2, \dots$ are i.i.d. random variables with $\ex|Z_i| < \infty$, then[^1]
$$ \frac{1}{M} \sum_{m=1}^M Z_m \to \ex[Z_i].$$

[^1]: Here "$\to$" denotes a suitable notion of convergence of random variables. 
    In STAT 302 you may have seen LLN with "convergence in probability", but this can 
    be strengthen to "convergence almost sure." 
    The difference between these notions of convergence will not matter in this course. 

Picking $Z_m = G^\parm$ we arrive to the following formalization of $\approx$: 
for any approximation error tolerance, we can find a number of iterations $M$ large enough 
such that we will be within that error tolerance with high probability after $M$ iterations.

