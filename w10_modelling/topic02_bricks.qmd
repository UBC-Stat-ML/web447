---
title: "More Bayesian bricks"
editor: 
  mode: source
---

{{< include ../_macros.qmd >}}


## Outline

### Topics

- More distributions to complement [those tested in quiz 1](../w07_quiz1/topic03_logistics.qmd). 
- Motivation, realization and parameterization(s) for each. 
- Reparameterization.


### Rationale

Recall our model building strategy: 

- start with observation, and find a distribution that "match its data type" (this creates the likelihood),
    - i.e. such that [**support**](../w01_discrete_inference/topic04_pmfs.qmd) of the distribution $=$ observation data type
- then look at the data types of each of the parameters of the distribution you just picked... 
    - ...and search for a distributions that match each the parameters' data type (this creates the prior),
- in the case of hierarchical models, recurse this process.

There are a few common data types for which we do not have talked much about distributions having 
realizations of that datatype. We now fill this gap.


## Counts

- Support: $\{0, 1, 2, 3, \dots\}$.

::: column-margin
![](https://upload.wikimedia.org/wikipedia/commons/8/83/Negbinomial.gif){width="200"}
:::
 

- Simple common choice is the [**Poisson distribution**](https://en.wikipedia.org/wiki/Poisson_distribution):
    - $\distPoiss(\lambda)$  
    - Parameter: Mean $\lambda > 0$.
    - Motivation:  [law of rare events](https://en.wikipedia.org/wiki/Poisson_distribution#Law_of_rare_events). 
    - [Stan doc.](https://mc-stan.org/docs/functions-reference/unbounded_discrete_distributions.html#poisson)
    
- Popular alternative, e.g., in bio-informatics: the **negative binomial distribution**:
    - $\distNB(\mu, \phi)$
    - Mean parameter $\mu > 0$ and concentration $\phi > 0$. 
    - Motivation: 
        - Poisson's variance is always the same as its mean.
        - Consider $\distNB$ when empirically the variance is greater than the mean ("over-dispersion").
    - [Stan doc.](https://mc-stan.org/docs/functions-reference/unbounded_discrete_distributions.html#nbalt)


## Positive real numbers

- Support: $\{x \in \reals: x > 0\} = \reals^+$

::: column-margin
![](https://upload.wikimedia.org/wikipedia/commons/e/e6/Gamma_distribution_pdf.svg){width="200"}
:::

- More common choice is the [**gamma distribution**](https://en.wikipedia.org/wiki/Gamma_distribution):
    - $\distGam(\alpha, \beta)$
    - Parameters: Shape parameters $\alpha > 0$ and rate $\beta > 0$.
    - [Stan doc.](https://mc-stan.org/docs/functions-reference/positive_continuous_distributions.html#gamma-distribution)


**Question:** consider the following Stan model:

```{r}
suppressPackageStartupMessages(require(rstan))
```

```{stan output.var = "gamma"}
data {
  int<lower=0> n_obs;
  vector<lower=0>[n_obs] observations;
}

parameters {
  real<lower=0> shape;
  real<lower=0> rate;
}

model {
  // priors
  shape ~ exponential(1.0/100);
  rate ~ exponential(1.0/100);
  
  // likelihood
  observations ~ gamma(shape, rate);
}
```

Notice that neither of the parameters passed in the likelihood can be interpreted as a mean. 
However, you are asked to report a mean parameter for the population from which the observations come from. 
How would you proceed?

{{< include ../../clickers/w10/_c01.qmd >}}



## Categories

   
```{r}
#| column: margin
#| echo: false

xs = c(1, 2, 3, 4, 5)
ps = c(0.2, 0.3, 0.1, 0.2, 0.1)

plot(xs, ps, type = 'h', xlab = "realization", ylab = "probability", ylim = c(0, 0.5))
```

- Support: $\{0, 1, 2, 3, \dots, K\}$, for some number of categories $K$. 
- All such distributions captured by the [**categorical distribution**](https://en.wikipedia.org/wiki/Categorical_distribution)
- We first discussed it in [Exercise 3](../exercises/ex03.qmd).
    - $\distCat(p_1, \dots, p_K)$
    - Probabilities $p_k > 0$, $\sum_k p_k = 1$.
    - [Stan doc.](https://mc-stan.org/docs/functions-reference/bounded_discrete_distributions.html#categorical-distribution)
 


## Simplex

**Terminology** for the set of valid parameters for the categorical, $\{(p_1, p_2, \dots, p_K) : p_k > 0, \sum_k p_k = 1\}$: the **$K$-simplex**. 

::: column-margin
![](https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Dirichlet.pdf/page1-750px-Dirichlet.pdf.jpg){width="200"}
:::

- Hence, if you need a prior over the parameters of a categorical, you need a distribution over the simplex!
- Common choice: the [**Dirichlet distribution**](https://en.wikipedia.org/wiki/Dirichlet_distribution):
    - $\distDir(\alpha_1, \dots, \alpha_K)$
    - Concentrations $\alpha_i > 0$.  
    - [Stan doc.](https://mc-stan.org/docs/functions-reference/simplex_distributions.html)


## Vectors

- Support: $\reals^K$

::: column-margin
![](../images/mvn.png){width="200"}
:::

- Common choice: the [**multivariate normal**](https://en.wikipedia.org/wiki/Multivariate_normal_distribution).
    - $\distNorm(\mu, \Sigma)$
    - Mean vector $\mu \in \reals^K$, covariance matrix $\Sigma \succ 0$, $\Sigma$ symmetric.
    - [Stan doc.](https://mc-stan.org/docs/functions-reference/distributions_over_unbounded_vectors.html)



## Many others!

### References

- Use wikipedia's [massive distribution list](https://en.wikipedia.org/wiki/List_of_probability_distributions),
- and [Stan's documentation](https://mc-stan.org/docs/functions-reference/).

### Alternative approach: reparameterization

- Suppose you need a distribution with support $[0, 1]$. 
- We have seen above that one option is to use a beta prior. 
- An alternative:
    - define $X \sim \distNorm(0, 1)$, 
    - use a transformation to map it to $[0, 1]$, e.g. $Y = \text{logistic}(X)$. 
- This approach is known as "re-parametrization"
    - For certain variational approaches, this helps inference. 
    - More on that in the last week. 
    


