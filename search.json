[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Caution\n\n\n\nPage under construction: information on this page may change.\n\n\n\n\n\n\n\n\n\n\nDate\nTopics\nReadings\n\n\n\n\nTue, Jan 9\nOverview. Probabilistic inference on discrete spaces.\nBDA 1.1-1.10\n\n\nTh, Jan 11\n\n\n\n\nTue, Jan 16\nA tour of Bayesian inference (on discrete spaces).\nBDA 2.1-2.5\n\n\nTh, Jan 18\n\n\n\n\nTue, Jan 23\nUniversal probabilistic inference via importance sampling.\nBDA 10.4. BDA 9.1-9.5 (going further on Decision Theory)\n\n\nTh, Jan 25\n\n\n\n\nTue, Jan 30\nBayesian classification, regression, GLMs, and beyond.\nBDA 14.1-14.5\n\n\nTh, Feb 1\n\n\n\n\nTue, Feb 6\nProperties of Bayesian models.\nBDA 4.1-4.5\n\n\nTh, Feb 8\n\n\n\n\nTue, Feb 13\nHierarchical models.\nBDA 5.1-5.7\n\n\nTh, Feb 15\n\n\n\n\nTue, Feb 20\nReading week.\nBDA 16.1-16.7\n\n\nTh, Feb 22\nReading week.\n\n\n\nTue, Feb 27\nQuiz 1.\n\n\n\nTh, Feb 29\nTBA\n\n\n\nTue, Mar 5\nMCMC user guide (via Stan).\nBDA 11.1-11.6\n\n\nTh, Mar 7\n\n\n\n\nFri, Mar 8\nProject proposal due.\n\n\n\nTue, Mar 12\nBayesian workflow.\nBDA 6.1-6.5\n\n\nTh, Mar 14\n\n\n\n\nTue, Mar 19\nModelling techniques (selected from prior design, mixtures, imputation, complex data collection).\nBDA 8.1-8.7\n\n\nTh, Mar 21\n\n\n\n\nTue, March 26\nQuiz 2.\n\n\n\nTh, Mar 28\nTBA\n\n\n\nTue, Apr 2\nMCMC developer guide.\nBDA 12.1-12.6\n\n\nTh, Apr 4\n\n\n\n\nTue, Apr 9\nVariational inference.\nBDA 13.7\n\n\nTh, Apr 11\nGuest lecture. (Last lecture)\n\n\n\nFri, Apr 19\nFinal project due.",
    "crumbs": [
      "Schedule"
    ]
  },
  {
    "objectID": "w00_intro/topic05_history.html",
    "href": "w00_intro/topic05_history.html",
    "title": "A bit of history",
    "section": "",
    "text": "Bayesian statistics: short historical overview\n\nPrecursors:\n\nThomas Bayes (1702–1761); first special case of Bayes rule, published posthumously in 1763\nPierre-Simon Laplace (1749–1827): generalizations, more applications\nIdea temporarily buried by frequentists in the 1920’s\n\nSecond wave: theoretical foundations\n\nBruno de Finetti, 1930: partial justification for exchangeable data\nStein paradox and crisis in frequentist statistics (1955)\nObjective-Subjective Bayes ‘divide’\n\nPopularization of Subjective Bayes by Leonard Savage in the ’50s\nInception of the Objective Bayes school: Harold Jeffreys (1939), further development by José-Miguel Bernardo (1979)\n\n\nThird wave: coming of age as a versatile data analysis tool\n\nInception: Nicholas Metropolis, Arianna Rosenbluth, Marshall Rosenbluth, Augusta Teller and Edward Teller (1953), Metropolis-Hastings algorithm in the physics literature\nIntroduction to Bayesian statistics: Stuart Geman and Donald Geman (1984)\nFirst major PPL: WinBUGS, David Lunn, Andrew Thomas, Nicky Best, David Spiegelhalter (2000)",
    "crumbs": [
      "Introduction",
      "A bit of history"
    ]
  },
  {
    "objectID": "w00_intro/topic01_why.html",
    "href": "w00_intro/topic01_why.html",
    "title": "Why?",
    "section": "",
    "text": "Address most data analysis issues (missing data, non-standard data types, non-iid, weird loss functions, adding expert knowledge, …)\n\nBayesian analysis: address those in a (semi) automated fashion / principled framework (“reductionist”)\n\nReductionism can be bad or good (main con of reductionism is computational)\n\nFrequentist statistics: every problem is a new problem\n\nImplementation complexity\n\nEfficient in analyst’s time (thanks to PPLs)\nHarder to scale computationally\n\\(\\Longrightarrow\\) shines on small data problems (there a much more of those than the “big data” hype would like you to think)\n\nStatistical properties\n\nOptimal if the model is well-specified\nSub-optimal in certain cases when the model is mis-specified\n\nThankfully the modelling flexibility makes it easier to build better models\nImportant to make model checks",
    "crumbs": [
      "Introduction",
      "Why?"
    ]
  },
  {
    "objectID": "w00_intro/topic01_why.html#bayesian-analysis-pros-and-cons",
    "href": "w00_intro/topic01_why.html#bayesian-analysis-pros-and-cons",
    "title": "Why?",
    "section": "",
    "text": "Address most data analysis issues (missing data, non-standard data types, non-iid, weird loss functions, adding expert knowledge, …)\n\nBayesian analysis: address those in a (semi) automated fashion / principled framework (“reductionist”)\n\nReductionism can be bad or good (main con of reductionism is computational)\n\nFrequentist statistics: every problem is a new problem\n\nImplementation complexity\n\nEfficient in analyst’s time (thanks to PPLs)\nHarder to scale computationally\n\\(\\Longrightarrow\\) shines on small data problems (there a much more of those than the “big data” hype would like you to think)\n\nStatistical properties\n\nOptimal if the model is well-specified\nSub-optimal in certain cases when the model is mis-specified\n\nThankfully the modelling flexibility makes it easier to build better models\nImportant to make model checks",
    "crumbs": [
      "Introduction",
      "Why?"
    ]
  },
  {
    "objectID": "w00_intro/topic01_why.html#week-2-example",
    "href": "w00_intro/topic01_why.html#week-2-example",
    "title": "Why?",
    "section": "Week 2 example",
    "text": "Week 2 example\n\nWould you rather get strapped to…\n\n“shiny rocket”: 1 success, 0 failures\n“rugged rocket”: 98 successes, 2 failures",
    "crumbs": [
      "Introduction",
      "Why?"
    ]
  },
  {
    "objectID": "w00_intro/topic01_why.html#paradox",
    "href": "w00_intro/topic01_why.html#paradox",
    "title": "Why?",
    "section": "Paradox?",
    "text": "Paradox?\n\nMaximum likelihood point estimates:\n\n“shiny rocket”: 100% success rate (1 success, 0 failures)\n“rugged rocket”: 98% success rate (98 successes, 2 failures)\n\nWhat is missing?",
    "crumbs": [
      "Introduction",
      "Why?"
    ]
  },
  {
    "objectID": "w00_intro/topic01_why.html#uncertainty-estimates",
    "href": "w00_intro/topic01_why.html#uncertainty-estimates",
    "title": "Why?",
    "section": "Uncertainty estimates",
    "text": "Uncertainty estimates\n\nTake-home message:\n\nPoint estimates are often insufficient, and can be very dangerous\nWe want some measure of uncertainty\n\nBayesian inference provides one way to build uncertainty measures\n\nBayesian measures of uncertainty we will describe: credible intervals\n\nAlternatives exist:\n\nConfidence intervals, from frequentist statistics\n“End product” looks similar, but very different in interpretation and construction",
    "crumbs": [
      "Introduction",
      "Why?"
    ]
  },
  {
    "objectID": "w00_intro/topic01_why.html#uncertainty-will-not-go-away",
    "href": "w00_intro/topic01_why.html#uncertainty-will-not-go-away",
    "title": "Why?",
    "section": "Uncertainty will not go away",
    "text": "Uncertainty will not go away\n\n\n\n\nJust collect more data??\n\nJust launch more rockets and wait? Collecting more data might be too costly/dangerous/unethical.\nIn some cases the data is just “gone”, i.e. we will never be able to collect more after a point (e.g.: phylogenetic tree inference)",
    "crumbs": [
      "Introduction",
      "Why?"
    ]
  },
  {
    "objectID": "w00_intro/topic04_examples.html",
    "href": "w00_intro/topic04_examples.html",
    "title": "Examples",
    "section": "",
    "text": "Origins of life/cancer/language and characterization of their respective evolutionary processes\nModelling high-throughput genomics data (single-cell sequencing, CRISPR-CAS9, ultra-deep, expression)\nBlack-hole imaging\n“Classical” tasks: classification, regression, clustering, etc\nA/B testing and Bayesian optimization\nDetermining fate of the universe from cosmic microwave background",
    "crumbs": [
      "Introduction",
      "Examples"
    ]
  },
  {
    "objectID": "w00_intro/topic04_examples.html#some-examples-of-bayesian-inference",
    "href": "w00_intro/topic04_examples.html#some-examples-of-bayesian-inference",
    "title": "Examples",
    "section": "",
    "text": "Origins of life/cancer/language and characterization of their respective evolutionary processes\nModelling high-throughput genomics data (single-cell sequencing, CRISPR-CAS9, ultra-deep, expression)\nBlack-hole imaging\n“Classical” tasks: classification, regression, clustering, etc\nA/B testing and Bayesian optimization\nDetermining fate of the universe from cosmic microwave background",
    "crumbs": [
      "Introduction",
      "Examples"
    ]
  },
  {
    "objectID": "w00_intro/topic04_examples.html#to-read-more-on-example-applications",
    "href": "w00_intro/topic04_examples.html#to-read-more-on-example-applications",
    "title": "Examples",
    "section": "To read more on example applications",
    "text": "To read more on example applications\nFor an entertaining popular science book on various applications of Bayesian statistics, have a look at The Theory That Would Not Die. Sharon Bertsch McGrayne. PDF available via UBC library.",
    "crumbs": [
      "Introduction",
      "Examples"
    ]
  },
  {
    "objectID": "exercises/ex03_distr_tutorial.html",
    "href": "exercises/ex03_distr_tutorial.html",
    "title": "Bayes1@UBC",
    "section": "",
    "text": "Here are the functionalities in distr you will need for the exercise\nLoading the package without annoying prompt:\nsuppressPackageStartupMessages(require(distr))"
  },
  {
    "objectID": "exercises/ex03_distr_tutorial.html#creating-a-distribution-object",
    "href": "exercises/ex03_distr_tutorial.html#creating-a-distribution-object",
    "title": "Bayes1@UBC",
    "section": "Creating a distribution object",
    "text": "Creating a distribution object\nLet’s create a Poisson with parameter \\(\\lambda = 3.2\\), which we will use in the following to demonstrate the functionalities in distr you will need for the exercise\n\ndistPoisson &lt;- Pois(lambda = 3.2)"
  },
  {
    "objectID": "exercises/ex03_distr_tutorial.html#sampling-from-it",
    "href": "exercises/ex03_distr_tutorial.html#sampling-from-it",
    "title": "Bayes1@UBC",
    "section": "Sampling from it",
    "text": "Sampling from it\nHere, we sample from our Poisson distribution 1 time:\n\nr(distPoisson)(1)\n\n[1] 4"
  },
  {
    "objectID": "exercises/ex03_distr_tutorial.html#evaluating-the-pmf-or-density",
    "href": "exercises/ex03_distr_tutorial.html#evaluating-the-pmf-or-density",
    "title": "Bayes1@UBC",
    "section": "Evaluating the PMF or density",
    "text": "Evaluating the PMF or density\nHere we compute the PMF of a poisson at the realization \\(x = 4\\):\n\nd(distPoisson)(4)\n\n[1] 0.1780928"
  },
  {
    "objectID": "exercises/ex01.html",
    "href": "exercises/ex01.html",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "",
    "text": "Grading\n\n\n\nOur priority with the weekly exercises is to provide timely feedback and an incentive to stay on top of the material so that lectures can be more effective.\nWe will select one or more questions that will be graded in more detail. For the other question(s), we will use the following particiation-centric binary scheme:\n\n1 point if something reasonable was attempted,\n0 otherwise.",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex01.html#goals",
    "href": "exercises/ex01.html#goals",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "Goals",
    "text": "Goals\n\nBring back to memory discrete probability (axioms, basic properties, conditioning, discrete Bayes rule).\nIntroduce forward discrete simulation.\nReview expectation and the law of large numbers.",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex01.html#setup",
    "href": "exercises/ex01.html#setup",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "Setup",
    "text": "Setup\nThis exercise is centered around the following scenario:\n\nImagine a bag with 3 coins each with a different probability parameter \\(p\\)\nCoin \\(i\\in \\{0, 1, 2\\}\\) has bias \\(i/2\\)—in other words:\n\nFirst coin: bias is \\(0/2 = 0\\) (i.e. both sides are “heads”, \\(p = 0\\))\nSecond coin: bias is \\(1/2 = 0.5\\) (i.e. standard coin, \\(p = 1/2\\))\nThird coin: bias is \\(2/2 = 1\\) (i.e. both sides are “tails”, \\(p = 1\\))\n\n\n\n\n\n\nConsider the following two steps sampling process\n\nStep 1: pick one of the three coins, but do not look at it!\nStep 2: flip the coin 4 times\n\nMathematically, this probability model can be written as follows: \\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\tag{1}\\]",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex01.html#sec-q1",
    "href": "exercises/ex01.html#sec-q1",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "Q.1: sampling from a joint distribution",
    "text": "Q.1: sampling from a joint distribution\n\nCompute \\(\\mathbb{E}[(1+Y_1)^X]\\) mathematically (with a precise mathematical derivation).\nWrite an R function called forward_sample that samples (“simulates”) from the joint distribution of \\((X, Y_1, \\dots, Y_4)\\). As a general practice, fix the seed, and submit both the code and the output (here, a single sample).\nHow can your code and the law of large number be used to approximate \\(\\mathbb{E}[(1+Y_1)^X]\\)?\nCompare the approximation from your code with you answer in part 1.\n\n\n\n\n\n\n\nBig idea\n\n\n\nPart 4 of this question illustrates a big idea in this course:\nstrategies to validate inference, i.e. ensuring it is bug-free in both the code and in the math. In a nutshell, this is possible thanks to theory: we use results that provide two ways to do the same thing, and verifying they indeed agree.",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex01.html#sec-q2",
    "href": "exercises/ex01.html#sec-q2",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "Q.2: computing a conditional",
    "text": "Q.2: computing a conditional\nSuppose now that you observe the outcome of the 4 coin flips, but not the type of coin that was picked. Say you observe: “heads”, “heads”, “heads”, “heads” = [0, 0, 0, 0]. Given that observation, what is the probability that you picked the standard coin (i.e., the one with \\(p = 1/2\\))?\n\nWrite mathematically: “Given you observe 4 heads, what is the probability that you picked the standard coin?”\nCompute the numerical value of the expression defined in part 1 (with a precise mathematical derivation).",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex01.html#sec-q3",
    "href": "exercises/ex01.html#sec-q3",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "Q.3: non uniform prior on coin types",
    "text": "Q.3: non uniform prior on coin types\nWe now modify the problem as follows: I stuffed the bag with 100 coins: 98 standard (fair) coins, 1 coin with only heads, and 1 coin with only tails. The rest is the same: pick one of the coins, flip it 4 times.\n\nWrite the joint distribution of this modified model. Use the \\(\\sim\\) notation as in Equation 1. Hint: use a Categorical distribution.\nCompute the probability that you picked one of the fair coins, given you see [0, 0, 0, 0].",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex01.html#sec-q4",
    "href": "exercises/ex01.html#sec-q4",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "Q.4: a first posterior inference algorithm",
    "text": "Q.4: a first posterior inference algorithm\nWe now generalize to having \\(K + 1\\) types of coins such that:\n\ncoin type \\(k \\in \\{0, 1, \\dots, K\\}\\) has bias \\(k/K\\)\nthe fraction of coins in the bag of type \\(k\\) is \\(\\rho_k\\).\n\nWe consider the same observation as before: “you observe 4 heads”. We want to find the conditional probability \\(\\pi_k\\) for all \\(k\\) that we picked coin type \\(k \\in \\{0, 1, \\dots, K\\}\\) from the bag given the observation.\n\nWrite an R function called posterior_given_four_heads taking as input a vector \\(\\rho = (\\rho_0, \\rho_1, \\dots, \\rho_K)\\) and returning \\(\\pi = (\\pi_0, \\pi_1, \\dots, \\pi_K)\\).\nTest your code by making sure you can recover the answer in Q. 3 as a special case. Report what values of \\(K\\) and \\(\\rho\\) you used.\nShow the output for \\(\\rho \\propto (1, 2, 3, \\dots, 10)\\). Here \\(\\propto\\) means “proportional to”; try to infer what it means in this context.",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex01.html#sec-q5",
    "href": "exercises/ex01.html#sec-q5",
    "title": "Exercise 1: discrete probabilistic inference",
    "section": "Q.5: generalizing observations",
    "text": "Q.5: generalizing observations\nWe now generalize Q. 4 as follows: instead of observing 4 “heads” out of 4 observations, say we observe n_heads out of n_observations, where n_heads and n_observations will be additional arguments passed into a new R function.\n\nWrite the joint distribution of this modified model. Use the \\(\\sim\\) notation as in Equation 1. Hint: use a Binomial distribution.\nWrite an R function called posterior taking three input arguments in the following order: a vector \\(\\rho\\) as in Q. 4, as well as two integers, n_heads and n_observations.\nTest your code by making sure you can recover the answer in Q. 3 as a special case.\nShow the output for \\(\\rho \\propto (1, 2, 3, \\dots, 10)\\) and n_heads = 2 and n_observations = 10.",
    "crumbs": [
      "Probability essentials",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex02.html",
    "href": "exercises/ex02.html",
    "title": "Exercise 2: Bayesian inference first contact",
    "section": "",
    "text": "Grading\n\n\n\nOur priority with the weekly exercises is to provide timely feedback and an incentive to stay on top of the material so that lectures can be more effective.\nWe will select one or more questions that will be graded in more detail. For the other question(s), we will use the following particiation-centric binary scheme:\n\n1 point if something reasonable was attempted,\n0 otherwise.",
    "crumbs": [
      "Bayes on a discrete model",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex02.html#goals",
    "href": "exercises/ex02.html#goals",
    "title": "Exercise 2: Bayesian inference first contact",
    "section": "Goals",
    "text": "Goals\n\nBuild a probability model for a concrete example.\nIntroduce the concept of Bayes estimators.",
    "crumbs": [
      "Bayes on a discrete model",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex02.html#sec-setup",
    "href": "exercises/ex02.html#sec-setup",
    "title": "Exercise 2: Bayesian inference first contact",
    "section": "Setup",
    "text": "Setup\nThis exercise is centered around the following scenario:\n\nYou are consulting for a satellite operator\nThey are about to send a $100M satellite on a Delta 7925H rocket\n\n\n\n\n\nData: as of Jan 2024, Delta 7925H rockets have been launched 3 times, with 0 failed launches \n\nNote: Delta 7925H is not reusable, so each rocket is “copy- built” from the same blueprint\n\nShould you recommend buying a $2M insurance policy?\n\nConvention: use 1 for a success, 0 for a failure.",
    "crumbs": [
      "Bayes on a discrete model",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex02.html#sec-q1",
    "href": "exercises/ex02.html#sec-q1",
    "title": "Exercise 2: Bayesian inference first contact",
    "section": "Q.1: define a Bayesian model",
    "text": "Q.1: define a Bayesian model\nIn order to perform inference on the unknown quantities, we must specify how they relate to the data; i.e., we need a probabilistic model. Assume that every Delta 7925H rocket has the same probability \\(p\\) of success. For simplicity, let us assume that \\(p\\) is allowed to take values on an evenly space grid \\[\np \\in \\left\\{\\frac{k}{K}: k\\in \\{0,\\dots,K\\}\\right\\}\n\\] for some fixed \\(K\\in\\mathbb{N}\\). Furthermore, we have access to a collection of numbers \\(\\rho_k\\in[0,1]\\) such that1 \\[\n\\forall k\\in\\{0,\\dots,K\\}:\\ \\mathbb{P}\\left(p=\\frac{k}{K}\\right) = \\rho_k.\n\\tag{1}\\]\nLet \\(Y_i\\) denote a binary variable with \\(Y_i=1\\) encoding a success, and \\(Y_i=0\\) a failure. We assume that, conditionally on \\(p\\), the \\(Y_i\\)’s are independent of each other.\nWe will use the following prior: \\[\n\\rho_k \\propto \\frac{k}{K}\\left(1-\\frac{k}{K}\\right).\n\\tag{2}\\] From now on, use \\(K = 20\\).\n\nWhat are the unknown quantities in this scenario? And what is the data?\nWrite the joint distribution of this model (use the \\(\\sim\\) notation).",
    "crumbs": [
      "Bayes on a discrete model",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex02.html#sec-q2",
    "href": "exercises/ex02.html#sec-q2",
    "title": "Exercise 2: Bayesian inference first contact",
    "section": "Q.2: posterior and point estimates",
    "text": "Q.2: posterior and point estimates\nTo help you answer the following questions, create the two vectors:\n\nprior_probabilities where entry \\(i\\) containing the prior probability \\(\\rho_{i-1}\\) defined in Q1 (the minus one reflects the fact that R uses indexing starting at 1), and\nrealizations, a vector of possible realizations of \\(p\\) in the same order, namely \\((0, 1/K, 2/K \\dots, 1)\\).\n\n\nPlot the prior PMF. Do you think this is a reasonable prior? Hint: use the same type of plot as used last week to plot PMFs.\nLet \\(\\pi_k = \\mathbb{P}(p = k/K | Y_{1:3} = (1, 1, 1))\\) denote the posterior probabilities, for \\(k \\in \\{0, 1, 2, \\dots, K\\}\\). Create a vector posterior_probabilities where entry \\(i\\) is \\(\\pi_{i-1}\\). Plot the posterior PMF.\nWhat is the posterior mode?\nWrite a function that compute the posterior mean of \\(p\\). Hint: you should obtain \\(\\mathbb{E}[p | Y_{1:3} = (1, 1, 1)] \\approx 0.7\\).",
    "crumbs": [
      "Bayes on a discrete model",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex02.html#sec-q3",
    "href": "exercises/ex02.html#sec-q3",
    "title": "Exercise 2: Bayesian inference first contact",
    "section": "Q.3: Bayes action",
    "text": "Q.3: Bayes action\nLet \\(a\\in\\{0,1\\}\\) be a binary variable denoting the decision of buying the insurance (\\(a=1\\)) or not (\\(a=0\\)).\n\nBased on the problem description from the Setup Section, define a loss function \\(L(a, y)\\) that summarizes the cost of having taken decision \\(a\\in\\{0,1\\}\\) depending on whether the next launch is successful (\\(y = 1\\)) or not (\\(y = 0\\)). Hint: use indicator functions (i.e. binary functions taking either the value zero or one).\nWe now consider the expected loss under the posterior predictive distribution: \\[\n\\mathcal{L}(a) := \\mathbb{E}[L(a,Y_4)|Y_{1:3}=(1, 1, 1)]\n\\] Write \\(\\mathcal{L}(a)\\) in terms of \\(\\mathbb{P}\\left(Y_4=1 \\middle| Y_{1:3}=(1, 1, 1) \\right)\\). Important: you can use without proof that \\(\\mathbb{P}\\left(Y_4=1 \\middle| Y_{1:3}=(1, 1, 1) \\right)\\) is the same as the posterior mean, which we computed earlier to be \\(\\approx 0.7\\) for our choice of prior.2\nFormulate a recommendation to the owner of the satellite (again, you can use without proof that \\(\\mathbb{P}\\left(Y_4=1 \\middle| Y_{1:3}=(1, 1, 1) \\right) \\approx 0.7\\)).",
    "crumbs": [
      "Bayes on a discrete model",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex02.html#footnotes",
    "href": "exercises/ex02.html#footnotes",
    "title": "Exercise 2: Bayesian inference first contact",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNotice that in Equation 1 we are using (small cap) \\(p\\) as a random variable, i.e. starting to move away from the probability theory capitalization convention towards the Bayesian convention where the same capitalization is used for both the random variable and its realization, as discussed in the first week.↩︎\nThe proof is as follows, where here we do desambiguate between the random variable \\(P\\) and its realization \\(p\\) (not to be confused with \\(\\mathbb{P}\\) and PMF \\(p(\\cdot)\\)!): \\[\\begin{align*}\n  \\mathbb{P}(Y_4 = y_4 | Y_{1:3} = \\boldsymbol{1}) &= \\sum_p \\mathbb{P}(P = p, Y_4 = y_4 | Y_{1:3} = \\boldsymbol{1}) \\;\\;\\text{(additivity axiom)} \\\\\n  &= \\sum_p  \\mathbb{P}(P = p | Y_{1:3} = \\boldsymbol{1}) \\mathbb{P}(Y_4 = y_4 | P = p, Y_{1:3} = \\boldsymbol{1}) \\;\\;\\text{(chain rule)} \\\\\n  &= \\sum_p \\pi(p) \\mathbb{P}(Y_4 = y_4 | P = p, Y_{1:3} = \\boldsymbol{1}) \\;\\;\\text{(definition)} \\\\\n  &= \\sum_p \\pi(p) \\mathbb{P}(Y_4 = y_4 | P = p) \\;\\;\\text{(conditional independence)} \\\\\n  &= \\sum_p \\pi(p) p \\;\\;\\text{(since each flip is assumed to be Bernoulli)} \\\\\n  &= \\mathbb{E}[p | Y_{1:3} = \\boldsymbol{1}].\n  \\end{align*}\\] Note however that this argument is very specific to this Bernoulli likelihood model and will not generalize. We will cover in class the general method to compute predictive distribution, see lecture notes.↩︎",
    "crumbs": [
      "Bayes on a discrete model",
      "Exercises"
    ]
  },
  {
    "objectID": "w03_ppl/topic01_ppls_intro.html",
    "href": "w03_ppl/topic01_ppls_intro.html",
    "title": "What is a PPL?",
    "section": "",
    "text": "What is a Probabilistic Programming Language (PPL)?\nHow to use a PPL.\n\n\n\n\nPPLs is the main way you will compute posterior distributions in this course. This week you will write your own! This will give you insight on the strengths and limitation of these approaches.",
    "crumbs": [
      "A first look at PPLs",
      "What is a PPL?"
    ]
  },
  {
    "objectID": "w03_ppl/topic01_ppls_intro.html#outline",
    "href": "w03_ppl/topic01_ppls_intro.html#outline",
    "title": "What is a PPL?",
    "section": "",
    "text": "What is a Probabilistic Programming Language (PPL)?\nHow to use a PPL.\n\n\n\n\nPPLs is the main way you will compute posterior distributions in this course. This week you will write your own! This will give you insight on the strengths and limitation of these approaches.",
    "crumbs": [
      "A first look at PPLs",
      "What is a PPL?"
    ]
  },
  {
    "objectID": "w03_ppl/topic01_ppls_intro.html#ppl-in-a-nutshell",
    "href": "w03_ppl/topic01_ppls_intro.html#ppl-in-a-nutshell",
    "title": "What is a PPL?",
    "section": "PPL in a nutshell",
    "text": "PPL in a nutshell\n\nIt is often easier to do forward sampling than to compute a posterior:\n\nForward sampling: just go down a single path in the decision tree.\nComputing a posterior: need to sum over all paths compatible with observed data.\n\nPPLs allow you to:\n\ncode your model as if you were going to do forward sampling,\nand the PPL will magically figure out how to approximate the posterior!",
    "crumbs": [
      "A first look at PPLs",
      "What is a PPL?"
    ]
  },
  {
    "objectID": "w03_ppl/topic01_ppls_intro.html#ppl-an-example-using-simpple",
    "href": "w03_ppl/topic01_ppls_intro.html#ppl-an-example-using-simpple",
    "title": "What is a PPL?",
    "section": "PPL: an example using simPPLe",
    "text": "PPL: an example using simPPLe\nWe created possibly the simplest possible PPL for this course. Let’s call it simPPLe. The exercise this week will be to understand simPPLe by filling-in a couple of key lines of code.\nFirst I will show you what simPPLe can do.\nLet us start with something we are familiar with: our bag of coin problem…\n\nMathematical description\nRecall our “bag of coins” model can be written as:\n\n\n\n\\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\tag{1}\\]\n\n\nPPL description of the same model\nHere is how to code up the “bag of coin” model in simPPLe for the purpose of computing \\(\\mathbb{P}(X = 1 | Y = (0, 0, 0, 0))\\):\n\n\nex03_ppl.R\n\ncoin_flips = rep(0, 4) # \"dataset\" of four identical coin flips = (0, 0, 0, 0) \n\n# simPPLe's description of our \"bag of coins\" example\nmy_first_probabilistic_program = function() {\n  \n  # Similar to forward sampling, but use 'observe' when the variable is observed\n  coin_index = simulate(DiscreteDistribution(supp = 0:2))\n  for (i in seq_along(coin_flips)) { \n    prob_heads = coin_index/2\n    observe(coin_flips[i], Bern(1 - prob_heads)) \n  }\n  \n  # return the test function g(x, y)\n  return(ifelse(coin_index == 1, 1, 0))\n}\n\nAfter solving this week’s exercise, you will be able to compute this probability as follows:\n\nsource(\"../exercises/ex03_scaffold.R\")\nsource(\"../exercises/ex03_ppl.R\")\nsource(\"../../solutions/sol03_posterior.R\")\n\nposterior(my_first_probabilistic_program, 100)\n\n[1] 0.03713188\n\n\n\n\nExtension: predicting the next draw\nRecall the painful calculation we did last week to get the predictive.\nHere is how to do it in simPPLe:\n\npredict_next_flip &lt;- function() {\n  coin_index = simulate(DiscreteDistribution(supp = 0:2))\n  prob_heads = coin_index/2\n  for (i in seq_along(coin_flips)) { \n    observe(coin_flips[i], Bern(1 - prob_heads)) \n  }\n  next_flip = simulate(Bern(1 - prob_heads))\n  same_as_observed = 1 - next_flip\n  return(same_as_observed)\n}\n\nposterior(predict_next_flip, 1000)\n\n[1] 0.9690606",
    "crumbs": [
      "A first look at PPLs",
      "What is a PPL?"
    ]
  },
  {
    "objectID": "w03_ppl/topic03_continuous.html",
    "href": "w03_ppl/topic03_continuous.html",
    "title": "Continuous models",
    "section": "",
    "text": "Review of key concepts for continuous random variables.\n\nDensity.\nComputing their expectation.\n\nBayes rule with continuous random variables.\n\n\n\n\nSince the parameters of distributions families are continuous, it natural to use continuous random variables for them in Bayesian statistics. For example it lets us get rid of the artificial discretization \\(K\\) we used in last week’s exercise.\nToday we will approach the calculations with both manual mathematic derivation and PPLs. Later we will increasingly rely only on PPLs. But it is still important to understand both methods.",
    "crumbs": [
      "A first look at PPLs",
      "Continuous models"
    ]
  },
  {
    "objectID": "w03_ppl/topic03_continuous.html#outline",
    "href": "w03_ppl/topic03_continuous.html#outline",
    "title": "Continuous models",
    "section": "",
    "text": "Review of key concepts for continuous random variables.\n\nDensity.\nComputing their expectation.\n\nBayes rule with continuous random variables.\n\n\n\n\nSince the parameters of distributions families are continuous, it natural to use continuous random variables for them in Bayesian statistics. For example it lets us get rid of the artificial discretization \\(K\\) we used in last week’s exercise.\nToday we will approach the calculations with both manual mathematic derivation and PPLs. Later we will increasingly rely only on PPLs. But it is still important to understand both methods.",
    "crumbs": [
      "A first look at PPLs",
      "Continuous models"
    ]
  },
  {
    "objectID": "w03_ppl/topic03_continuous.html#densities",
    "href": "w03_ppl/topic03_continuous.html#densities",
    "title": "Continuous models",
    "section": "Densities",
    "text": "Densities\nDefinition: \\(X\\) has density \\(f(x)\\) if \\[\\mathbb{P}(X \\in A) = \\int_A f(x) \\mathrm{d}x.\\]\nLOTUS: works the same as with discrete models: \\[\\mathbb{E}[g(X)] = \\int f(x) g(x) \\mathrm{d}x.\\]",
    "crumbs": [
      "A first look at PPLs",
      "Continuous models"
    ]
  },
  {
    "objectID": "w03_ppl/topic03_continuous.html#joint-densities",
    "href": "w03_ppl/topic03_continuous.html#joint-densities",
    "title": "Continuous models",
    "section": "Joint densities",
    "text": "Joint densities\nDefinition: \\((X, Y)\\) has joint density \\(f(x, y)\\) if \\[\\mathbb{P}((X, Y) \\in A) = \\int \\int_A f(x, y) \\mathrm{d}x.\\]",
    "crumbs": [
      "A first look at PPLs",
      "Continuous models"
    ]
  },
  {
    "objectID": "w03_ppl/topic03_continuous.html#key-properties",
    "href": "w03_ppl/topic03_continuous.html#key-properties",
    "title": "Continuous models",
    "section": "Key properties",
    "text": "Key properties\nNote that in much of what follows, everything works the same as with with discrete models except we replace sums by integrals and PMFs \\(p\\) by densities \\(f\\).\nLOTUS: \\[\\mathbb{E}[g(X, Y)] = \\int f(x, y) g(x, y) \\mathrm{d}x.\\]\nMarginalization: going from a joint density on \\((X, Y)\\) to the density of \\(X\\) only (the latter is called the marginal): \\[f_X(x) = \\int f(x, y) \\mathrm{d}y.\\]\nChain rule: \\[f(x, y) = f_X(x) f_{Y|X}(y|x).\\]\nBayes theorem: \\[f_{X|Y}(x|y) = \\frac{f(x, y)}{f_Y(y)}.\\]",
    "crumbs": [
      "A first look at PPLs",
      "Continuous models"
    ]
  },
  {
    "objectID": "w03_ppl/topic03_continuous.html#example-doomsday-model",
    "href": "w03_ppl/topic03_continuous.html#example-doomsday-model",
    "title": "Continuous models",
    "section": "Example: Doomsday model",
    "text": "Example: Doomsday model\n\nMathematical description\nConsider the following joint density described using chain rule: \\[\\begin{align*}\nX &\\sim {\\mathrm{Unif}}(0, 5) \\\\\nY | X &\\sim {\\mathrm{Unif}}(0, X).\n\\end{align*}\\]\n\n\nAleatoric interpretation\n\nI have a measuring tape, but you do not know how long is it.\n\nLength of tape: \\(X\\).\nLet’s say we think it’s less than 5m.\n\nI go in a separate room, unroll it fully, and pick a number at random from the tape.\n\nRandom point on tape: \\(Y\\)\n\n\nGoal: from the \\(Y\\), trying to guess the full length of the tape.\n\n\nEpistemic interpretation\n\n\\(X\\) is the total number of humans to ever live, future and past (in trillion).\n\\(Y\\) is the number of humans that were born before present (from archeological records, ~0.06 trillion).\n\n\n\n\nGoal: Can we guess (probabilistically) how many more human there will ever be in total?\nThis is known as the Doomsday argument\n\n\nComputations on the Doomsday model\nJoint density: which of these is the joint density?\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(\\frac{\\mathbb{1}[y &lt; x &lt; 5]}{y - 5} \\frac{\\mathbb{1}[0 &lt; y &lt; x]}{x}\\)\n\\(\\frac{\\mathbb{1}[0 &lt; y &lt; 5]}{5} \\frac{\\mathbb{1}[0 &lt; x &lt; y]}{y}\\)\n\\(\\frac{\\mathbb{1}[0 &lt; x &lt; 5]}{5} \\frac{\\mathbb{1}[0 &lt; y &lt; x]}{x}\\)\n\\(\\frac{\\mathbb{1}[0 &lt; x &lt; 5]}{5} \\frac{\\mathbb{1}[0 &lt; y &lt; 5]}{5}\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nWe have \\[f_X(x) = \\frac{\\mathbb{1}[0 &lt; x &lt; 5]}{5}\\] and \\[f_{Y|X}(y|x) =  \\frac{\\mathbb{1}[0 &lt; y &lt; x]}{x},\\] therefore \\[f(x, y) = \\frac{\\mathbb{1}[0 &lt; x &lt; 5]}{5} \\frac{\\mathbb{1}[0 &lt; y &lt; x]}{x}.\\]\n\n\n\nMarginal density: compute the marginal \\(f_Y(y)\\)\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(\\frac{1}{5} (\\log 5 - \\log y)\\)\n\\(\\log 5 - \\log y\\)\n\\(\\frac{2}{y^2} - \\frac{2}{25}\\)\n\\(\\frac{1}{5} \\left( \\frac{2}{y^2} - \\frac{2}{25} \\right)\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n\\[\\begin{align*}\nf_Y(y) &= \\frac{1}{5} \\int \\frac{ \\mathbb{1}[0 &lt; x &lt; 5] \\mathbb{1}[0 &lt; y &lt; x]}{x} \\mathrm{d}x \\\\\n&= \\frac{1}{5} \\int_y^5 \\frac{\\mathrm{d}x}{x} \\\\\n&= \\frac{1}{5} (\\log 5 - \\log y).\n\\end{align*}\\]\n\n\n\nPosterior density: from our marginal and Bayes’ theorem, we obtain \\[f_{X|Y}(x|y) = \\frac{\\mathbb{1}[0&lt;x&lt;5] \\mathbb{1}[0 &lt; y &lt; x]}{x (\\log 5 - \\log y)}.\\]\nPosterior expectation: compute \\(\\mathbb{E}[X|Y = 0.06]\\)\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(1.5\\)\n\\(\\approx 1.23\\)\n\\(\\approx 1.117\\)\n\\(\\approx 0.9714\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n\\[\\begin{align*}\nf_{X|Y}(x|y) &= \\int_y^5 x f_{X|Y}(x|y) \\mathrm{d}x \\\\\n&= \\frac{1}{\\log 5 - \\log y} \\int_y^5 \\mathrm{d}x \\\\\n&= \\frac{1}{\\log 5 - \\log y} (5 - y) \\approx 1.117. \\\\\n\\end{align*}\\]\n\n\n\n\n\n\n\n\n\nComparison with simPPLe\n\n\n\n\n\nCompare this to the simPPLe approximation\n\nsource(\"../exercises/ex03_scaffold.R\")\nsource(\"../../solutions/sol03_posterior.R\")\n\ndoomsday_model &lt;- function() {\n  x = simulate(Unif(0, 5))\n  observe(0.06, Unif(0, x))\n  return(x)\n}\n\nposterior(doomsday_model, 1000)\n\n[1] 1.032426",
    "crumbs": [
      "A first look at PPLs",
      "Continuous models"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic03_posteriors.html",
    "href": "w02_discrete_bayes/topic03_posteriors.html",
    "title": "Posterior distributions",
    "section": "",
    "text": "Notion of posterior distribution.\nExamples\nHow to use a posterior?\n\n\n\n\nThe posterior distribution appears in the second step of the Bayesian Recipe and is therefore encountered (at least implicitly) in all full Bayesian problems.",
    "crumbs": [
      "Bayes on a discrete model",
      "Posterior distributions"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic03_posteriors.html#outline",
    "href": "w02_discrete_bayes/topic03_posteriors.html#outline",
    "title": "Posterior distributions",
    "section": "",
    "text": "Notion of posterior distribution.\nExamples\nHow to use a posterior?\n\n\n\n\nThe posterior distribution appears in the second step of the Bayesian Recipe and is therefore encountered (at least implicitly) in all full Bayesian problems.",
    "crumbs": [
      "Bayes on a discrete model",
      "Posterior distributions"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic03_posteriors.html#definition",
    "href": "w02_discrete_bayes/topic03_posteriors.html#definition",
    "title": "Posterior distributions",
    "section": "Definition",
    "text": "Definition\nThe conditional PMF of the unknowns \\(X\\) given the observation \\(Y\\) is the called the posterior PMF.1\n\nNotation\nWe use \\(\\pi(x) = \\mathbb{P}(X = x | Y = y)\\) for the posterior PMF.\nRecall:\n\\[\\pi(x) = \\frac{\\gamma(x)}{Z},\\]\nwhere \\(\\gamma(x) = \\mathbb{P}(X = x, Y = y)\\) is the un-normalized posterior and \\(Z = \\mathbb{P}(Y = y)\\) is the normalization constant.",
    "crumbs": [
      "Bayes on a discrete model",
      "Posterior distributions"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic03_posteriors.html#examples",
    "href": "w02_discrete_bayes/topic03_posteriors.html#examples",
    "title": "Posterior distributions",
    "section": "Examples",
    "text": "Examples\n\nExample 1: coins in a bag\nVisualization of the prior PMF and how it arises from the decision tree and random variable \\(X\\) (showing 3 flips instead of 4):\n\n\nRecall that the probability of each path is the product of the edge labels.\n\nVisualization of the posterior PMF and how it arises from the decision tree and random variable \\(X\\):\n\n\nRecall we zero out the contribution of the paths not compatible with the observation (Heads, Heads, Heads).\nThis gives a list of numbers that do not sum to one, so we renormalize them.\n\n\n\nExample 2: rocket insurance\nYou will construct prior and posterior PMFs in question 2 of this week’s exercises.",
    "crumbs": [
      "Bayes on a discrete model",
      "Posterior distributions"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic03_posteriors.html#what-to-do-with-a-posterior",
    "href": "w02_discrete_bayes/topic03_posteriors.html#what-to-do-with-a-posterior",
    "title": "Posterior distributions",
    "section": "What to do with a posterior?",
    "text": "What to do with a posterior?\n\nShow a visualiation (posterior PMF).\nCompute a summary of the PMF:\n\npoint estimate: single “best guess”, or\na credible region: a set of “guesses”.\n\nMore generally: decision theory / Step 3 of the Bayesian Recipe.",
    "crumbs": [
      "Bayes on a discrete model",
      "Posterior distributions"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic03_posteriors.html#footnotes",
    "href": "w02_discrete_bayes/topic03_posteriors.html#footnotes",
    "title": "Posterior distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nif the unknown quantity is continuous, the posterior will be expressed using a density. A term that captures both the continuous and discrete case is “distribution” i.e. “posterior distribution”.↩︎",
    "crumbs": [
      "Bayes on a discrete model",
      "Posterior distributions"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic08_criticism.html",
    "href": "w02_discrete_bayes/topic08_criticism.html",
    "title": "Intro to model criticism",
    "section": "",
    "text": "What is a model mis-specification?\nWhat are the consequences?\nWhat to do about it.\n\n\n\n\nModel mis-specification (the model being “too wrong”) can lead to serious problems in all types of statistical models, but Bayesian models are often more seriously affected. As a result it is important to detect serious cases of mis-specification and to address them. This is just an introduction, we will go in more depth once we have introduced Bayesian regression models.",
    "crumbs": [
      "Bayes on a discrete model",
      "Intro to model criticism"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic08_criticism.html#outline",
    "href": "w02_discrete_bayes/topic08_criticism.html#outline",
    "title": "Intro to model criticism",
    "section": "",
    "text": "What is a model mis-specification?\nWhat are the consequences?\nWhat to do about it.\n\n\n\n\nModel mis-specification (the model being “too wrong”) can lead to serious problems in all types of statistical models, but Bayesian models are often more seriously affected. As a result it is important to detect serious cases of mis-specification and to address them. This is just an introduction, we will go in more depth once we have introduced Bayesian regression models.",
    "crumbs": [
      "Bayes on a discrete model",
      "Intro to model criticism"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic08_criticism.html#definitions",
    "href": "w02_discrete_bayes/topic08_criticism.html#definitions",
    "title": "Intro to model criticism",
    "section": "Definitions",
    "text": "Definitions\nModel mis-specification: when the model is “too wrong” (in the context of the famous quote by George Box).\nModel criticism: the task of trying to find mis-specification.\n\nIt can be done by reasoning and discussion with experts.\nIt can be done using data (goodness-of-fit)\n\n\nExample\nRecall our notation: \\(\\rho\\) prior PMF, \\(\\pi\\) posterior PMF.\n\nSuppose we put zero prior mass to having a fair dice. What happens on the posterior?\n\n\n\nIf we put prior mass of zero to some realization \\(x\\), say \\(\\rho(x) = 0\\) then the posterior probability on \\(x\\) will always be zero, \\(\\pi(x) = 0\\), no matter how many observations we get\n\nThis could be disastrous! (e.g. ignoring extreme scenarios can have extreme consequences)\n\nPrinciple to avoid this is known as Cromwell’s rule (Oliver Cromwell, 1650): “I beseech you, in the bowels of Christ, think it possible that you may be mistaken.”\n\nDiscussion: can you identify other issues with the model from Exercise 2?",
    "crumbs": [
      "Bayes on a discrete model",
      "Intro to model criticism"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic08_criticism.html#how-to-correct-mis-specification",
    "href": "w02_discrete_bayes/topic08_criticism.html#how-to-correct-mis-specification",
    "title": "Intro to model criticism",
    "section": "How to correct mis-specification",
    "text": "How to correct mis-specification\n\nImprove the model!\nThen iterate with more criticism and improve again if needed.\nIterative model improvement is part of the current “best practice” in Bayesian analysis.",
    "crumbs": [
      "Bayes on a discrete model",
      "Intro to model criticism"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic06_decision.html",
    "href": "w02_discrete_bayes/topic06_decision.html",
    "title": "Decision theory",
    "section": "",
    "text": "Decision theory: making decision in the face of uncertainty.\n\nFirst, without observed data.\nSecond, incorporating observed data.\n\nReview of property of expectation useful for decision theory calculations.\n\n\n\n\nWe talked a lot about the “Bayesian recipe.” Here we formalize the last step of that recipe: using a posterior and a loss function to make a decision.\nLater, we will see that the point estimates and credible sets covered this week are actually special cases of the decision theoretic framework (i.e. they emerge when specific loss functions are selected).",
    "crumbs": [
      "Bayes on a discrete model",
      "Decision theory"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic06_decision.html#outline",
    "href": "w02_discrete_bayes/topic06_decision.html#outline",
    "title": "Decision theory",
    "section": "",
    "text": "Decision theory: making decision in the face of uncertainty.\n\nFirst, without observed data.\nSecond, incorporating observed data.\n\nReview of property of expectation useful for decision theory calculations.\n\n\n\n\nWe talked a lot about the “Bayesian recipe.” Here we formalize the last step of that recipe: using a posterior and a loss function to make a decision.\nLater, we will see that the point estimates and credible sets covered this week are actually special cases of the decision theoretic framework (i.e. they emerge when specific loss functions are selected).",
    "crumbs": [
      "Bayes on a discrete model",
      "Decision theory"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic06_decision.html#decision-theory-without-data",
    "href": "w02_discrete_bayes/topic06_decision.html#decision-theory-without-data",
    "title": "Decision theory",
    "section": "Decision theory without data",
    "text": "Decision theory without data\nYour friend proposes the following game (a good model for lottery!):\n\nShe flips a standard coin:\n\nif it’s a “heads”: you give her $10\nif it’s a “tails”: she gives you $9.\n\nYour decision: to play or not to play?\n\n\nMathematical formulation\n\nSet of actions: \\(A = \\{0, 1\\}\\) (\\(1 =\\) play, \\(0 =\\) do not play).\nProbability model: \\(X \\sim {\\mathrm{Bern}}(1/2)\\).\nLoss function:\n\n\\(L(a, x)\\): how much do I lose if I pick action \\(a \\in A\\) and encounter realization \\(X = x\\)?\n\nMathematical solution: minimize over \\(a \\in A\\) the expected loss \\[L(a) = \\mathbb{E}[L(a, X)].\\]\n\n\n\nExample\nCompute \\(\\operatorname{arg\\,min}L(a)\\) and \\(\\min L(a)\\).\n\n\\(1\\) and \\(1\\)\n\\(1\\) and \\(-1/2\\)\n\\(1\\) and \\(1/2\\)\n\\(0\\) and \\(0\\)\nNone of the above\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nThe loss function is given by:\n\n\n\n\nDo not play (\\(a = 0\\))\nPlay (\\(a = 1\\))\n\n\n\n\nHeads (\\(x = 1\\))\n\\(0\\)\n\\(10\\)\n\n\nTails (\\(x = 0\\))\n\\(0\\)\n\\(-9\\)\n\n\n\nTherefore, the action that maximizes \\(L(a)\\) is \\(a = 0\\) (i.e., \\(a = 0\\) is the “argmin”) and gives value \\(L(0) = 0\\).\n\n\n\nIt is useful and important to answer this easy question in excruciating mathematical details. This will prepare us for more complex decision scenarios.\nLet us start by writing the loss function mathematically using indicator function defined as: \\[\\mathbb{1}[\\text{some condition}] = \\left\\{\n\\begin{array}{ll}\n1 & \\text{if the condition is true,} \\\\\n0 & \\text{if the condition is false.}\n\\end{array}\n\\right.\\] This gives us: \\[L(a, x) = \\mathbb{1}[a = 0] \\cdot (\\$0) + \\mathbb{1}[a = 1, x = 0] \\cdot (-\\$9) +  \\mathbb{1}[a = 1, x = 1] \\cdot (\\$10).\\]\nLet us simplify the expected loss function, i.e. \\[\\mathbb{E}[L(a, X)] = \\mathbb{E}[\\mathbb{1}[a = 0] \\cdot (\\$0) + \\mathbb{1}[a = 1, X = 0] \\cdot (-\\$9) +  \\mathbb{1}[a = 1, X = 1] \\cdot (\\$10)].\\] o do that simplification, first use linearity of expectation which you will recall from probability theory tells us that for any random variables \\(X_1\\) and \\(X_2\\), we have \\(\\mathbb{E}[X_1 + c X_2] = \\mathbb{E}[X_1] + c \\mathbb{E}[X_2]\\) for any constant \\(c\\).\nIn our context, using linearity with \\(c=1\\) allows us to simplify the above to: \\[\\underbrace{\\mathbb{E}[\\mathbb{1}[a = 0] \\cdot (\\$0)]}_0 + \\mathbb{E}[\\mathbb{1}[a = 1, X = 0] \\cdot (-\\$9)] + \\mathbb{E}[\\mathbb{1}[a = 1, X = 1] \\cdot (\\$10)].\\]\nTrick 1: To deal with each remaining term, use that: \\(\\mathbb{1}[a = 1, X = 1] = \\mathbb{1}[a = 1]\\mathbb{1}[X = 1]\\) (check!), and then use linearity with \\(c = \\$ 10 \\cdot \\mathbb{1}[a = 1]\\) to get: \\[\\mathbb{E}[\\mathbb{1}[a = 1, X = 1] \\cdot (\\$10)] =  \\$ 10 \\cdot \\mathbb{1}[a = 1] \\mathbb{E}[\\mathbb{1}[X = 1]].\\]\nLOTUS: Finally, we have to compute \\(\\mathbb{E}[\\mathbb{1}[X = 1]]\\). From our review of the Law of the Unconscious Statistician, this is done as follows: \\[\\mathbb{E}[\\mathbb{1}[X = 1]] = \\sum_x \\mathbb{1}[x = 1] p_X(x) = 0 + 1 \\cdot p_X(1) = 1/2.\\]\nTrick 2: you will often take expectation of indicator function, you will always find that \\(\\mathbb{E}[\\mathbb{1}[\\text{an event}]] = \\mathbb{P}(\\text{an event})\\).\nPutting it all together: \\[L(a) = \\mathbb{E}[L(a, X)] =  -\\$ 9 \\cdot \\mathbb{1}[a = 1] (1/2) + \\$ 10 \\cdot \\mathbb{1}[a = 1] (1/2) = \\$0.5 \\cdot \\mathbb{1}[a = 1].\\]",
    "crumbs": [
      "Bayes on a discrete model",
      "Decision theory"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic06_decision.html#decision-theory-with-data",
    "href": "w02_discrete_bayes/topic06_decision.html#decision-theory-with-data",
    "title": "Decision theory",
    "section": "Decision theory with data",
    "text": "Decision theory with data\n\nWe now consider the case where we have some data \\(Y\\) that give us information about \\(X\\).\nThe actions \\(A\\) and loss \\(L(a, x)\\) are the same as before.\n\nHow to modify the last section to take into account the data \\(Y\\)?\n\nDo everything the same, except:\nuse the conditional PMF \\(p_{X|Y}\\) instead of the PMF \\(p_X\\).\n\n\nDefinition: the Bayes estimator\nMathematically: use an action \\(a \\in A\\) minimizing the posterior expected loss, i.e. \\[\\operatorname{arg\\,min}\\mathbb{E}[L(a, X) | Y = y].\\] where: \\[\\mathbb{E}[L(a, X) | Y = y] = \\sum_x L(a, x) p_{X|Y}(x|y).\\]\n\n\nExample\nYou will apply the Bayes estimator in question 3 of this week’s exercises.",
    "crumbs": [
      "Bayes on a discrete model",
      "Decision theory"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic04_point.html",
    "href": "w02_discrete_bayes/topic04_point.html",
    "title": "Point estimates",
    "section": "",
    "text": "Common point estimates:\n\nPosterior mean.\nPosterior mode.\n\n\n\n\n\nIt is often necessary to summarize the posterior distribution with a single “best guess”, even though as we will see this hides important information namely our uncertainty about that guess.",
    "crumbs": [
      "Bayes on a discrete model",
      "Point estimates"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic04_point.html#outline",
    "href": "w02_discrete_bayes/topic04_point.html#outline",
    "title": "Point estimates",
    "section": "",
    "text": "Common point estimates:\n\nPosterior mean.\nPosterior mode.\n\n\n\n\n\nIt is often necessary to summarize the posterior distribution with a single “best guess”, even though as we will see this hides important information namely our uncertainty about that guess.",
    "crumbs": [
      "Bayes on a discrete model",
      "Point estimates"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic04_point.html#definitions",
    "href": "w02_discrete_bayes/topic04_point.html#definitions",
    "title": "Point estimates",
    "section": "Definitions",
    "text": "Definitions\n\nLet \\(\\pi(x) = \\mathbb{P}(X = x | Y = y)\\) denote a posterior PMF.\nPoint estimate: Instead of plotting the full information in \\(\\pi\\), we can report a “location” summary such as the mean of the posterior \\(\\pi\\).\n\n\nPosterior mean\nRecall the mean is computed from a PMF via \\[\\sum_x x\\; \\pi(x),\\] where the sum is over \\(\\{x : \\pi(x) &gt; 0 \\}\\).\nNotation: the posterior mean is denoted \\(\\mathbb{E}[X | Y = y] = \\sum x\\ \\pi(x)\\).\n\n\nExample 1\nCompute \\(\\mathbb{E}[X | Y = (1, 1)]\\) in the bag of coin example.\n\nImagine a bag with 3 coins each with a different probability parameter \\(p\\)\nCoin \\(i\\in \\{0, 1, 2\\}\\) has bias \\(i/2\\)—in other words:\n\nFirst coin: bias is \\(0/2 = 0\\) (i.e. both sides are “heads”, \\(p = 0\\))\nSecond coin: bias is \\(1/2 = 0.5\\) (i.e. standard coin, \\(p = 1/2\\))\nThird coin: bias is \\(2/2 = 1\\) (i.e. both sides are “tails”, \\(p = 1\\))\n\n\n\n\n\n\nConsider the following two steps sampling process\n\nStep 1: pick one of the three coins, but do not look at it!\nStep 2: flip the coin 4 times\n\nMathematically, this probability model can be written as follows: \\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\tag{1}\\]\n\n\n0.5\n1.8\n2.25\n3.5\nNone of the above\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nFirst, compute the unnormalized posterior \\(\\gamma \\propto \\pi\\): \\[\\gamma = (\\gamma(0), \\gamma(1), \\gamma(2)) = (1/3) (0^2, (1/2)^2, 1^2),\\] then normalize: \\[\\pi = \\gamma / Z =  (0, 1/5, 4/5).\\] Finally, compute the conditional expectation: \\[\\mathbb{E}[X | Y = (1, 1)] = \\sum x \\; \\pi(x) = (0, 1, 2) \\cdot (0, 1/5, 4/5) = 9/5 = 1.8.\\]\nCommon mistake: forgetting normalization step: \\[\\sum x \\; \\pi(x) \\neq \\sum x \\; \\gamma(x).\\]\n\nThis “common mistake” highlights that we really need \\(Z\\) to compute posterior expectations using the exact, exhaustive approach (i.e. the method we are using here).\nWhen we talk more about Monte Carlo methods, we will see that these methods allow us to approximate expecations without having to compute \\(Z\\)!\n\n\n\n\n\n\nPosterior mode\nThe mode is the location of the “tallest stick” in the PMF.\nNotation: \\(\\operatorname{arg\\,max}\\pi(x),\\) i.e. the point that achieves the maximum of \\(\\pi\\).\nIn the Bayesian context, the mode of a posterior PMF is also known as the Maximum A Posteriori (MAP) estimator.\n\n\nExample 2\nYou will practice computing the posterior mean/mode in question 2 of the exercises.",
    "crumbs": [
      "Bayes on a discrete model",
      "Point estimates"
    ]
  },
  {
    "objectID": "challenges/ch04.html",
    "href": "challenges/ch04.html",
    "title": "Challenge questions",
    "section": "",
    "text": "Not for grades!\n\n\n\nThese are not essential for learning the material and can be skipped without affecting your grade. If you successfully solve one set of problem, a week of participation activity will be waived (it does not have to be the same week you submit the challenge question). Submit your answer at any time. I will not post solutions for the challenge questions.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nPage under construction: information on this page may change.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Challenge"
    ]
  },
  {
    "objectID": "challenges/ch02.html",
    "href": "challenges/ch02.html",
    "title": "Challenge questions",
    "section": "",
    "text": "Not for grades!\n\n\n\nThese are not essential for learning the material and can be skipped without affecting your grade. If you successfully solve one set of problem, a week of participation activity will be waived (it does not have to be the same week you submit the challenge question). Submit your answer at any time. I will not post solutions for the challenge questions.\n\n\nAfter doing Exercise 2 consider the following problem:\n\nWrite a function that takes as input posterior_probabilities and builds the highest probability set for any \\(\\alpha\\in[0,1]\\).\nReport a \\(75\\%\\) highest probability set, making sure that the posterior probability of the set you return does not fall below \\(75\\%\\).",
    "crumbs": [
      "Bayes on a discrete model",
      "Challenge"
    ]
  },
  {
    "objectID": "drafts/topic06_ess.html",
    "href": "drafts/topic06_ess.html",
    "title": "Effective sample size",
    "section": "",
    "text": "TODO\n\n\n\nTODO"
  },
  {
    "objectID": "drafts/topic06_ess.html#outline",
    "href": "drafts/topic06_ess.html#outline",
    "title": "Effective sample size",
    "section": "",
    "text": "TODO\n\n\n\nTODO"
  },
  {
    "objectID": "drafts/topic06_ess.html#todo",
    "href": "drafts/topic06_ess.html#todo",
    "title": "Effective sample size",
    "section": "TODO",
    "text": "TODO\nTODO: look up bound in Chopin\nTODO: link up with rates plot - intuition of the MCSE\nTODO: more readings on SNIS\n\nChopin\nOwen\nPareto stuffs"
  },
  {
    "objectID": "drafts/ex02.html",
    "href": "drafts/ex02.html",
    "title": "Exercise 2: Bayesian inference on discrete spaces",
    "section": "",
    "text": "Caution\n\n\n\nPage under construction: information on this page may change."
  },
  {
    "objectID": "drafts/ex02.html#goals",
    "href": "drafts/ex02.html#goals",
    "title": "Exercise 2: Bayesian inference on discrete spaces",
    "section": "Goals",
    "text": "Goals\nA first contact with several Bayesian concepts. We use the same discrete model for all questions.\n\nNotions of priors, likelihood, posterior.\nPoint summary of posterior distribution: mean, median, mode.\nConstructing credible intervals.\nBasic decision theory.\nSequential update of posterior distribution."
  },
  {
    "objectID": "w01_discrete_inference/topic05_decision_diagrams.html",
    "href": "w01_discrete_inference/topic05_decision_diagrams.html",
    "title": "Decision trees",
    "section": "",
    "text": "Decision trees\nReview of more probability theory concepts, contextualized in decision trees: outcome, event, sample space, partitions, conditional probability\n\n\n\n\nWe will use decision trees to provide visualization for a bunch of complex concepts such as forward simulation, posterior inference, importance sampling, probabilistic programming, etc.",
    "crumbs": [
      "Probability essentials",
      "Decision trees"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic05_decision_diagrams.html#outline",
    "href": "w01_discrete_inference/topic05_decision_diagrams.html#outline",
    "title": "Decision trees",
    "section": "",
    "text": "Decision trees\nReview of more probability theory concepts, contextualized in decision trees: outcome, event, sample space, partitions, conditional probability\n\n\n\n\nWe will use decision trees to provide visualization for a bunch of complex concepts such as forward simulation, posterior inference, importance sampling, probabilistic programming, etc.",
    "crumbs": [
      "Probability essentials",
      "Decision trees"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic05_decision_diagrams.html#running-example",
    "href": "w01_discrete_inference/topic05_decision_diagrams.html#running-example",
    "title": "Decision trees",
    "section": "Running example",
    "text": "Running example\n\nImagine a bag with 3 coins each with a different probability parameter \\(p\\)\nCoin \\(i\\in \\{0, 1, 2\\}\\) has bias \\(i/2\\)—in other words:\n\nFirst coin: bias is \\(0/2 = 0\\) (i.e. both sides are “heads”, \\(p = 0\\))\nSecond coin: bias is \\(1/2 = 0.5\\) (i.e. standard coin, \\(p = 1/2\\))\nThird coin: bias is \\(2/2 = 1\\) (i.e. both sides are “tails”, \\(p = 1\\))\n\n\n\n\n\n\nConsider the following two steps sampling process\n\nStep 1: pick one of the three coins, but do not look at it!\nStep 2: flip the coin 4 times\n\nMathematically, this probability model can be written as follows: \\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\tag{1}\\]",
    "crumbs": [
      "Probability essentials",
      "Decision trees"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic05_decision_diagrams.html#decision-tree",
    "href": "w01_discrete_inference/topic05_decision_diagrams.html#decision-tree",
    "title": "Decision trees",
    "section": "Decision tree",
    "text": "Decision tree\n\nDecision tree: a recursive classification of all possible scenarios\nNodes in the tree are “groups of scenarios” which we call events\nChildren of a node partitions an event into an exhaustive set of sub-cases,\n\ni.e. \\(E_1, E_2, \\dots\\) is a partition of \\(E\\).\n\nIn the decision tree below, we partitioned events until we get events at the leaves each containing a single scenario\n\nWe call one individual scenario an outcome\nWe call the set of all outcomes the sample space, \\(S\\), and put it at the root of decision trees.\n\n\n\n\n\n\n\n\nflowchart TD\nS__and__X_0 -- 1.0 --&gt; S__and__X_0__and__Y1_false[\"Y1=false\"]\nS__and__X_2__and__Y1_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS -- 0.33 --&gt; S__and__X_0[\"X=0\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS -- 0.33 --&gt; S__and__X_1[\"X=1\"]\nS__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_false[\"Y1=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS__and__X_0__and__Y1_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true[\"Y2=true\"]\nS__and__X_2 -- 1.0 --&gt; S__and__X_2__and__Y1_true[\"Y1=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_true[\"Y1=true\"]\nS -- 0.33 --&gt; S__and__X_2[\"X=2\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_2__and__Y1_true__and__Y2_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]",
    "crumbs": [
      "Probability essentials",
      "Decision trees"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic05_decision_diagrams.html#nodes-and-events",
    "href": "w01_discrete_inference/topic05_decision_diagrams.html#nodes-and-events",
    "title": "Decision trees",
    "section": "Nodes and events",
    "text": "Nodes and events\nTo describe the event corresponding to a node \\(v\\) in the tree:\n\ntrace the path from the node \\(v\\) to the root\ntake the intersection of all node labels\n\nExample: find the node in the above tree corresponding to the event \\((X = 1) \\cap (Y_1 = 0)\\).\nProbability notation review:\n\n\\((X = 1) = \\{s \\in S : X(s) = 1\\}\\)\n\\((X = 1, Y_1 = 0) = (X = 1) \\cap (Y_1 = 0)\\)",
    "crumbs": [
      "Probability essentials",
      "Decision trees"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic05_decision_diagrams.html#edges-and-conditional-probabilities",
    "href": "w01_discrete_inference/topic05_decision_diagrams.html#edges-and-conditional-probabilities",
    "title": "Decision trees",
    "section": "Edges and conditional probabilities",
    "text": "Edges and conditional probabilities\nWhen there is an edge from events \\(E_1\\) to \\(E_2\\), we annotate it with \\(\\mathbb{P}(E_2 | E_1)\\).\nRecall: conditional probability of \\(E_2\\) given \\(E_1\\)\n\\[\\mathbb{P}(E_2 | E_1) = \\frac{\\mathbb{P}(E_1 \\cap E_2)}{\\mathbb{P}(E_1)}\\]\nExample:\n\ntake the edge from \\(E_1 = (X = 1)\\) to \\(E_2 = (X = 1, Y_1 = 0)\\). \\[\\mathbb{P}(E_2 | E_1) = \\frac{\\mathbb{P}(E_1 \\cap E_2)}{\\mathbb{P}(E_1)} = \\frac{\\mathbb{P}(E_2)}{\\mathbb{P}(E_1)} = \\mathbb{P}(Y_1 = 0 | X = 1)\\]\nTranslating \\(\\mathbb{P}(Y_1 = 0 | X = 1)\\) into words: “the probability that the first flip is ‘heads’ \\((Y_1 = 0)\\) given that you picked the standard coin \\((X = 1)\\).’’\nHence the edge from \\(E_1\\) to \\(E_2\\) is labelled \\(1/2\\).",
    "crumbs": [
      "Probability essentials",
      "Decision trees"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic02_axioms.html",
    "href": "w01_discrete_inference/topic02_axioms.html",
    "title": "Axioms of probability",
    "section": "",
    "text": "Definition: \\(E_1, E_2, \\dots\\) is a partition of \\(E\\) if:\n\nthe \\(E_i\\)’s are disjoint, i.e., \\[E_i \\cap E_j = \\emptyset \\text{ when } i\\neq j,\\]\nand their union is \\(E\\), i.e., \\(\\cup_i E_i = E\\).",
    "crumbs": [
      "Probability essentials",
      "Axioms of probability"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic02_axioms.html#partitions",
    "href": "w01_discrete_inference/topic02_axioms.html#partitions",
    "title": "Axioms of probability",
    "section": "",
    "text": "Definition: \\(E_1, E_2, \\dots\\) is a partition of \\(E\\) if:\n\nthe \\(E_i\\)’s are disjoint, i.e., \\[E_i \\cap E_j = \\emptyset \\text{ when } i\\neq j,\\]\nand their union is \\(E\\), i.e., \\(\\cup_i E_i = E\\).",
    "crumbs": [
      "Probability essentials",
      "Axioms of probability"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic02_axioms.html#sec-axioms",
    "href": "w01_discrete_inference/topic02_axioms.html#sec-axioms",
    "title": "Axioms of probability",
    "section": "Axioms of probability",
    "text": "Axioms of probability\n\nA probability is a function \\(\\mathbb{P}\\) that satisfy the following constraints:\n\n\\(\\mathbb{P}\\) should take events as input and return a number between zero and one: \\[\\mathbb{P}(E) \\in [0, 1].\\]\nAdditivity axiom: if \\(E_1, E_2, \\dots\\) is a partition of \\(E\\), then \\[\\mathbb{P}(E) = \\sum_i \\mathbb{P}(E_i).\\]\n\\(\\mathbb{P}(S) = 1\\)\n\nThanks to the constraints, even if I only specify a few known probabilities I can recover many other ones mathematically/computationally.",
    "crumbs": [
      "Probability essentials",
      "Axioms of probability"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic04_pmfs.html",
    "href": "w01_discrete_inference/topic04_pmfs.html",
    "title": "Probability mass functions",
    "section": "",
    "text": "Probability Mass Function (PMF):\n\ndenoted by \\(p\\) (not to be confused by \\(\\mathbb{P}\\)),\ndefined by: \\[p(x) = \\mathbb{P}(X = x).\\]\nIf there are several random variables, we use a subscript to disambiguate the PMFS, e.g.,\n\n\\(p_X\\) for the PMF of the latent random variable,\n\\(p_Y\\) for the PMF of the observed random variable.",
    "crumbs": [
      "Probability essentials",
      "Probability mass functions"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic04_pmfs.html#definition",
    "href": "w01_discrete_inference/topic04_pmfs.html#definition",
    "title": "Probability mass functions",
    "section": "",
    "text": "Probability Mass Function (PMF):\n\ndenoted by \\(p\\) (not to be confused by \\(\\mathbb{P}\\)),\ndefined by: \\[p(x) = \\mathbb{P}(X = x).\\]\nIf there are several random variables, we use a subscript to disambiguate the PMFS, e.g.,\n\n\\(p_X\\) for the PMF of the latent random variable,\n\\(p_Y\\) for the PMF of the observed random variable.",
    "crumbs": [
      "Probability essentials",
      "Probability mass functions"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic04_pmfs.html#sec-simulate-pmf",
    "href": "w01_discrete_inference/topic04_pmfs.html#sec-simulate-pmf",
    "title": "Probability mass functions",
    "section": "Simulation/sampling from a PMF",
    "text": "Simulation/sampling from a PMF\n\nIn R\n\nrequire(extraDistr)\n\nLoading required package: extraDistr\n\n# 10 coin flips:\nrbern(10, prob=0.5)\n\n [1] 1 1 0 1 1 0 0 0 1 1\n\n# two dice rolls\nrdunif(2, min=1, max=6)\n\n[1] 3 6\n\n\n\n\nHow does it work?\n\nThink of the green lines in the uniform PMF as “sticks” with “labels.”\n\nThe “labels” are the different realization, e.g. 1, 2, 3, …, 6.\n\nPlace the six sticks in the interval \\([0, 1]\\) so that they do not overlap.\nSample a uniform real number in \\([0, 1]\\)\n\nin R: runif(1)\n\nThe uniform falls in exactly one of the sticks.\nReturn the label of that stick.\n\n\n\nMathematical explanation\nThe above “stick-based” algorithm can be implemented using the cumulative distribution function and a generalization of its inverse known as the quantile function.\nCumulative distribution function (CDF): \\(F(x) = \\mathbb{P}(X \\le x).\\)\nQuantile function: \\(Q(u) = \\inf\\{x \\in \\mathbb{R}: u \\le F(x)\\}\\).\nThen the “stick-based” algorithm can be written as:\n\n\\(U \\sim {\\mathrm{Unif}}[0, 1]\\)\nReturn \\(Q(U)\\).",
    "crumbs": [
      "Probability essentials",
      "Probability mass functions"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic04_pmfs.html#plotting-pmfs-in-r",
    "href": "w01_discrete_inference/topic04_pmfs.html#plotting-pmfs-in-r",
    "title": "Probability mass functions",
    "section": "Plotting PMFs in R",
    "text": "Plotting PMFs in R\nHere is an example of how to plot PMFs in R:\n\nrealizations &lt;- 0:20\n\nplot(realizations, dbinom(realizations, size=20, prob=.3), type='h')\n\n\n\n\n\n\n\n\nSome explanations:\n\nHere dbinom is the R function for the PMF of a binomial (R uses the prefix d___ for densities and PMFs).\nWe use the fact that many functions in R such as this one are vectorized, i.e. the normal PMF function takes a single point \\(x\\) and output \\(p(x)\\) where \\(p\\) is the PMF; the vectorized version takes vector \\((x_1, x_2, \\dots)\\) and returns \\((p(x_1), p(x_2), \\dots)\\).\nThe argument type = 'h' instructs the plot function to make the plot “histogram”-like.",
    "crumbs": [
      "Probability essentials",
      "Probability mass functions"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic07_conditional.html",
    "href": "w01_discrete_inference/topic07_conditional.html",
    "title": "Conditioning",
    "section": "",
    "text": "Intuition on conditioning\nA conditional probability is a probability.\n\n\n\n\n\nConditioning is the workhorse of Bayesian inference!\n\nUsed to define models (as when we assigned probabilities to edges of a decision tree)\nAnd soon, to gain information on latent variables given observations.",
    "crumbs": [
      "Probability essentials",
      "Conditioning"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic07_conditional.html#outline",
    "href": "w01_discrete_inference/topic07_conditional.html#outline",
    "title": "Conditioning",
    "section": "",
    "text": "Intuition on conditioning\nA conditional probability is a probability.\n\n\n\n\n\nConditioning is the workhorse of Bayesian inference!\n\nUsed to define models (as when we assigned probabilities to edges of a decision tree)\nAnd soon, to gain information on latent variables given observations.",
    "crumbs": [
      "Probability essentials",
      "Conditioning"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic07_conditional.html#conditioning-as-belief-update",
    "href": "w01_discrete_inference/topic07_conditional.html#conditioning-as-belief-update",
    "title": "Conditioning",
    "section": "Conditioning as belief update",
    "text": "Conditioning as belief update\nKey concept: Bayesian methods use probabilities to encode beliefs.\n\nWe will explore this perspective in much more details next week.",
    "crumbs": [
      "Probability essentials",
      "Conditioning"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic07_conditional.html#a-conditional-probability-is-a-probability",
    "href": "w01_discrete_inference/topic07_conditional.html#a-conditional-probability-is-a-probability",
    "title": "Conditioning",
    "section": "A conditional probability is a probability",
    "text": "A conditional probability is a probability\nThe “updated belief” interpretation highlights the fact that we want the result of the conditioning procedure, \\(\\mathbb{P}(\\cdot | E)\\) to be a probability when viewed as a function of the first argument for any fixed \\(E\\).",
    "crumbs": [
      "Probability essentials",
      "Conditioning"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic07_conditional.html#intuition-behind-conditioning",
    "href": "w01_discrete_inference/topic07_conditional.html#intuition-behind-conditioning",
    "title": "Conditioning",
    "section": "Intuition behind conditioning",
    "text": "Intuition behind conditioning\n\n\n\n\n\n\n\nFor a query even \\(A\\), what should be the updated probability?\nWe want to remove from \\(A\\) all the outcomes that are not compatible with the new information \\(E\\). How?\n\nTake the intersection: \\(A \\cap E\\)\nWe also want: \\(\\mathbb{P}(S | E) = 1\\) (last section)\nHow? Renormalize: \\[\\mathbb{P}(A | E) = \\frac{\\mathbb{P}(A \\cap E)}{\\mathbb{P}(E)}\\]\nIntersection can also be denoted using a comma, for example \\(\\mathbb{P}(A \\cap E) = \\mathbb{P}(A, E)\\)",
    "crumbs": [
      "Probability essentials",
      "Conditioning"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html",
    "href": "w01_discrete_inference/topic08_chain.html",
    "title": "Chain rule",
    "section": "",
    "text": "Mathematical statement\nVisual intuition on a decision tree\nSpecial names for the pieces of chain rule (joint and conditional PMFs)\nConditional independence\n\n\n\n\nThe chain rule allows us to compute a probability that the forward sampling function takes a given path.\nThe chain rule seem innocent but is used heavily in Bayesian statistics. It is also the building block for Bayes rule.",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#outline",
    "href": "w01_discrete_inference/topic08_chain.html#outline",
    "title": "Chain rule",
    "section": "",
    "text": "Mathematical statement\nVisual intuition on a decision tree\nSpecial names for the pieces of chain rule (joint and conditional PMFs)\nConditional independence\n\n\n\n\nThe chain rule allows us to compute a probability that the forward sampling function takes a given path.\nThe chain rule seem innocent but is used heavily in Bayesian statistics. It is also the building block for Bayes rule.",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#proposition",
    "href": "w01_discrete_inference/topic08_chain.html#proposition",
    "title": "Chain rule",
    "section": "Proposition",
    "text": "Proposition\nIf \\(E_1\\) and \\(E_2\\) are any events, \\[\\mathbb{P}(E_1, E_2) = \\mathbb{P}(E_1) \\mathbb{P}(E_2 | E_1).\\]\nThis is true in any order, i.e. we also have \\(\\mathbb{P}(E_1, E_2) = \\mathbb{P}(E_2) \\mathbb{P}(E_1 | E_2)\\).",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#sec-chain-rule",
    "href": "w01_discrete_inference/topic08_chain.html#sec-chain-rule",
    "title": "Chain rule",
    "section": "Generalization",
    "text": "Generalization\nFor any events \\(E_1, E_2, E_3 \\dots\\),\n\\[\\mathbb{P}(E_1, E_2, E_3 \\dots) = \\mathbb{P}(E_1) \\mathbb{P}(E_2 | E_1) \\mathbb{P}(E_3 | E_1, E_2) \\dots.\\]",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#visual-intuition",
    "href": "w01_discrete_inference/topic08_chain.html#visual-intuition",
    "title": "Chain rule",
    "section": "Visual intuition",
    "text": "Visual intuition\nChain rule: the probability of a node is the product of the edge labels on the path to the root.\n\n\n\n\n\n\nflowchart TD\nS__and__X_0 -- 1.0 --&gt; S__and__X_0__and__Y1_false[\"Y1=false\"]\nS__and__X_2__and__Y1_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS -- 0.33 --&gt; S__and__X_0[\"X=0\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS -- 0.33 --&gt; S__and__X_1[\"X=1\"]\nS__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_false[\"Y1=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS__and__X_0__and__Y1_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true[\"Y2=true\"]\nS__and__X_2 -- 1.0 --&gt; S__and__X_2__and__Y1_true[\"Y1=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_true[\"Y1=true\"]\nS -- 0.33 --&gt; S__and__X_2[\"X=2\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_2__and__Y1_true__and__Y2_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]\nstyle S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true fill:#f9f,stroke:#333,stroke-width:4px",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#poll-what-is-the-probability-of-the-node-in-red",
    "href": "w01_discrete_inference/topic08_chain.html#poll-what-is-the-probability-of-the-node-in-red",
    "title": "Chain rule",
    "section": "Poll: what is the probability of the node in red?",
    "text": "Poll: what is the probability of the node in red?\n\n1/2\n1/4\n1/8\n1/24\nNone of the above\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nMultiplying the four edge leading to the node we get: \\(1/2 \\cdot 1/2 \\cdot 1/2 \\cdot 1/3 = 1/24\\).",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#poll-what-is-the-event-corresponding-to-that-node",
    "href": "w01_discrete_inference/topic08_chain.html#poll-what-is-the-event-corresponding-to-that-node",
    "title": "Chain rule",
    "section": "Poll: what is the event corresponding to that node?",
    "text": "Poll: what is the event corresponding to that node?\n\n\\((Y_3 = 1)\\)\n\\((Y_3 = 1, Y_2 = 1)\\)\n\\((Y_3 = 1, Y_2 = 1)\\)\n\\((Y_3 = 1, Y_2 = 1, Y_1 = 1)\\)\n\\((Y_3 = 1, Y_2 = 1, Y_1 = 1, X = 1)\\)\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nRecall that the event is the intersection of all node labels to the root, hence the event is \\((Y_3 = 1, Y_2 = 1, Y_1 = 1, X = 1)\\).\nThe calculation we did visually in the previous clicker question is mathematically: \\[\\mathbb{P}(Y_3 = 1, Y_2 = 1, Y_1 = 1, X = 1) = \\mathbb{P}(X = 1) \\mathbb{P}(Y_1 | X = 1) \\mathbb{P}(Y_2 | X = 1, Y_1 = 1) \\mathbb{P}(Y_3 = 1 | X = 1, Y_1 = 1, Y_2 = 1).\\]",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#joint-pmf",
    "href": "w01_discrete_inference/topic08_chain.html#joint-pmf",
    "title": "Chain rule",
    "section": "Joint PMF",
    "text": "Joint PMF\nWe will often encounter expression of the form of a conjunction (intersection/and) of several variables. A handy notation for that is the joint PMF\nFor example, here is the joint PMF of \\((X, Y_1, Y_2, Y_3)\\):\n\\[p(x, y_1, y_2, y_3) = \\mathbb{P}(X = x, Y_1 = y_1, Y_2 = y_2, Y_3 = y_3).\\]\nSometimes we put the random variables in question as subscript, for example \\(p_{X, Y_1}(x, y)\\) for the joint PMF of \\(X\\) and \\(Y_1\\).",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#conditional-pmf",
    "href": "w01_discrete_inference/topic08_chain.html#conditional-pmf",
    "title": "Chain rule",
    "section": "Conditional PMF",
    "text": "Conditional PMF\nSimilarly, here is an example of a conditional PMF: \\[p_{Y_1|X}(y | x) = \\mathbb{P}(Y_1 = y | X = x).\\]",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic08_chain.html#sec-conditional-independence",
    "href": "w01_discrete_inference/topic08_chain.html#sec-conditional-independence",
    "title": "Chain rule",
    "section": "Conditional independence",
    "text": "Conditional independence\nThe model was specified as:\n\\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\] i.e. with \\(\\mathbb{P}(X = x)\\) and \\(\\mathbb{P}(Y_i = y | X = x)\\) for all \\(x\\) and \\(y\\).\nQuestion: how did we go from \\(\\mathbb{P}(Y_2 | X = 1, Y_1 = 1)\\) (in our chain rule computation) to \\(\\mathbb{P}(Y_2 | X = 1)\\) (model specification)?\nDefinition: \\(V\\) and \\(W\\) are conditionally independence given \\(Z\\) if \\[\\mathbb{P}(V = v, W = w | Z = z) = \\mathbb{P}(V = v | Z = z) \\mathbb{P}(W = w | Z = z).\\]\nExercise: show the above definition is equivalent to:\n\\[\\mathbb{P}(V = v | W = w, Z = z) = \\mathbb{P}(V = v | Z = z).\\]",
    "crumbs": [
      "Probability essentials",
      "Chain rule"
    ]
  },
  {
    "objectID": "w04_glms/topic04_classification.html",
    "href": "w04_glms/topic04_classification.html",
    "title": "Bernoulli regression",
    "section": "",
    "text": "A first example of a Bayesian model based on a linear model and a Bernoulli likelihood.\nPrior construction via prior predictive distribution.\nApproximation of the posterior using a PPL.\nVisualizing a posterior distribution over functions.\n\n\n\n\n\nThis is our first example of a Bayesian General Linear Model (GLM).\nGLMs are the probably the most common models.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bernoulli regression"
    ]
  },
  {
    "objectID": "w04_glms/topic04_classification.html#outline",
    "href": "w04_glms/topic04_classification.html#outline",
    "title": "Bernoulli regression",
    "section": "",
    "text": "A first example of a Bayesian model based on a linear model and a Bernoulli likelihood.\nPrior construction via prior predictive distribution.\nApproximation of the posterior using a PPL.\nVisualizing a posterior distribution over functions.\n\n\n\n\n\nThis is our first example of a Bayesian General Linear Model (GLM).\nGLMs are the probably the most common models.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bernoulli regression"
    ]
  },
  {
    "objectID": "w04_glms/topic04_classification.html#sec-data",
    "href": "w04_glms/topic04_classification.html#sec-data",
    "title": "Bernoulli regression",
    "section": "Example",
    "text": "Example\n\nThe Ariane 1 is an expandable rocket launched 11 times between 1979 and 1986.\nIt failed 2 times and was successful the 9 other launches.\nSo far our models treat the launches as iid given the success probability \\(p\\).\nCan we do better?\n\n\n\n\n\nsource(\"../../solutions/simple.R\")\nsource(\"../blocks/simple_utils.R\")\nsuppressPackageStartupMessages(require(\"dplyr\"))\nset.seed(1)\n\ndf = read.csv(\"../data/launches.csv\") %&gt;% filter(LV.Type == \"Ariane 1\")\nsuccess_indicators = df$Suc_bin\nrmarkdown::paged_table(df)\n\n\n  \n\n\n\n\nplot(success_indicators, xlab = \"Launch index i\")\n\n\n\n\n\n\n\n\n\nFrom this “Exploratory Data Analysis” (EDA), it seems plausible that the success probability is increasing with time.\nMatches with intuition: after a failure, some corrections are made.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bernoulli regression"
    ]
  },
  {
    "objectID": "w04_glms/topic04_classification.html#sec-model",
    "href": "w04_glms/topic04_classification.html#sec-model",
    "title": "Bernoulli regression",
    "section": "Building a better model",
    "text": "Building a better model\n\nEach observation is binary, so the likelihood still has to be Bernoulli.\n\nWe will denote its parameter by \\(\\theta \\in [0, 1]\\).\n\nWhat we will change is the prior.\nOld model: \\(\\theta\\) is shared by all launches (“constant over the launch index” \\(i \\in \\{1, 2, \\dots, 11\\}\\))\nNew model: \\(\\theta\\) changes from one launch to the next.\n\ni.e., \\(\\theta\\) is a function of the index \\(i \\in \\{1, 2, \\dots, 11\\}\\), denoted \\(\\theta(i)\\).\n\nQuestion: what kind of function should we start with?\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nGeneral modelling principle: start with something simple!\nIn our context: start with a linear function.\n\n\n\n\nStructure of the model\n\nWe need to build a prior over linear functions.\nRecall: enough to describe how to forward simulate a dataset.\nForward simulation process:\n\nsimulate an intercept,\nsimulate a slope,\nthis determines \\(\\theta(i)\\) for each \\(i \\in \\{1, 2, \\dots, 11\\}\\).\nSimulate \\(y_i \\sim {\\mathrm{Bern}}(\\theta(i))\\) independently but not identically.\n\nI.e. we have reduce the problem to that of sampling two real numbers.\n\nReasonable prior for a first try: the normal distribution.\n\n\n\n\nPrior (first attempt)\nLet us draw one random linear function:\n\nMath: (not yet final) \\[\\begin{align*}\n\\text{slope} &\\sim \\mathcal{N}(0, 1) \\\\\n\\text{intercept} &\\sim \\mathcal{N}(0, 1) \\\\\n\\theta(i) &= \\text{slope} \\cdot i + \\text{intercept}\n\\end{align*}\\]\nForward simulation code: (not yet final)\n\n\nset.seed(1)\nplot(success_indicators, ylab = \"success probability\", xlab = \"Launch index i\")\nxs = 1:length(success_indicators)\nintercept = simulate(Norm(0, 1))\nslope     = simulate(Norm(0, 1))\n\nlines(intercept + slope * xs)\n\n\n\n\n\n\n\n\nWhat is the problem in the above?\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n\nThe function \\(\\theta(i)\\) can take values smaller than zero or greater than one.\nThis creates problem when we feed the parameter to the Bernoulli, which expects a number between 0 and 1.\n\n\n\n\nFix:\n\nwe cannot use just a linear function…\n… instead we can compose a linear function with the logistic or sigmoid function.\n\nLogistic function: maps real numbers \\(r \\in (-\\infty, \\infty)\\) into \\((0, 1)\\).\nMath: \\[\\text{logistic}(r) = \\frac{1}{1 + e^{-r}}.\\]\nIn R: plogis(r).\n\n\n\nrs = seq(-5, 5, 0.01)\nplot(rs, plogis(rs), type = 'l', xlab = \"r\", ylab = \"logistic(r)\")\n\n\n\n\n\n\n\n\n\n\nPrior (second, final attempt)\n\nMath: \\[\\begin{align*}\n\\text{slope} &\\sim \\mathcal{N}(0, 1) \\\\\n\\text{intercept} &\\sim \\mathcal{N}(0, 1) \\\\\n\\theta(i) &= \\text{logistic}(\\text{slope} \\cdot i + \\text{intercept})\n\\end{align*}\\]\nForward simulation code:\n\n\nset.seed(1)\nplot(success_indicators, ylab = \"success probability\", xlab = \"Launch index i\")\nxs = 1:length(success_indicators)\nintercept = simulate(Norm(0, 1))\nslope     = simulate(Norm(0, 1))\n\nlines(plogis(intercept + slope * xs))",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bernoulli regression"
    ]
  },
  {
    "objectID": "w04_glms/topic04_classification.html#prior-predictive",
    "href": "w04_glms/topic04_classification.html#prior-predictive",
    "title": "Bernoulli regression",
    "section": "Prior predictive",
    "text": "Prior predictive\nLet us repeat what we did in the last section 50 times to see several draws from the prior at once (using alpha to make the lines translucent):\n\nset.seed(1)\nplot(success_indicators, ylab = \"success probability\", xlab = \"Launch index i\")\nxs = 1:length(success_indicators)\n\nfor (i in 1:50) {\n  intercept = simulate(Norm(0, 1))\n  slope     = simulate(Norm(0, 1))\n  lines(plogis(intercept + slope * xs), col = rgb(red = 0, green = 0, blue = 0, alpha = 0.5))\n}\n\n\n\n\n\n\n\n\n\nHard to get intuition about a prior by just staring at the mathematical formulas.\nSimulating from the prior can help figuring out if the prior is reasonable or not.\n\nThis is known as the prior predictive.\n\nExploration:\n\nso far I used a mean of zero and standard deviation of 1 for the slope and intercept priors.\nLet us try a prior that is more “vague”, with standard deviation of 10 for both the slope and intercept priors:\n\n\n\nset.seed(1)\nplot(success_indicators, ylab = \"success probability\", xlab = \"Launch index i\")\nxs = 1:length(success_indicators)\n\nfor (i in 1:50) {\n  intercept = simulate(Norm(0, 10))\n  slope     = simulate(Norm(0, 10))\n  lines(plogis(intercept + slope * xs), col = rgb(red = 0, green = 0, blue = 0, alpha = 0.5))\n}",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bernoulli regression"
    ]
  },
  {
    "objectID": "w04_glms/topic04_classification.html#posterior-distribution",
    "href": "w04_glms/topic04_classification.html#posterior-distribution",
    "title": "Bernoulli regression",
    "section": "Posterior distribution",
    "text": "Posterior distribution\n\nIn this week’s exercise, you will implement the model described above in simPPLe.\nHere is a peak of the posterior distribution you should obtain:\n\n\nsource(\"../../solutions/sol04_logistic_regression.R\")\n\nposterior = posterior_particles(logistic_regression, 1000)\nweighted_scatter_plot(posterior, plot_options = list(xlab=\"intercept parameter\", ylab=\"slope parameter\"))\n\n\n\n\n\n\n\n\n\nAgain, this is a bit hard to interpret.\nLet us plot similarly to what we did with the prior predictive:\n\nFor each sample \\(x^{(m)}= (\\text{intercept}^{(m)}, \\text{slope}^{(m)})\\) with weight \\(w^{(m)}\\),\nDraw the curve \\(\\text{logistic}(\\text{slope}^{(m)}\\cdot i + \\text{intercept}^{(m)})\\)…\nwith alpha value (transparency) proportional to the corresponding weight \\(w^{(m)}\\).\n\n\n\nset.seed(1)\nplot(success_indicators, ylab = \"success probability\", xlab = \"Launch index i\")\nxs = 1:length(success_indicators)\n\nsamples = posterior$samples \nnorm_weights = posterior$weights / sum(posterior$weights)\n\nfor (i in 1:nrow(samples)) {\n  intercept = samples[i, 1]\n  slope     = samples[i, 2]\n  pr = norm_weights[i]\n  lines(plogis(intercept + slope * xs), col = rgb(red = 0, green = 0, blue = 0, alpha = pr*20))\n}",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bernoulli regression"
    ]
  },
  {
    "objectID": "w04_glms/topic04_classification.html#terminology",
    "href": "w04_glms/topic04_classification.html#terminology",
    "title": "Bernoulli regression",
    "section": "Terminology",
    "text": "Terminology\nThe model we just reviewed is an instance of Bayesian logistic regression, a method for classification.\nSome terminology from classification:\n\noutput variables: instances of which we try to “predict”\n\nalso known as “target”, “label”, “predicted variable”, “regressand”, …\nsometimes observed (“training instances”), sometimes unobserved (“test instances”)\nin our example?\n\ninput variables: what we use as the basis of each prediction\n\nalso known as “independent variables”, “covariates”, “predictor”, “regressors”, “feature”,..\ntypically always observed (both at training and test time)\n\nparameters: auxiliary quantities that encode a function mapping inputs to (information on) output.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bernoulli regression"
    ]
  },
  {
    "objectID": "w04_glms/topic02_bivariate.html",
    "href": "w04_glms/topic02_bivariate.html",
    "title": "Bivariate posteriors",
    "section": "",
    "text": "Posterior distribution on two parameters (bivariate).\n\n\n\n\nThere is typically more than one unknown variables. Going from one unknown to two unknowns is the biggest leap.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bivariate posteriors"
    ]
  },
  {
    "objectID": "w04_glms/topic02_bivariate.html#outline",
    "href": "w04_glms/topic02_bivariate.html#outline",
    "title": "Bivariate posteriors",
    "section": "",
    "text": "Posterior distribution on two parameters (bivariate).\n\n\n\n\nThere is typically more than one unknown variables. Going from one unknown to two unknowns is the biggest leap.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bivariate posteriors"
    ]
  },
  {
    "objectID": "w04_glms/topic02_bivariate.html#example",
    "href": "w04_glms/topic02_bivariate.html#example",
    "title": "Bivariate posteriors",
    "section": "Example",
    "text": "Example\nWe will revisit the rocket comparison problem from the first week:\n\nWould you rather get strapped to…\n\n“shiny rocket” (option A): 1 success, 0 failures\n“rugged rocket” (option B): 98 successes, 2 failures\n\n\n\n\n\n\nIf you are sick of hearing about rocket, here is an alternative interpretation:\n\nImagine you work for Google and serve website ad banners.\nA client gives you two designs for the ad banner: A and B.\nYou will serve them to web visitors and the objective is to maximize the number of clicks.\n\nSuccess: a user clicked (1).\nFailure: a user did not click (0).\n\nTraining data:\n\nVersion A: 1 success, 0 failures.\nVersion B: 98 successes, 2 failures\n\nYou can only show the ad one more time to a user (client budget almost exhausted).\n\nShould you show A or B?\n\nThis is a basic example of what is known as A/B testing.\n\n\nModel: for \\(j \\in \\{A, B\\}\\), independently,\n\\[\\begin{align*}\np_j &\\sim {\\mathrm{Unif}}(0, 1) \\\\\ny_j | p_j &\\sim {\\mathrm{Binom}}(n_j, p_j),\n\\end{align*}\\]\nwhere:\n\n\\(p_j\\) are the success probabilities\n\\(n_j\\) is the number of times you showed \\(j\\)\n\\(y_j\\) is the number of clicks on \\(j\\).\n\nQuestion:\nHow to mathematically encode the questions:\n\n“Would you rather get strapped to…”\n“Should you show A or B?”\n\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(\\mathbb{P}(p_A = 1)\\)\n\\(\\mathbb{P}(p_A = 1 | Y = y)\\)\n\\(\\mathbb{P}(p_A &gt; p_B)\\)\n\\(\\mathbb{P}(p_A &gt; p_B | Y = y)\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n\\(\\mathbb{P}(p_A &gt; p_B | Y = y)\\): in words, is the chance of success of A greater than B?\n\n\n\nModify the code below to approximate that probability.\nsource(\"../../solutions/simple.R\")\nset.seed(1)\n\nbivariate = function() {\n  \n  p_A = simulate(Beta(1, 1))\n  observe(1, Binom(size = 1, prob = p_A)) \n  \n  # add the part of the model describing p_B (prior and likelihood)\n  \n  return # what is the \"test function\"?\n}\nposterior(bivariate, 10000)\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(\\approx 0.1\\)\n\\(\\approx 0.3\\)\n\\(\\approx 0.6\\)\n\\(\\approx 0.9\\)\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n\nsource(\"../../solutions/simple.R\")\nset.seed(1)\n\nbivariate = function() {\n  \n  p_A = simulate(Beta(1, 1))\n  observe(1, Binom(size = 1, prob = p_A)) \n  \n  p_B = simulate(Beta(1, 1))\n  observe(98, Binom(size = 100, prob = p_B)) \n  \n  return(ifelse(p_A &gt; p_B, 1, 0))\n}\nposterior(bivariate, 10000)\n\n[1] 0.06909026",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bivariate posteriors"
    ]
  },
  {
    "objectID": "w04_glms/topic02_bivariate.html#visualization-of-a-bivariate-joint-posterior",
    "href": "w04_glms/topic02_bivariate.html#visualization-of-a-bivariate-joint-posterior",
    "title": "Bivariate posteriors",
    "section": "Visualization of a bivariate joint posterior",
    "text": "Visualization of a bivariate joint posterior\nLet us get more insight on joint posterior distributions (posterior over two variables).\nTo do so, we use visualizations where the x-axis is the first parameter (here \\(p_A\\)) and the y-axis is the second parameter (here \\(p_B\\)).\n\n# This contains useful functions to visualize the output of simPPLe:\nsource(\"../blocks/simple_utils.R\")\n\nbivariate_pair = function() {\n  \n  p_A = simulate(Beta(1, 1))\n  observe(1, Binom(size = 1, prob = p_A)) \n  \n  p_B = simulate(Beta(1, 1))\n  observe(98, Binom(size = 100, prob = p_B)) \n  \n  # We modify the above to return a vector containing both parameters\n  c(p_A, p_B)\n}\n\n# To compute the plot, we need the list of samples and weights (\"particles\"), i.e. more details compared to posterior()\n# This is what posterior_particles accomplishes\nparticles = posterior_particles(bivariate_pair, 10000)\n\n# Now we use these to create the plot below\nweighted_scatter_plot(particles, plot_options = list(xlab=\"p_A\", ylab=\"p_B\"))\n\nxaxis = seq(0, 1, 0.01)\nlines(xaxis, xaxis)\n\n\n\n\n\n\n\n\n\nEach point is a sample produced by SNIS, \\(x^{(m)}= (p_A^{(m)}, p_B^{(m)})\\).\nWe encode its associated weight \\(w^{(m)}\\) by the transparency (alpha) of the point.\n\nQuestion: What region of integration should you use to compute \\(\\mathbb{P}(p_A &gt; p_B | Y = y)\\)?\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n◤\n◥\n◢\n◣\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n◢",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Bivariate posteriors"
    ]
  },
  {
    "objectID": "w04_glms/topic01_simPPLe.html",
    "href": "w04_glms/topic01_simPPLe.html",
    "title": "simPPLe",
    "section": "",
    "text": "Last week’s Q2 exercise solution.\n\n\n\n\nWe will use simPPLe this week to do probabilistic modelling.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "simPPLe"
    ]
  },
  {
    "objectID": "w04_glms/topic01_simPPLe.html#outline",
    "href": "w04_glms/topic01_simPPLe.html#outline",
    "title": "simPPLe",
    "section": "",
    "text": "Last week’s Q2 exercise solution.\n\n\n\n\nWe will use simPPLe this week to do probabilistic modelling.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "simPPLe"
    ]
  },
  {
    "objectID": "w04_glms/topic01_simPPLe.html#background",
    "href": "w04_glms/topic01_simPPLe.html#background",
    "title": "simPPLe",
    "section": "Background",
    "text": "Background\nIf you missed Tuesday’s lecture last week, make sure to read the introduction to PPLs.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "simPPLe"
    ]
  },
  {
    "objectID": "w04_glms/topic01_simPPLe.html#setting-up-simpple-on-your-computer",
    "href": "w04_glms/topic01_simPPLe.html#setting-up-simpple-on-your-computer",
    "title": "simPPLe",
    "section": "Setting up simPPLe on your computer",
    "text": "Setting up simPPLe on your computer\n\nLet us combine the “scaffold” files and the answer of last week’s Q2 into one file. Copy paste the code below into a file called simple.R:\n\n\n\nsimple.R\n\n###### solution\n\nposterior = function(ppl_function, number_of_iterations) {\n  numerator = 0.0\n  denominator = 0.0\n  for (i in 1:number_of_iterations) {\n    weight &lt;&lt;- 1.0\n    g_i = ppl_function()\n    numerator = numerator + weight * g_i\n    denominator = denominator + weight\n  }\n  return(numerator/denominator)\n}\n\n###### contents of the scaffold\n\nsuppressPackageStartupMessages(library(distr))\n\n## Utilities to make the distr library a bit nicer to use\n\np &lt;- function(distribution, realization) {\n  d(distribution)(realization) # return the PMF or density \n}\n\nBern = function(probability_to_get_one) {\n  DiscreteDistribution(supp = 0:1, prob = c(1-probability_to_get_one, probability_to_get_one))\n}\n\n## Key functions called by simPPLe programs\n\n# Use simulate(distribution) for unobserved random variables\nsimulate &lt;- function(distribution) {\n  r(distribution)(1) # sample once from the given distribution\n}\n\n# Use observe(realization, distribution) for observed random variables\nobserve = function(realization, distribution) {\n  # `&lt;&lt;-` lets us modify variables that live in the global scope from inside a function\n  weight &lt;&lt;- weight * p(distribution, realization) \n}\n\n\nThis way, you can now load simPPLe by loading simple.R into your session (note: in the code below replace ../../solutions/ by the path to the file you just created)\n\nsource(\"../../solutions/simple.R\")\n\n# define your model as a function, e.g. my_function\n\n# call: posterior(my_function, 100) to approximate posterior E[my_function | observations]",
    "crumbs": [
      "The joy of probabilistic modelling",
      "simPPLe"
    ]
  },
  {
    "objectID": "w04_glms/topic01_simPPLe.html#testing",
    "href": "w04_glms/topic01_simPPLe.html#testing",
    "title": "simPPLe",
    "section": "Testing",
    "text": "Testing\nI will start this Tuesday’s lecture with the following simPPLe test (a continuous version of the rocket model): (note: in the code below replace ../../solutions/ by the path to the file you just created)\nsource(\"../../solutions/simple.R\")\n\nset.seed(1)\n\ndata = rep(0, 4) \n\n# simPPLe's description of our \"bag of coins\" example\nbeta_binomial = function() {\n  \n  # Similar to forward sampling, but use 'observe' when the variable is observed\n  p = simulate(Beta(1, 1))\n  for (i in seq_along(data)) { \n    observe(data[i], Bern(p)) \n  }\n  \n  # return the test function, here the parameter p\n  return(p)\n}\n\nposterior(beta_binomial, 100)\n\nWhat is the output?\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(0.0010394\\)\n\\(0.0194394\\)\n\\(0.0826293\\)\n\\(0.1728016\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n\\(0.1728016\\).",
    "crumbs": [
      "The joy of probabilistic modelling",
      "simPPLe"
    ]
  },
  {
    "objectID": "w04_glms/topic03_normal.html",
    "href": "w04_glms/topic03_normal.html",
    "title": "Normal distributions",
    "section": "",
    "text": "Quick review of the normal distribution.\nDifferent parameterizations.\n\n\n\n\nThe normal distribution is often used in Bayesian analysis when one needs a prior over an unknown \\(x\\) such that \\(x \\in (-\\infty, \\infty) = \\mathbb{R}\\).",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Normal distributions"
    ]
  },
  {
    "objectID": "w04_glms/topic03_normal.html#outline",
    "href": "w04_glms/topic03_normal.html#outline",
    "title": "Normal distributions",
    "section": "",
    "text": "Quick review of the normal distribution.\nDifferent parameterizations.\n\n\n\n\nThe normal distribution is often used in Bayesian analysis when one needs a prior over an unknown \\(x\\) such that \\(x \\in (-\\infty, \\infty) = \\mathbb{R}\\).",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Normal distributions"
    ]
  },
  {
    "objectID": "w04_glms/topic03_normal.html#examples-of-normal-densities",
    "href": "w04_glms/topic03_normal.html#examples-of-normal-densities",
    "title": "Normal distributions",
    "section": "Examples of normal densities",
    "text": "Examples of normal densities",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Normal distributions"
    ]
  },
  {
    "objectID": "w04_glms/topic03_normal.html#parameterizations",
    "href": "w04_glms/topic03_normal.html#parameterizations",
    "title": "Normal distributions",
    "section": "Parameterizations",
    "text": "Parameterizations\n\nThere are different conventions to measure the spread.\n\nStandard deviation \\(\\sigma\\).\nVariance, \\(\\sigma^2\\).\nPrecision, \\(\\tau = 1/\\sigma^2\\).\n\nKeep that in mind as different languages will use different conventions!\nStandard deviation is the most intuitive:\n\nit is the width of the bell,\nthe only one that has the same units as \\(x\\) (e.g. if \\(x\\) is in meters, so is \\(\\sigma\\)).",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Normal distributions"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic09_bayes.html",
    "href": "w01_discrete_inference/topic09_bayes.html",
    "title": "Bayes rule",
    "section": "",
    "text": "Bayes rule for discrete models\nVisual intuition\n\n\n\n\nFirst example of computing a posterior distribution, a key concept in Bayesian statistics.",
    "crumbs": [
      "Probability essentials",
      "Bayes rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic09_bayes.html#outline",
    "href": "w01_discrete_inference/topic09_bayes.html#outline",
    "title": "Bayes rule",
    "section": "",
    "text": "Bayes rule for discrete models\nVisual intuition\n\n\n\n\nFirst example of computing a posterior distribution, a key concept in Bayesian statistics.",
    "crumbs": [
      "Probability essentials",
      "Bayes rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic09_bayes.html#running-example",
    "href": "w01_discrete_inference/topic09_bayes.html#running-example",
    "title": "Bayes rule",
    "section": "Running example",
    "text": "Running example\n\nImagine a bag with 3 coins each with a different probability parameter \\(p\\)\nCoin \\(i\\in \\{0, 1, 2\\}\\) has bias \\(i/2\\)—in other words:\n\nFirst coin: bias is \\(0/2 = 0\\) (i.e. both sides are “heads”, \\(p = 0\\))\nSecond coin: bias is \\(1/2 = 0.5\\) (i.e. standard coin, \\(p = 1/2\\))\nThird coin: bias is \\(2/2 = 1\\) (i.e. both sides are “tails”, \\(p = 1\\))\n\n\n\n\n\n\nConsider the following two steps sampling process\n\nStep 1: pick one of the three coins, but do not look at it!\nStep 2: flip the coin 4 times\n\nMathematically, this probability model can be written as follows: \\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\tag{1}\\]\n\nConsider the second question in the first exercise:\nSuppose now that you observe the outcome of the 4 coin flips, but not the type of coin that was picked. Say you observe: “heads”, “heads”, “heads”, “heads” = [0, 0, 0, 0]. Given that observation, what is the probability that you picked the standard coin (i.e., the one with \\(p = 1/2\\))?",
    "crumbs": [
      "Probability essentials",
      "Bayes rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic09_bayes.html#strategy",
    "href": "w01_discrete_inference/topic09_bayes.html#strategy",
    "title": "Bayes rule",
    "section": "Strategy",
    "text": "Strategy\nDenote the observation by \\(y_{1:4} = (0, 0, 0, 0)\\). In the rest of the argument we will always fix \\(y\\) to that value.\n\nAttack the more general problem \\(\\pi(x) = \\mathbb{P}(X = x | Y_{1:4} = y_{1:4})\\) for all hypotheses \\(x \\in \\{0, 1, 2\\}\\) instead of just the requested \\(x = 1\\) (corresponding to the “standard coin”).\nBy definition of conditioning: \\[\\pi(x) = \\frac{\\mathbb{P}(X = x, Y_{1:4} = y_{1:4})}{\\mathbb{P}(Y_{1:4} = y_{1:4})}.\\] Let us call the numerator \\[\\gamma(x) = \\mathbb{P}(X = x, Y_{1:4} = y_{1:4}),\\] and the denominator, \\[Z = \\mathbb{P}(Y_{1:4} = y_{1:4}).\\]\nStart by computing \\(\\gamma(x)\\) for all \\(x\\). (using chain rule)\nNote \\(Z = \\gamma(0) + \\gamma(1) + \\gamma(2)\\) (why?).",
    "crumbs": [
      "Probability essentials",
      "Bayes rule"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic06_forward_sampling.html",
    "href": "w01_discrete_inference/topic06_forward_sampling.html",
    "title": "Forward sampling",
    "section": "",
    "text": "Notion of forward sampling (also known as forward simulation)\nHow to do it in practice\n\nUseful functions\nGraphical models\n\n\n\n\n\n\nSampling is the main way Bayesian inference is performed nowadays.\nWe introduce here the simplest flavour of sampling, forward sampling.\nBayesian inference mostly uses a more complicated type of sampling called posterior sampling which we will cover later.\nBut forward sampling is still helpful to help debug Bayesian inference software as we will see soon.",
    "crumbs": [
      "Probability essentials",
      "Forward sampling"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic06_forward_sampling.html#outline",
    "href": "w01_discrete_inference/topic06_forward_sampling.html#outline",
    "title": "Forward sampling",
    "section": "",
    "text": "Notion of forward sampling (also known as forward simulation)\nHow to do it in practice\n\nUseful functions\nGraphical models\n\n\n\n\n\n\nSampling is the main way Bayesian inference is performed nowadays.\nWe introduce here the simplest flavour of sampling, forward sampling.\nBayesian inference mostly uses a more complicated type of sampling called posterior sampling which we will cover later.\nBut forward sampling is still helpful to help debug Bayesian inference software as we will see soon.",
    "crumbs": [
      "Probability essentials",
      "Forward sampling"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic06_forward_sampling.html#forward-sampling-as-depth-first-traversal",
    "href": "w01_discrete_inference/topic06_forward_sampling.html#forward-sampling-as-depth-first-traversal",
    "title": "Forward sampling",
    "section": "Forward sampling as depth-first traversal",
    "text": "Forward sampling as depth-first traversal\nRecall our recurring bag sampling example, with its corresponding decision tree:\n\n\n\n\n\n\nflowchart TD\nS__and__X_0 -- 1.0 --&gt; S__and__X_0__and__Y1_false[\"Y1=false\"]\nS__and__X_2__and__Y1_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS -- 0.33 --&gt; S__and__X_0[\"X=0\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS -- 0.33 --&gt; S__and__X_1[\"X=1\"]\nS__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_false[\"Y1=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS__and__X_0__and__Y1_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true[\"Y2=true\"]\nS__and__X_2 -- 1.0 --&gt; S__and__X_2__and__Y1_true[\"Y1=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_true[\"Y1=true\"]\nS -- 0.33 --&gt; S__and__X_2[\"X=2\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_2__and__Y1_true__and__Y2_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]\n\n\n\n\n\n\n\n\nForward simulation is a type of tree traversal. I.e. moving from node to node in the tree.\nForward simulation is a recursive process initialized at the root of the decision tree (labelled \\(S\\)).\n\nWhen we are a node \\(v\\) in the tree, we pick one of \\(v\\)’s children at random.\n\nMore precisely, we use methods discussed in the previous section on simulation from PMFs\n\nWe recurse until we reach a leaf.\n\nFrom this leaf we obtain an outcome and hence a realization for all random variables, both “observed” and “unobserved.”",
    "crumbs": [
      "Probability essentials",
      "Forward sampling"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic06_forward_sampling.html#forward-sampling-as-specifying-a-model",
    "href": "w01_discrete_inference/topic06_forward_sampling.html#forward-sampling-as-specifying-a-model",
    "title": "Forward sampling",
    "section": "Forward sampling as specifying a model",
    "text": "Forward sampling as specifying a model\nWe have encountered that notation earlier:\n\\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2).\n\\end{align*}\n\\]\n\nThis notation is a recipe providing all the information required to perform forward sampling.\n\nSpecifically, the PMF to use at each recursion step.\nIn continuous models, it will be the same idea except that we will have a probability density instead of a PMF.",
    "crumbs": [
      "Probability essentials",
      "Forward sampling"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic06_forward_sampling.html#example-1",
    "href": "w01_discrete_inference/topic06_forward_sampling.html#example-1",
    "title": "Forward sampling",
    "section": "Example 1",
    "text": "Example 1\nYou will practice forward sampling in Ex1, Q1.1.2",
    "crumbs": [
      "Probability essentials",
      "Forward sampling"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic06_forward_sampling.html#example-2",
    "href": "w01_discrete_inference/topic06_forward_sampling.html#example-2",
    "title": "Forward sampling",
    "section": "Example 2",
    "text": "Example 2\nConsider the following model:\n\\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{1, 2, 3, 4\\} \\\\\nY | X &\\sim {\\mathrm{Unif}}\\{1, \\dots, X\\}.\n\\end{align*}\n\\]\n\n\n\nInterpretation: you roll a D&D d4 dice (blue one on the image), then pick an integer uniformly between 1 and the number on the dice.\nExample of forward simulation code for the above “censored dice”:\n\nrequire(extraDistr)\n\nLoading required package: extraDistr\n\nset.seed(4)\n\nforward_simulate_roll_and_pick &lt;- function() {\n  x &lt;- rdunif(1, min=1, max=4) # 1 uniform between 1-6, i.e. a dice\n  y &lt;- rdunif(1, min=1, max=x)\n  c(x, y) # return a vector with these two realizations\n}\n\nforward_simulate_roll_and_pick()\n\n[1] 3 1\n\nforward_simulate_roll_and_pick()\n\n[1] 2 1\n\nforward_simulate_roll_and_pick()\n\n[1] 4 2",
    "crumbs": [
      "Probability essentials",
      "Forward sampling"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic03_random_variables.html",
    "href": "w01_discrete_inference/topic03_random_variables.html",
    "title": "Random variables",
    "section": "",
    "text": "Random variable as mathematical objects.\nNotation convention for observation/latent\n\n\n\n\nRandom variables are used as building blocks for two key uses in Bayesian stats: modelling “knowns” (observations) and “unknowns” (latent variables/parameters/prediction).",
    "crumbs": [
      "Probability essentials",
      "Random variables"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic03_random_variables.html#outline",
    "href": "w01_discrete_inference/topic03_random_variables.html#outline",
    "title": "Random variables",
    "section": "",
    "text": "Random variable as mathematical objects.\nNotation convention for observation/latent\n\n\n\n\nRandom variables are used as building blocks for two key uses in Bayesian stats: modelling “knowns” (observations) and “unknowns” (latent variables/parameters/prediction).",
    "crumbs": [
      "Probability essentials",
      "Random variables"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic03_random_variables.html#definition",
    "href": "w01_discrete_inference/topic03_random_variables.html#definition",
    "title": "Random variables",
    "section": "Definition",
    "text": "Definition\nA (real) random variable is a function from a sample space \\(S\\) to the reals, \\(X : S \\to \\mathbb{R}\\).\nExample:\n\nContinuing the example with \\(S = \\{1, 2, 3, 4\\}\\).\nConsider \\(X(s) = 1\\) if \\(s\\) is odd, and \\(X(s) = 0\\) otherwise.",
    "crumbs": [
      "Probability essentials",
      "Random variables"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic03_random_variables.html#probabilists-notation",
    "href": "w01_discrete_inference/topic03_random_variables.html#probabilists-notation",
    "title": "Random variables",
    "section": "Probabilist’s notation",
    "text": "Probabilist’s notation\n\nLet \\(X\\) denote a random variable.\nThe notation \\((X = 1)\\) or \\((X \\in E)\\) is invalid in set theory.\nTherefore, probabilists “gave it a meaning” as follows:\n\n\\[(X = 1) = \\{s : X(s) = 1\\}.\\]\nExample: Consider \\(X(s) = 1\\) if \\(s\\) is odd, and \\(X(s) = 0\\) otherwise. Then \\((X = 1)\\) corresponds to the red circle.",
    "crumbs": [
      "Probability essentials",
      "Random variables"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic03_random_variables.html#sec-conventions-probability-vs-bayesian",
    "href": "w01_discrete_inference/topic03_random_variables.html#sec-conventions-probability-vs-bayesian",
    "title": "Random variables",
    "section": "Conventions: probability vs Bayesian",
    "text": "Conventions: probability vs Bayesian\nProbability convention:\n\nRandom variables are denoted with capitals in probability theory\nThe same letter in small cap is used for a dummy variable holding the output of the random variable.\n\nNote: “A dummy variable holding the output of the random variable” is called a realization.\nExample: \\(X\\) for the random variable and \\(x\\) for its realization.\n\nWe will start off using this convention in the first few weeks.\n\nBayesian statistics convention:\n\nOften the capitalization convention is not used in the Bayesian statistics literature.\nHence we will eventually drop the probability theory capitalization convention.",
    "crumbs": [
      "Probability essentials",
      "Random variables"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic03_random_variables.html#more-conventions",
    "href": "w01_discrete_inference/topic03_random_variables.html#more-conventions",
    "title": "Random variables",
    "section": "More conventions",
    "text": "More conventions\n\n\\(X\\): unobserved random variable\n\\(Y\\): observed random variable\n\nMore precisely:\n\n\\(Y\\) is the “mechanism of observation”..\nwhereas the actual observation is a realization \\(y\\) of \\(Y\\).",
    "crumbs": [
      "Probability essentials",
      "Random variables"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic03_random_variables.html#extension",
    "href": "w01_discrete_inference/topic03_random_variables.html#extension",
    "title": "Random variables",
    "section": "Extension",
    "text": "Extension\nA random vector is a function from a sample space to \\(\\mathbb{R}^n\\).\nExample in Bayesian statistics: the vector \\((X, Y)\\) containing both the unobserved and observed quantities.",
    "crumbs": [
      "Probability essentials",
      "Random variables"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic01_outcomes.html",
    "href": "w01_discrete_inference/topic01_outcomes.html",
    "title": "Sample space, outcomes, events",
    "section": "",
    "text": "Review of basic probability theory concepts: outcome, event, sample space\nIntuition from the Bayesian perspective\n\n\n\n\n\nOne definition of Bayesian inference: applying probability theory to statistical inference problems\n\nTherefore, it is critical to understand probability to learn Bayesian inference\nThis week, we will help you “reload in memory” some of the most important bits of probability theory used in this course",
    "crumbs": [
      "Probability essentials",
      "Sample space, outcomes, events"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic01_outcomes.html#outline",
    "href": "w01_discrete_inference/topic01_outcomes.html#outline",
    "title": "Sample space, outcomes, events",
    "section": "",
    "text": "Review of basic probability theory concepts: outcome, event, sample space\nIntuition from the Bayesian perspective\n\n\n\n\n\nOne definition of Bayesian inference: applying probability theory to statistical inference problems\n\nTherefore, it is critical to understand probability to learn Bayesian inference\nThis week, we will help you “reload in memory” some of the most important bits of probability theory used in this course",
    "crumbs": [
      "Probability essentials",
      "Sample space, outcomes, events"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic01_outcomes.html#definitions",
    "href": "w01_discrete_inference/topic01_outcomes.html#definitions",
    "title": "Sample space, outcomes, events",
    "section": "Definitions",
    "text": "Definitions\n\nSample space, denoted \\(S\\), a set.\n\nExample: \\(S = \\{1, 2, 3, 4\\}\\) (see Figure).\n\nEach element \\(s\\) of \\(S\\) is called an outcome, \\(s \\in S\\).\n\nExample: each of the 4 points.\n\nA set of outcomes \\(E \\subset S\\) is called an event.\n\nExample: \\(E = \\{s \\in S : s \\text{ is odd}\\}\\) (red in the Figure).",
    "crumbs": [
      "Probability essentials",
      "Sample space, outcomes, events"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic01_outcomes.html#intuition-bayesian-view",
    "href": "w01_discrete_inference/topic01_outcomes.html#intuition-bayesian-view",
    "title": "Sample space, outcomes, events",
    "section": "Intuition: Bayesian view",
    "text": "Intuition: Bayesian view\n\nIn Bayesian statistics, an outcome will describe the state of the world.\nWe do not know which outcome is the true state of the world.\nWe observe partial information on the state of the world/outcome.\nWe rule out the outcomes that are not consistent with the observation…\n…but there will be several outcomes left!\n\nWe will deal with this situation using probability theory.",
    "crumbs": [
      "Probability essentials",
      "Sample space, outcomes, events"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic01_outcomes.html#intuition-randomized-algorithms",
    "href": "w01_discrete_inference/topic01_outcomes.html#intuition-randomized-algorithms",
    "title": "Sample space, outcomes, events",
    "section": "Intuition: randomized algorithms",
    "text": "Intuition: randomized algorithms\n\nAn algorithm is “randomized” if it has access to virtual dices/coins.\nIn practice this is done using pseudorandom number generators.\nIn this context an outcome is a random seed, i.e. the initialization of the pseudorandom number generator.",
    "crumbs": [
      "Probability essentials",
      "Sample space, outcomes, events"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic10_expectations.html",
    "href": "w01_discrete_inference/topic10_expectations.html",
    "title": "Expectations",
    "section": "",
    "text": "Expectation for discrete random models\nLaw of the Unconscious Statistician\n\n\n\n\nExpectation si the main tool to translate a posterior distribution into the various outputs of Bayesian inference (point estimate, credible intervals, prediction, action).",
    "crumbs": [
      "Probability essentials",
      "Expectations"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic10_expectations.html#outline",
    "href": "w01_discrete_inference/topic10_expectations.html#outline",
    "title": "Expectations",
    "section": "",
    "text": "Expectation for discrete random models\nLaw of the Unconscious Statistician\n\n\n\n\nExpectation si the main tool to translate a posterior distribution into the various outputs of Bayesian inference (point estimate, credible intervals, prediction, action).",
    "crumbs": [
      "Probability essentials",
      "Expectations"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic10_expectations.html#expectation-of-a-single-random-variable",
    "href": "w01_discrete_inference/topic10_expectations.html#expectation-of-a-single-random-variable",
    "title": "Expectations",
    "section": "Expectation of a single random variable",
    "text": "Expectation of a single random variable\nRecall: \\[\\mathbb{E}[X] = \\sum_x x p_X(x),\\] where the sum is over the point masses of \\(X\\), i.e. \\(\\{x : p_X(x) &gt; 0\\}\\).\nTest yourself: compute \\(\\mathbb{E}[X]\\) if \\(X \\sim {\\mathrm{Bern}}(p)\\), with \\(p = 0.8\\).\n\n\n\n\n\n\n\nflowchart TD\nS -- 0.2 --&gt; S__and__X_false[\"X=false\"]\nS -- 0.8 --&gt; S__and__X_true[\"X=true\"]",
    "crumbs": [
      "Probability essentials",
      "Expectations"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic10_expectations.html#law-of-the-unconscious-statistician",
    "href": "w01_discrete_inference/topic10_expectations.html#law-of-the-unconscious-statistician",
    "title": "Expectations",
    "section": "Law of the Unconscious Statistician",
    "text": "Law of the Unconscious Statistician\nProposition: if \\(g\\) is some function, \\[\\mathbb{E}[g(X)] = \\sum_x g(x) p_X(x).\\]\nTest yourself: compute \\(\\mathbb{E}[X^2]\\) if \\(X \\sim {\\mathrm{Bern}}(p)\\), and hence \\(\\operatorname{Var}[X] = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2\\).",
    "crumbs": [
      "Probability essentials",
      "Expectations"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic10_expectations.html#expectation-of-a-function-of-several-random-variables",
    "href": "w01_discrete_inference/topic10_expectations.html#expectation-of-a-function-of-several-random-variables",
    "title": "Expectations",
    "section": "Expectation of a function of several random variables",
    "text": "Expectation of a function of several random variables\nLet us go back to our running example:\n\nImagine a bag with 3 coins each with a different probability parameter \\(p\\)\nCoin \\(i\\in \\{0, 1, 2\\}\\) has bias \\(i/2\\)—in other words:\n\nFirst coin: bias is \\(0/2 = 0\\) (i.e. both sides are “heads”, \\(p = 0\\))\nSecond coin: bias is \\(1/2 = 0.5\\) (i.e. standard coin, \\(p = 1/2\\))\nThird coin: bias is \\(2/2 = 1\\) (i.e. both sides are “tails”, \\(p = 1\\))\n\n\n\n\n\n\nConsider the following two steps sampling process\n\nStep 1: pick one of the three coins, but do not look at it!\nStep 2: flip the coin 4 times\n\nMathematically, this probability model can be written as follows: \\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY_i | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\tag{1}\\]\n\nExample: computing \\(\\mathbb{E}[X (Y_1+1)]\\) (similar to what you will be doing in the exercise in question 1.1)\nNote: this is of the form \\(\\mathbb{E}[g(\\dots)]\\), so we can use the Law of the Unconscious Statistician.\nHow to do it:\n\nfirst, identify \\(g\\), here it is \\(g(x, y_1, \\dots, y_4) = x(y_1+1)\\) (in the exercise it is slightly different)\ndenote by \\(p\\) the joint PMF of all the random variables in the model\ncompute the expectation using \\[\\mathbb{E}[g(X, Y_1, \\dots, Y_4)] = \\sum_x \\sum_{y_1} \\sum_{y_2} \\dots \\sum_{y_4} g(x, y_1, \\dots, y_4)  p(x, y_1, y_2, y_3, y_4).\\]\nEach sum runs over the point mass of its PMF as before, e.g. \\(x \\in \\{0, 1, 2\\}\\).\nRecall: \\(p(x, y_1, y_2, y_3, y_4)\\) can be computed using the chain rule.\n\nRecall the decision tree, how to visualize the above equation?\n\n\n\n\n\n\nflowchart TD\nS__and__X_0 -- 1.0 --&gt; S__and__X_0__and__Y1_false[\"Y1=false\"]\nS__and__X_2__and__Y1_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS -- 0.33 --&gt; S__and__X_0[\"X=0\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS -- 0.33 --&gt; S__and__X_1[\"X=1\"]\nS__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false[\"Y3=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_false[\"Y1=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true[\"Y2=true\"]\nS__and__X_0__and__Y1_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false[\"Y2=false\"]\nS__and__X_1__and__Y1_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true[\"Y2=true\"]\nS__and__X_2 -- 1.0 --&gt; S__and__X_2__and__Y1_true[\"Y1=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1 -- 0.5 --&gt; S__and__X_1__and__Y1_true[\"Y1=true\"]\nS -- 0.33 --&gt; S__and__X_2[\"X=2\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_2__and__Y1_true__and__Y2_true -- 1.0 --&gt; S__and__X_2__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_true__and__Y3_false__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_true__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_true[\"Y3=true\"]\nS__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false -- 0.5 --&gt; S__and__X_1__and__Y1_true__and__Y2_false__and__Y3_false__and__Y4_false[\"Y4=false\"]\nS__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_true__and__Y3_true__and__Y4_true[\"Y4=true\"]\nS__and__X_1__and__Y1_false__and__Y2_false -- 0.5 --&gt; S__and__X_1__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]\nS__and__X_0__and__Y1_false__and__Y2_false -- 1.0 --&gt; S__and__X_0__and__Y1_false__and__Y2_false__and__Y3_false[\"Y3=false\"]",
    "crumbs": [
      "Probability essentials",
      "Expectations"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic11_monte_carlo.html",
    "href": "w01_discrete_inference/topic11_monte_carlo.html",
    "title": "Simple Monte Carlo",
    "section": "",
    "text": "Simple Monte Carlo method\nTheoretical guarantee from the Law of Large Numbers\n\n\n\n\nSimple Monte Carlo is the foundation for more complex Monte Carlo methods used by Bayesian practioners (e.g. Importance Sampling and Markov chain Monte Carlo (MCMC))",
    "crumbs": [
      "Probability essentials",
      "Simple Monte Carlo"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic11_monte_carlo.html#outline",
    "href": "w01_discrete_inference/topic11_monte_carlo.html#outline",
    "title": "Simple Monte Carlo",
    "section": "",
    "text": "Simple Monte Carlo method\nTheoretical guarantee from the Law of Large Numbers\n\n\n\n\nSimple Monte Carlo is the foundation for more complex Monte Carlo methods used by Bayesian practioners (e.g. Importance Sampling and Markov chain Monte Carlo (MCMC))",
    "crumbs": [
      "Probability essentials",
      "Simple Monte Carlo"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic11_monte_carlo.html#approximation-of-expectations-using-forward-simulation",
    "href": "w01_discrete_inference/topic11_monte_carlo.html#approximation-of-expectations-using-forward-simulation",
    "title": "Simple Monte Carlo",
    "section": "Approximation of expectations using forward simulation",
    "text": "Approximation of expectations using forward simulation\n\nAs before, we want to compute an expectation \\(\\mathbb{E}[g(X, Y)]\\)\nImagine a very large decision tree, but where most branches have very low probability and only few have large probability\nIn this case, instead of computing the exact expectation by iterating over each of the leaves as before, we will approximate expectations using forward simulation (a method know as simple Monte Carlo)\nThis is done as follows:\n\nCall your forward simulator \\(M\\) times.\n\nDenote the output at iteration \\(m \\in \\{1, 2, \\dots M\\}\\) by: \\[(X^{(m)}, Y^{(m)}) \\sim p_{X, Y}(\\cdot)\\]\nCompute \\(g\\) on each, call each of the \\(M\\) outputs \\(G^{(m)}\\) \\[G^{(m)}= g(X^{(m)}, Y^{(m)}).\\]\n\nReturn the average \\[\\hat G_M = \\frac{1}{M} \\sum_{m=1}^M G^{(m)}.\\]\n\n\nIntuitively, the output \\(\\hat G_M\\) has the nice property: \\[\\hat G_M \\approx \\mathbb{E}[g(X, Y)]. \\tag{1}\\]",
    "crumbs": [
      "Probability essentials",
      "Simple Monte Carlo"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic11_monte_carlo.html#example-1",
    "href": "w01_discrete_inference/topic11_monte_carlo.html#example-1",
    "title": "Simple Monte Carlo",
    "section": "Example 1",
    "text": "Example 1\nQuestion 1.2 in the exercise.",
    "crumbs": [
      "Probability essentials",
      "Simple Monte Carlo"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic11_monte_carlo.html#example-2",
    "href": "w01_discrete_inference/topic11_monte_carlo.html#example-2",
    "title": "Simple Monte Carlo",
    "section": "Example 2",
    "text": "Example 2\nConsider the following model:\n\\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{1, 2, 3, 4\\} \\\\\nY | X &\\sim {\\mathrm{Unif}}\\{1, \\dots, X\\}.\n\\end{align*}\n\\]\n\n\n\nInterpretation: you roll a D&D d4 dice (blue one on the image), then pick an integer uniformly between 1 and the number on the dice.\nLet us use Monte Carlo to estimate \\(\\mathbb{E}[X^Y]\\):\n\nrequire(extraDistr)\n\nLoading required package: extraDistr\n\nset.seed(4)\n\n# Recall our forward simulation code from earlier:\nforward_simulate_roll_and_pick &lt;- function() {\n  x &lt;- rdunif(1, min=1, max=4) # 1 uniform between 1-6, i.e. a dice\n  y &lt;- rdunif(1, min=1, max=x)\n  c(x, y) # return a vector with these two realizations\n}\n\nsum &lt;- 0.0\nn_iterations &lt;- 10000\nfor (iteration in 1:n_iterations) {\n  sample &lt;- forward_simulate_roll_and_pick()\n  sum &lt;- sum + sample[1]^sample[2]\n}\nprint(sum/n_iterations)\n\n[1] 25.7831",
    "crumbs": [
      "Probability essentials",
      "Simple Monte Carlo"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic11_monte_carlo.html#sec-lln",
    "href": "w01_discrete_inference/topic11_monte_carlo.html#sec-lln",
    "title": "Simple Monte Carlo",
    "section": "Guarantees from the Law of Large Numbers",
    "text": "Guarantees from the Law of Large Numbers\nQuestion: How can we make \\(\\approx\\) more formal in Equation 1?\nProposition (Law of Large Numbers, LLN): if \\(Z_1, Z_2, \\dots\\) are i.i.d. random variables with \\(\\mathbb{E}|Z_i| &lt; \\infty\\), then1 \\[ \\frac{1}{M} \\sum_{m=1}^M Z_m \\to \\mathbb{E}[Z_1].\\]\nPicking \\(Z_m = G^{(m)}\\) we arrive to the following formalization of \\(\\approx\\): for any approximation error tolerance, we can find a number of iterations \\(M\\) large enough such that we will be within that error tolerance with high probability after \\(M\\) iterations.",
    "crumbs": [
      "Probability essentials",
      "Simple Monte Carlo"
    ]
  },
  {
    "objectID": "w01_discrete_inference/topic11_monte_carlo.html#footnotes",
    "href": "w01_discrete_inference/topic11_monte_carlo.html#footnotes",
    "title": "Simple Monte Carlo",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere “\\(\\to\\)” denotes a suitable notion of convergence of random variables. In STAT 302 you may have seen LLN with “convergence in probability”, but this can be strengthen to “convergence almost sure.” The difference between these notions of convergence will not matter in this course.↩︎",
    "crumbs": [
      "Probability essentials",
      "Simple Monte Carlo"
    ]
  },
  {
    "objectID": "drafts/ex03.html",
    "href": "drafts/ex03.html",
    "title": "Exercise 3: Universal probabilistic inference via importance sampling",
    "section": "",
    "text": "Caution\n\n\n\nPage under construction: information on this page may change."
  },
  {
    "objectID": "drafts/ex03.html#goals",
    "href": "drafts/ex03.html#goals",
    "title": "Exercise 3: Universal probabilistic inference via importance sampling",
    "section": "Goals",
    "text": "Goals\n\nUnderstanding and implementing importance sampling\nIntroduction to probabilistic programming"
  },
  {
    "objectID": "challenges/ch03.html",
    "href": "challenges/ch03.html",
    "title": "Challenge questions",
    "section": "",
    "text": "Not for grades!\n\n\n\nThese are not essential for learning the material and can be skipped without affecting your grade. If you successfully solve one set of problem, a week of participation activity will be waived (it does not have to be the same week you submit the challenge question). Submit your answer at any time. I will not post solutions for the challenge questions.\n\n\nRecall the decision tree visualization we introduced in the first week.\nCreate a variant of simPPLe which draws decision trees automatically.\nSpecifically, your code should include a function decision_tree which takes as input a simPPLe probabilistic program, and output a mermaid string which can be rendered in your browser as a diagram.\nDemonstrate your code on two examples: one in class, and one not from the class.",
    "crumbs": [
      "A first look at PPLs",
      "Challenge"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic01_bayes_recipe.html",
    "href": "w02_discrete_bayes/topic01_bayes_recipe.html",
    "title": "The Bayesian recipe",
    "section": "",
    "text": "Introduce the Bayesian Recipe (synonym for the Bayes estimator)\nIllustrate it using this week’s running example\n\n\n\n\nThe Bayesian Recipe/Bayes estimator is the guide for all “full Bayesian” statistical analyses. This week we apply it to an example that builds on last week’s review.",
    "crumbs": [
      "Bayes on a discrete model",
      "The Bayesian recipe"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic01_bayes_recipe.html#outline",
    "href": "w02_discrete_bayes/topic01_bayes_recipe.html#outline",
    "title": "The Bayesian recipe",
    "section": "",
    "text": "Introduce the Bayesian Recipe (synonym for the Bayes estimator)\nIllustrate it using this week’s running example\n\n\n\n\nThe Bayesian Recipe/Bayes estimator is the guide for all “full Bayesian” statistical analyses. This week we apply it to an example that builds on last week’s review.",
    "crumbs": [
      "Bayes on a discrete model",
      "The Bayesian recipe"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic01_bayes_recipe.html#sec-running",
    "href": "w02_discrete_bayes/topic01_bayes_recipe.html#sec-running",
    "title": "The Bayesian recipe",
    "section": "This week’s running example",
    "text": "This week’s running example\n\nYou are consulting for a satellite operator\nThey are about to send a $100M satellite on a Delta 7925H rocket\n\n\n\n\n\nData: as of Jan 2024, Delta 7925H rockets have been launched 3 times, with 0 failed launches \n\nNote: Delta 7925H is not reusable, so each rocket is “copy- built” from the same blueprint\n\nShould you recommend buying a $2M insurance policy?\n\nConvention: use 1 for a success, 0 for a failure.",
    "crumbs": [
      "Bayes on a discrete model",
      "The Bayesian recipe"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic01_bayes_recipe.html#the-bayesian-recipe",
    "href": "w02_discrete_bayes/topic01_bayes_recipe.html#the-bayesian-recipe",
    "title": "The Bayesian recipe",
    "section": "The Bayesian recipe",
    "text": "The Bayesian recipe\nThe goal this week is to undersand the 3 steps in the Bayesian recipe:\n\nConstruct a probability model including\n\nrandom variables for what we will measure/observe\nrandom variables for the unknown quantities\n\nthose we are interested in (“parameters”, “predictions”)\nothers that just help us formulate the problem (“nuisance”, “random effects”).\n\n\nCompute the posterior distribution (condition on the data)\nUse the posterior distribution to (decision theory):\n\nmake prediction (point estimate)\nestimate uncertainty (credible intervals)\nmake a decision",
    "crumbs": [
      "Bayes on a discrete model",
      "The Bayesian recipe"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic01_bayes_recipe.html#plan",
    "href": "w02_discrete_bayes/topic01_bayes_recipe.html#plan",
    "title": "The Bayesian recipe",
    "section": "Plan",
    "text": "Plan\n\nUnderstanding Step 1 (“construct a probability model”):\n\nwe reviewed probability models last week,\nin fact, the model we use for this week’s problem is the same as last week’s!\nWe will just need to add some Bayesian terminology: prior, likelihood.\n\nUnderstanding Step 2 (“condition on the data”):\n\nwe reviewed conditional probability last week,\nin fact, the conditional probability calculation for this week’s problem is the same as last week’s!\nWe just need to add some Bayesian terminology: posterior distributions.\n\nUnderstanding Step 3: this is where most of the new material will be for this week.",
    "crumbs": [
      "Bayes on a discrete model",
      "The Bayesian recipe"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic07_prediction.html",
    "href": "w02_discrete_bayes/topic07_prediction.html",
    "title": "Prediction",
    "section": "",
    "text": "Prediction using decision trees\nExample\n\n\n\n\nOften we do not care so much about “parameters” but instead about predicting future observations.",
    "crumbs": [
      "Bayes on a discrete model",
      "Prediction"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic07_prediction.html#outline",
    "href": "w02_discrete_bayes/topic07_prediction.html#outline",
    "title": "Prediction",
    "section": "",
    "text": "Prediction using decision trees\nExample\n\n\n\n\nOften we do not care so much about “parameters” but instead about predicting future observations.",
    "crumbs": [
      "Bayes on a discrete model",
      "Prediction"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic07_prediction.html#example-coins-in-a-bag",
    "href": "w02_discrete_bayes/topic07_prediction.html#example-coins-in-a-bag",
    "title": "Prediction",
    "section": "Example: coins in a bag",
    "text": "Example: coins in a bag\nConsider the setup from last week with 3 coins and 3 flips with \\(Y = (1, 1, 1)\\) (in the following, let \\(\\boldsymbol{1}\\) denote a vector of 1’s).\nQuestion: given you have see 3 heads, what is the probability that the next one is also heads?\nMathematically: \\(\\mathbb{P}(Y_4 = 1 | Y_{1:3} = \\boldsymbol{1})\\). This is known as “prediction”.",
    "crumbs": [
      "Bayes on a discrete model",
      "Prediction"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic07_prediction.html#general-approach",
    "href": "w02_discrete_bayes/topic07_prediction.html#general-approach",
    "title": "Prediction",
    "section": "General approach",
    "text": "General approach\nKey message: In Bayesian statistics, prediction and parameter estimation are treated in the exact same way!\nIdea: Add \\(Y_4\\) to the unobserved random variables, i.e. set \\(\\tilde X = (X, Y_4)\\).\nThen, to compute \\(\\mathbb{P}(Y_4 = 1 | Y_{1:3} = \\boldsymbol{1})\\) use same techniques as last week (decision tree, chain rule, axioms of probability).",
    "crumbs": [
      "Bayes on a discrete model",
      "Prediction"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic07_prediction.html#example-continued",
    "href": "w02_discrete_bayes/topic07_prediction.html#example-continued",
    "title": "Prediction",
    "section": "Example, continued",
    "text": "Example, continued\nUse the following picture to help you computing \\(\\mathbb{P}(Y_4 = 1 | Y_{1:3} = \\boldsymbol{1})\\).\n\n\nPoll: compute the predictive\n\n\\(\\approx 0.11\\)\n\\(\\approx 0.35\\)\n\\(\\approx 0.52\\)\n\\(\\approx 0.94\\)\nNone of the above\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\n\nAdd a random variable for the quantity you want to predict (next flip \\(Y_4\\)).\nAdd one level in the decision tree.\nUse Bayes rule.\n\nTwist: distinct paths are compatible with observations and lead to the same prediction: \\((Y_{1:4} = \\boldsymbol{1}) = (X = 2, Y_{1:4} = \\boldsymbol{1}) \\cup (X = 1, Y_{1:4} = \\boldsymbol{1})\\).\nSum the probabilities of the paths leading to the same prediction (why can we do this?).\n\nLet \\(\\gamma(i) = \\mathbb{P}(Y_{1:3} = \\boldsymbol{1}, Y_4 = i)\\).\nTwo ways to get \\((Y_{1:4} = \\boldsymbol{1})\\), hence: \\(\\gamma(1) = 1/48 + 1/3\\)\nOnly one way to get \\((Y_{1:3} = \\boldsymbol{1}, Y_4 = 0)\\): \\(\\gamma(0) = 1/48\\)\n\nAs before, normalize \\(\\gamma\\) to get \\(\\pi\\): \\[\\Pr(Y_4 = 1|Y_{1:3} = \\boldsymbol{1}) = \\frac{\\gamma(1)}{\\gamma(0) + \\gamma(1)} = 17/18 \\approx 0.94\\]\n\n\nMathematical details of the above intuitive explanation:\nBy definition of conditioning: \\[\\pi(i) := \\mathbb{P}(Y_4 = i | Y_{1:3} = \\boldsymbol{1}) = \\frac{\\mathbb{P}(Y_{1:3} = \\boldsymbol{1}, Y_4 = i)}{\\mathbb{P}(Y_{1:3} = \\boldsymbol{1})} \\propto \\mathbb{P}(Y_{1:3} = \\boldsymbol{1}, Y_4 = i) =: \\gamma(i).\\] Since \\(\\{(X = 0, Y_{1:3} = \\boldsymbol{1}, Y_4 = i), (X = 1, Y_{1:3} = \\boldsymbol{1}, Y_4 = i), (X = 2, Y_{1:3} = \\boldsymbol{1}, Y_4 = i)\\}\\) is a partition of \\((Y_{1:3} = \\boldsymbol{1}, Y_4 = i)\\), from the additivity axiom of probability, reviewed last week, we have: \\[\\gamma(i) = \\mathbb{P}(Y_{1:3} = \\boldsymbol{1}, Y_4 = i) = \\sum_x \\mathbb{P}(X = x, Y_{1:3} = \\boldsymbol{1}, Y_4 = i). \\tag{1}\\] The above explains why we can “sum the paths leading to the same prediction.”\nNext, to compute each term in Equation 1, we use chain rule (“multiplying the edge probabilities to find a path probability”): \\[\\mathbb{P}(X = x, Y_{1:3} = \\boldsymbol{1}, Y_4 = i) = \\mathbb{P}(X = x) \\mathbb{P}(Y_1 = y_1 | X = x) \\mathbb{P}(Y_2 = y_2 | X = x, Y_1 = y_1) \\mathbb{P}(Y_3 = y_3 | X = x, Y_{1:2} = y_{1:2}) \\mathbb{P}(Y_4 = y_4 | X = x, Y_{1:3} = y_{1:3}).\\] Note that by conditional independence, these probabilities can be simplified, for example, \\[\\mathbb{P}(Y_2 = y_2 | X = x, Y_1 = y_1) = \\mathbb{P}(Y_2 = y_2 | X = x),\\] or in words: “once I know the kind of coin (\\(X\\)), knowing the first flips (\\(Y_1\\)) does not bring additional information on the second flip (\\(Y_2\\)).”\nDoing this for each \\(i\\) in Equation 1:\n\n\\(\\gamma(0) = 0 + 1/48 + 0\\)\n\\(\\gamma(1) = 0 + 1/48 + 1/3\\).\n\nFinally, we renormalize to get a posterior PMF \\(\\pi\\): \\[\\pi = \\frac{\\gamma}{Z},\\] i.e.: \\[(\\pi(0), \\pi(1)) = \\frac{(\\gamma(0), \\gamma(1))}{\\gamma(0) + \\gamma(1)}.\\]",
    "crumbs": [
      "Bayes on a discrete model",
      "Prediction"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic05_credible.html",
    "href": "w02_discrete_bayes/topic05_credible.html",
    "title": "Credible sets",
    "section": "",
    "text": "Nominal coverage.\nCommon credible sets:\n\nQuantiles.\nHighest-density sets.\n\n\n\n\n\nAs we have seen at the beginning one motivation for Bayesian methods is that they allow us to quantify uncertainty in our predictions. Credible sets is one way to convey this uncertainty quantification.",
    "crumbs": [
      "Bayes on a discrete model",
      "Credible sets"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic05_credible.html#outline",
    "href": "w02_discrete_bayes/topic05_credible.html#outline",
    "title": "Credible sets",
    "section": "",
    "text": "Nominal coverage.\nCommon credible sets:\n\nQuantiles.\nHighest-density sets.\n\n\n\n\n\nAs we have seen at the beginning one motivation for Bayesian methods is that they allow us to quantify uncertainty in our predictions. Credible sets is one way to convey this uncertainty quantification.",
    "crumbs": [
      "Bayes on a discrete model",
      "Credible sets"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic05_credible.html#nominal-coverage",
    "href": "w02_discrete_bayes/topic05_credible.html#nominal-coverage",
    "title": "Credible sets",
    "section": "Nominal coverage",
    "text": "Nominal coverage\nThe “nominal coverage” is the basic property that we use to construct credible sets:\n\nYou are given a level, typically \\(95\\%\\) or \\(90\\%\\), denoted \\(1-\\alpha = 0.95\\) or \\(1-\\alpha = 0.9\\)\n\nIntuition: we want to find a set \\(T\\) such that we are \\(95\\%\\) sure that the true \\(x\\) is in \\(T\\).\n\nIdeally, we would want to find a set \\(T\\) such that \\(\\sum_{x \\in T} p(x) = 0.9\\)\n\nFor discrete distributions, there may not be a solution, but let us ignore that issue for now (suppose each probability is very small and replace \\(=\\) by \\(\\approx\\) up to an error bounded by the largest individual probability)\nFor continuous distributions that will not be an issue\n\nAnother problem: there are many solutions! Some of them might appear weird, e.g. include points of probability zero!\n\nExample: both sets shown in red contain \\(75\\%\\) of the mass.",
    "crumbs": [
      "Bayes on a discrete model",
      "Credible sets"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic05_credible.html#quantile-based-credible-interval",
    "href": "w02_discrete_bayes/topic05_credible.html#quantile-based-credible-interval",
    "title": "Credible sets",
    "section": "Quantile-based credible interval",
    "text": "Quantile-based credible interval\nThe simplest way of building credible intervals:\n\nsuppose you want a \\(90\\%\\) credible set\nwe will remove \\(10\\%/2 = 5\\%\\) on each side\nremove sticks from the very left moving to right\n\neach time you remove one, add its length to a counter…\nuntil that counter hits \\(5\\%\\).\n\nthen do the same from very right moving to the left\nthe sticks left form \\(T\\).",
    "crumbs": [
      "Bayes on a discrete model",
      "Credible sets"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic05_credible.html#highest-density-set",
    "href": "w02_discrete_bayes/topic05_credible.html#highest-density-set",
    "title": "Credible sets",
    "section": "Highest Density Set",
    "text": "Highest Density Set\n\nHighest Density Set: pick a solution with the least number of points \\(|T|\\)\nTo handle discrete models: \\(\\text{argmin}\\{ |T| : \\sum_{x \\in T} p(x) \\ge 0.9\\}\\).\n\nStill not unique in some corner cases, but good enough\n\n\nExample:\n\nthe left one below is a highest density set\nnote the one on the right has more points in it, \\(5 &lt; 9\\).\n\n\nChallenge: implement a function taking as input a posterior PMF (as a vector), a level, and returns an HDI. Details here.",
    "crumbs": [
      "Bayes on a discrete model",
      "Credible sets"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic05_credible.html#credible-interval",
    "href": "w02_discrete_bayes/topic05_credible.html#credible-interval",
    "title": "Credible sets",
    "section": "Credible interval",
    "text": "Credible interval\nWhen we move to continuous random variables, \\(T\\) will often be an interval, i.e. \\(T = [L, R]\\) for some left and right end points \\(L\\) and \\(R\\). In such case, \\(T\\) is called a credible interval.",
    "crumbs": [
      "Bayes on a discrete model",
      "Credible sets"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic05_credible.html#high-density-interval",
    "href": "w02_discrete_bayes/topic05_credible.html#high-density-interval",
    "title": "Credible sets",
    "section": "High Density Interval",
    "text": "High Density Interval\nSimilarly, a High Density Interval (HDI) is a shortest interval (i.e. minimizing \\(R - L\\)) containing a prescribed probability mass.",
    "crumbs": [
      "Bayes on a discrete model",
      "Credible sets"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic02_models.html",
    "href": "w02_discrete_bayes/topic02_models.html",
    "title": "Bayesian models",
    "section": "",
    "text": "Bayesian interpretation of probability models: from aleatoric to epistemic.\nTerminology: prior, likelihood, joint.\n\n\n\n\nThis week, we will give a new interpretation to the “bag of coin” example (where the uncertainty is “aleatoric”), turning it into a Bayesian model (where the uncertainty is “epistemic”). Mathematically this is the same model but with a different interpretation. This shift of interpretation is the basis of all Bayesian models.",
    "crumbs": [
      "Bayes on a discrete model",
      "Bayesian models"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic02_models.html#outline",
    "href": "w02_discrete_bayes/topic02_models.html#outline",
    "title": "Bayesian models",
    "section": "",
    "text": "Bayesian interpretation of probability models: from aleatoric to epistemic.\nTerminology: prior, likelihood, joint.\n\n\n\n\nThis week, we will give a new interpretation to the “bag of coin” example (where the uncertainty is “aleatoric”), turning it into a Bayesian model (where the uncertainty is “epistemic”). Mathematically this is the same model but with a different interpretation. This shift of interpretation is the basis of all Bayesian models.",
    "crumbs": [
      "Bayes on a discrete model",
      "Bayesian models"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic02_models.html#what-is-a-bayesian-model",
    "href": "w02_discrete_bayes/topic02_models.html#what-is-a-bayesian-model",
    "title": "Bayesian models",
    "section": "What is a Bayesian model?",
    "text": "What is a Bayesian model?\nA Bayesian model is a probability model equipped with:\n\nrandom variable(s) representing the data (we use \\(Y\\) in this course)\nrandom variable(s) for the unknown quantities (we use \\(X\\) in this course).\n\nNote: concretely, a Bayesian model is a joint PMF over \\(X\\) and \\(Y\\), typically written using the “\\(\\sim\\)” notation introduced last week.",
    "crumbs": [
      "Bayes on a discrete model",
      "Bayesian models"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic02_models.html#from-a-coins-to-rockets",
    "href": "w02_discrete_bayes/topic02_models.html#from-a-coins-to-rockets",
    "title": "Bayesian models",
    "section": "From a coins to rockets",
    "text": "From a coins to rockets\nFor this week’s rocket example, we will use the exact same probability model as the bag of coin example from last week.\nUse the following correspondence to link last week’s example with this week’s:\n\n\\((Y_i = 1)\\):\n\n\\(\\leftrightarrow\\) “\\(i\\)-th flip is a heads”\n\\(\\leftrightarrow\\) “\\(i\\)-th launch is a success”\n\n\\((X = k)\\):\n\n\\(\\leftrightarrow\\) “the coin drawn from bag has probability \\(p = k/K\\) of heads”\n\\(\\leftrightarrow\\) “this type of rocket has probability \\(p = k/K\\) of success.”",
    "crumbs": [
      "Bayes on a discrete model",
      "Bayesian models"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic02_models.html#terminology",
    "href": "w02_discrete_bayes/topic02_models.html#terminology",
    "title": "Bayesian models",
    "section": "Terminology",
    "text": "Terminology\nThe task of constructing a Bayesian model is often broken down into constructing:\n\nthe prior: the PMF of the unknown \\(X\\),1\nthe likelihood: the conditional PMF of observed \\(Y\\) given \\(X\\).",
    "crumbs": [
      "Bayes on a discrete model",
      "Bayesian models"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic02_models.html#epistemic-vs-aleatoric-probability",
    "href": "w02_discrete_bayes/topic02_models.html#epistemic-vs-aleatoric-probability",
    "title": "Bayesian models",
    "section": "Epistemic vs aleatoric probability",
    "text": "Epistemic vs aleatoric probability\n\nIn the bag of coin example, we can replicate the whole “experiment” several times (both prior and likelihood).\nIn the rocket example, we can only replicate launches (likelihood), not the prior sampling part.\nEpistemic probability: the part we cannot replicate.\nAleatoric probability: the part that can be replicated.\nBayesian statistics uses both types of probability,\nwhereas other fields of statistics, e.g. MLE, typically uses only aleatoric.",
    "crumbs": [
      "Bayes on a discrete model",
      "Bayesian models"
    ]
  },
  {
    "objectID": "w02_discrete_bayes/topic02_models.html#footnotes",
    "href": "w02_discrete_bayes/topic02_models.html#footnotes",
    "title": "Bayesian models",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nif the unknown quantity is continuous, the prior will be expressed using a density. A term that captures both the continuous and discrete case is “distribution” i.e. “prior distribution”.↩︎",
    "crumbs": [
      "Bayes on a discrete model",
      "Bayesian models"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html",
    "href": "w03_ppl/topic02_snis.html",
    "title": "Importance sampling",
    "section": "",
    "text": "What Self-Normalizing Importance Sampling (SNIS) does.\nIntuition on how SNIS does it.\nSNIS pseudo-code.\n\n\n\n\nSince SNIS is the “inference algorithm” used by simPPLe, you will need a basic understanding of SNIS to complete this week’s exercise.",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#outline",
    "href": "w03_ppl/topic02_snis.html#outline",
    "title": "Importance sampling",
    "section": "",
    "text": "What Self-Normalizing Importance Sampling (SNIS) does.\nIntuition on how SNIS does it.\nSNIS pseudo-code.\n\n\n\n\nSince SNIS is the “inference algorithm” used by simPPLe, you will need a basic understanding of SNIS to complete this week’s exercise.",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#goal",
    "href": "w03_ppl/topic02_snis.html#goal",
    "title": "Importance sampling",
    "section": "Goal",
    "text": "Goal\n\nOur goal is to compute \\(\\mathbb{E}[g(X) | Y = y]\\).\nSNIS will allow us to approximate this conditional expectation.\nHow is this different than the Simple Monte Carlo method that we used in Ex1.Q.1.3?",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#problem-formulation",
    "href": "w03_ppl/topic02_snis.html#problem-formulation",
    "title": "Importance sampling",
    "section": "Problem formulation",
    "text": "Problem formulation\nSNIS is used to solve the following type of problems:\n\nInput: You are given an unnormalized distribution \\(\\gamma(x)\\)\n\nExample: the numerator in Bayes rule.\n\nOutput: You want to approximate an expectation…\n\n…under the renormalized distribution \\(\\pi(x) = \\gamma(x) / Z\\).\nMathematically: SNIS provides an approximation to \\(\\mathbb{E}_\\pi[g(X)] = \\sum \\pi(x) g(x)\\).\n\n\nTerminology: \\(g\\) is called a test function. Think about it as specifying a query.\nExamples: of test functions\n\nLet’s say you want to approximate \\(\\mathbb{P}(X = 1 | Y = y)\\).\n\nWe can do this with SNIS by picking the right \\(g\\)!\nFrom last week’s “trick 2”, if we take \\(g(x) = \\mathbb{1}[X = 1]\\), \\(\\pi(x) = p(x | y)\\), \\[\\mathbb{E}_\\pi[g(X)] = \\sum \\pi(x) g(x) = \\mathbb{E}[\\mathbb{1}[X = 1] | Y = y] = \\mathbb{P}(X = 1 | Y = y).\\]\n\nWhat function \\(g(x)\\) would you take to compute a posterior mean?\n\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(g(x) = \\mathbb{1}[X = x]\\)\n\\(g(x) = \\mathbb{1}[x]\\)\n\\(g(x) = x\\)\n\\(g(x) = x^2\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nIf we set \\(g(x) = x\\), then \\(\\sum x \\pi(x) = \\mathbb{E}[X | Y = y]\\).\n\n\n\n\nHow would you proceed to compute \\(\\operatorname{Var}[X | Y = y]\\)?",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#snis-extra-ingredient-the-proposal",
    "href": "w03_ppl/topic02_snis.html#snis-extra-ingredient-the-proposal",
    "title": "Importance sampling",
    "section": "SNIS’ extra ingredient: the proposal",
    "text": "SNIS’ extra ingredient: the proposal\nIn addition to the unnormalized distribution \\(\\gamma\\) and test function \\(f\\), SNIS requires a proposal \\(q(x)\\).\n\nThe proposal will help SNIS explore the space of possible values that \\(X\\) can take.\nThis week, we will use the prior as the proposal, \\(q(x) = \\rho(x)\\).\n\nIt can be generalized to any PMF \\(q(x)\\) such that \\(q(x) = 0 \\Longrightarrow \\pi(x) = 0\\).",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#intuition-decision-tree",
    "href": "w03_ppl/topic02_snis.html#intuition-decision-tree",
    "title": "Importance sampling",
    "section": "Intuition: decision tree",
    "text": "Intuition: decision tree\n\nRecall the forward_sample function from the first exercise, Q.1.3.\nSNIS follows the same general approach (Monte Carlo),\n\ntraverse the decision tree several times to get “samples”\nthe key difference is that these samples will not be equally weighted in SNIS in contrast to Q.1.3.\n\nAt each iteration, just as forward sampling, SNIS goes down the decision tree…\n\n…but for some decision points, the choice is made for us—by the data!\n\nCall these “forced choices.”\n\nWe keep track of the probability of the “forced choices”,\n\nthe product of these probability will be the un-normalized weight of the sample.",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#algorithm",
    "href": "w03_ppl/topic02_snis.html#algorithm",
    "title": "Importance sampling",
    "section": "Algorithm",
    "text": "Algorithm\n\nCall the proposal \\(M\\) times.\n\nDenote the output at iteration \\(m \\in \\{1, 2, \\dots M\\}\\) by: \\[(X^{(m)}) \\sim q(\\cdot)\\]\nCompute \\(g\\) on each, call each of the \\(M\\) outputs \\(G^{(m)}\\) \\[G^{(m)}= g(X^{(m)}).\\]\nCompute also an un-normalized weight for each of the \\(M\\) outputs: \\[W^{(m)}= w(X^{(m)}) = \\frac{\\gamma(X^{(m)})}{q(X^{(m)})}.\\] - Here \\(w(x)\\) is a weighing function.\n\nReturn the ratio \\[\\hat G_M = \\frac{\\sum_{m=1}^M W^{(m)}G^{(m)}}{\\sum_{m=1}^M W^{(m)}} .\\]\n\nExample: compute \\(\\hat G_M\\) in the bag of coin example if \\(g(x) = x\\), \\(X^{(1)} = 1\\), \\(X^{(2)} = 2\\). Use the decision tree above to help you.\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(0\\)\n\\(1.5\\)\n\\(\\approx 1.89\\)\n\\(\\approx 2.17\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nWe have:\n\n\n\n\\(m\\)\n\\(X^{(m)}\\)\n\\(W^{(m)}\\)\n\\(W^{(m)}G^{(m)}\\)\n\n\n\n\n1\n1\n\\((1/2)^3\\)\n\\((1/2)^3\\)\n\n\n2\n2\n1\n2\n\n\n\nHence:\n\\[\\hat G_M = \\frac{(1/2)^3 + 2}{(1/2)^3 + 1} \\approx 1.89.\\]",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#weight-simplification",
    "href": "w03_ppl/topic02_snis.html#weight-simplification",
    "title": "Importance sampling",
    "section": "Weight simplification",
    "text": "Weight simplification\n\nRecall from chain rule: \\(\\gamma(x) = p(x, y) = \\rho(x) L(y | x)\\) where \\(\\rho\\) is the prior and \\(L\\) the likelihood.\nHence, since the proposal is the prior \\(q(x) = p(x)\\), the weight calculation simplifies to \\[w(x) = \\frac{\\gamma(x)}{q(x)} = \\frac{\\rho(x) L(y | x)}{\\rho(x)} = L(y | x).\\]",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#theoretical-guarantees-of-snis",
    "href": "w03_ppl/topic02_snis.html#theoretical-guarantees-of-snis",
    "title": "Importance sampling",
    "section": "Theoretical guarantees of SNIS",
    "text": "Theoretical guarantees of SNIS\n\nWe have the same type of result as we encountered in Simple Monte Carlo\nNamely: for any approximation error tolerance, we can find a number of iterations \\(M\\) large enough such that we will be within that error tolerance with high probability after \\(M\\) iterations.\nName for the above property: consistency.\n\nProposition: if \\(\\mathbb{E}_\\pi|g(X)| &lt; \\infty\\), then1 \\[\\hat G_M \\to \\mathbb{E}_\\pi[g(X)],\\] as \\(M\\) goes to \\(\\infty\\).",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic02_snis.html#footnotes",
    "href": "w03_ppl/topic02_snis.html#footnotes",
    "title": "Importance sampling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere “\\(\\to\\)” can be taken to be “convergence in probability”, or this can be strengthen to “convergence almost sure.”↩︎",
    "crumbs": [
      "A first look at PPLs",
      "Importance sampling"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html",
    "href": "w03_ppl/topic05_mc_rates.html",
    "title": "Monte Carlo convergence rate",
    "section": "",
    "text": "Convergence rate of Monte Carlo methods.\nEmpirical scaling laws using physicist’s log-log plot trick.\nMathematical underpinnings.\n\n\n\n\nWhen using Monte Carlo methods, you need to specify the number of iterations (also known as number of samples).\nHow to set the number of iterations?\nWe cover here a heuristic, forming the foundation for more principled methods.",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html#outline",
    "href": "w03_ppl/topic05_mc_rates.html#outline",
    "title": "Monte Carlo convergence rate",
    "section": "",
    "text": "Convergence rate of Monte Carlo methods.\nEmpirical scaling laws using physicist’s log-log plot trick.\nMathematical underpinnings.\n\n\n\n\nWhen using Monte Carlo methods, you need to specify the number of iterations (also known as number of samples).\nHow to set the number of iterations?\nWe cover here a heuristic, forming the foundation for more principled methods.",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html#setup",
    "href": "w03_ppl/topic05_mc_rates.html#setup",
    "title": "Monte Carlo convergence rate",
    "section": "Setup",
    "text": "Setup\nImportant: we go back to simple Monte Carlo here, to make the argument simpler. However our findings will apply equally to SNIS (and later, to MCMC).",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html#motivating-example",
    "href": "w03_ppl/topic05_mc_rates.html#motivating-example",
    "title": "Monte Carlo convergence rate",
    "section": "Motivating example",
    "text": "Motivating example\nLet us revisit Q.1.3 in the first exercise. We will use it to explore tricks to set the number of Monte Carlo iterations.\nSetup: coin bag with a single flip (where we write \\(Y = Y_1\\))\n\n\n\n\\[\n\\begin{align*}\nX &\\sim {\\mathrm{Unif}}\\{0, 1, 2\\} \\\\\nY | X &\\sim {\\mathrm{Bern}}(X/2)\n\\end{align*}\n\\tag{1}\\]\nPlan: We will use our forward simulator and the law of large numbers to approximate \\(\\mathbb{E}[(1 + Y)^X]\\).\nRecall from the exercise 1 solutions (simplified a bit here):\n\ntruth = 1/3 * (1 + 1/2 + 1 + 4)\ntruth\n\n[1] 2.166667\n\nset.seed(1)\nsuppressMessages(require(extraDistr))\n\nforward_sample = function() {\n  x = rdunif(1, min=0, max=2)\n  y = rbern(1, x/2)\n  return(c(x, y))\n}\n\nsimple_monte_carlo = function(n_iterations) {\n  sum = 0.0\n  for (iteration in 1:n_iterations) {\n    sample = forward_sample()\n    sum = sum + (1+sample[2])^sample[1]\n  }\n  return(sum/n_iterations)\n}\n\nLet’s run the simulator with 10 iterations:\n\nsimple_monte_carlo(10)\n\n[1] 2.3\n\n\nIs this reliable? Let’s run it two more times:\n\nsimple_monte_carlo(10)\n\n[1] 2.7\n\nsimple_monte_carlo(10)\n\n[1] 2.1\n\n\n\nOK.. the first digit seems “stabilized” but not the second digit.\nSuppose I want one more digit of accuracy…\n\nBy how much should I increase the number of iteration to get one more digit of accuracy?\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n10 times more iterations\n100 times more iterations\n1000 times more iterations\nthere is no way to answer this questions\nNone of the above",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html#empirical-scaling",
    "href": "w03_ppl/topic05_mc_rates.html#empirical-scaling",
    "title": "Monte Carlo convergence rate",
    "section": "Empirical scaling",
    "text": "Empirical scaling\nContinuing on the same example (where we know the truth!), we will now:\n\nvary the number of iterations (\\(10^1, 10^{1.5}, 10^2, 10^{2.5}, 10^3\\)),\n\nfor each number of iteration n_iterations, we run simple_monte_carlo(n_iterations) 500 times,\nand plot the errors in log-log scale.\n\n\nFirst, a function to compute the approximation error of one call to simple_monte_carlo(n_iterations):\n\napproximate_error = function(n_iterations) {\n  mc = simple_monte_carlo(n_iterations)\n  error = abs(mc - truth)\n  return(error)\n}\n\nSecond, running approximate_error on the different numbers of iterations, each 500 times:\n\ndf &lt;- data.frame(\"n_iterations\" = rep(c(10, 32, 100, 316, 1000), each=500))\ndf$errors &lt;- sapply(df$n_iterations, approximate_error)\n\nFinally, plotting the errors in log-log scale (each of the \\(500 \\cdot 5\\) points is the error of one Monte Carlo run):\n\nrequire(ggplot2)\n\nLoading required package: ggplot2\n\nggplot(data=df, aes(x=n_iterations, y=errors)) +\n  stat_summary(fun = mean, geom=\"line\") + # Line averages over 1000 replicates\n  scale_x_log10() +  # Show result in log-log scale\n  scale_y_log10() +\n  theme_minimal() +\n  geom_point()\n\n\n\n\n\n\n\n\n\nGood news: error goes to zero\n\nRecall this property is known as consistency.\nThis confirms the theory covered on the previous page.\nBut here we are interested in the rate (how fast does it go to zero?)\n\nResult suggests a linear fit in the log-log scale \\(\\underbrace{\\log_{10}(\\text{error})}_{y} = a\\; \\underbrace{\\log_{10}(\\text{number of iterations})}_{x} + b\\)\nQuestions:\n\nEyeball the coefficient \\(a = \\Delta x / \\Delta y\\).\nWhat can you this coefficient tell you about the scaling of the error?\n\n\n\nBased on this extra information, let’s try revisit our initial question:",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html#mathematical-underpinnings",
    "href": "w03_ppl/topic05_mc_rates.html#mathematical-underpinnings",
    "title": "Monte Carlo convergence rate",
    "section": "Mathematical underpinnings",
    "text": "Mathematical underpinnings\nNotation: recall \\(\\hat G_M\\) is the estimator. Let us denote the truth by \\(g^* = \\mathbb{E}[g(X, Y)]\\).\nCore of the argument: use that for independent random variables \\(V_1, V_2\\), \\(\\operatorname{Var}[V_1 + V_2] = \\operatorname{Var}[V_1] + \\operatorname{Var}[V_2]\\)! This gives us:\n\\[\\operatorname{SD}(\\hat G_M) = \\sqrt{\\operatorname{Var}\\frac{1}{M} \\sum_{i=1}^M G^{(m)}} = \\sqrt{\\frac{M \\operatorname{Var}G^{(1)}}{M^2}} = \\frac{\\text{constant}}{\\sqrt{M}}\\]\nIn the following, I will explain why analyzing the standard deviation makes sense…\nSurrogate error measure: Mathematically analyzing the error as we define in our code, \\(\\mathbb{E}|\\hat G_M - g^*|\\), is tricky; it is easier to look instead at the Root Mean Squared Error (RMSE): \\[\\operatorname{RMSE}= \\sqrt{\\operatorname{MSE}} = \\sqrt{ \\mathbb{E}[ (\\hat G_M - g^*)^2 ]}.\\] Sanity check: Note that the units are OK, i.e. the error measured in RMSE and with the more intuitive \\(\\mathbb{E}|\\hat G_M - g^*|\\) has the same units, e.g. meters, or grams or whatever, as the estimator \\(\\hat G_M\\) and truth \\(g^*\\).\nIt’s enough to study the standard deviation:\n\nRecall that the MSE is the sum of variance and bias squared (see wikipedia for proof) \\[\\begin{align*}\n  \\operatorname{MSE}&= \\operatorname{Var}[\\hat G_M] + (\\operatorname{Bias}(\\hat G_M, g^*))^2 \\\\\n  \\operatorname{Bias}(\\hat G_M, g^*) &= (\\mathbb{E}[\\hat G_M] - g^*)^2.\n  \\end{align*}\\]\nFor simple Monte Carlo, the bias is zero by linearity of expectation:1 \\[\\mathbb{E}[\\hat G_M] = \\mathbb{E}\\left[\\frac{1}{M} \\sum_{m=1}^M G^{(m)}\\right] = \\frac{1}{M} \\sum_{m=1}^M \\mathbb{E}[G^{(m)}] = \\mathbb{E}[G^{(m)}] = g^*.\\]\n\n\nThe bias of zero gives a simpler expression for RMSE: \\[\\operatorname{RMSE}= \\sqrt{\\operatorname{Var}[\\hat G_M] + 0} = \\operatorname{SD}[\\hat G_M]\\]\nHence for simple Monte Carlo, analyzing the scaling of the standard deviation (SD) is the same as analyzing the RMSE.",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html#contextualizing-the-error-rate-of-monte-carlo",
    "href": "w03_ppl/topic05_mc_rates.html#contextualizing-the-error-rate-of-monte-carlo",
    "title": "Monte Carlo convergence rate",
    "section": "Contextualizing the error rate of Monte Carlo",
    "text": "Contextualizing the error rate of Monte Carlo\n\nNumerical methods such as the trapezoidal rule converge much faster in terms of \\(M\\): \\[\\text{error} = \\frac{\\text{constant}}{M^2},\\] i.e. 10 times more iterations gives two digits of extra accuracy (here \\(M\\) is the number of grid points used in a 1d numerical integral)!\nSo why do we use Monte Carlo?\n\nThe constants in the analysis of numerical integration blow up exponentially in the dimensionality of the problem!\nMany Monte Carlo methods can avoid this exponential blow up in the dimensionality2\nAnd good scalability in the dimensionality of the problem often more important than scalability in number of digits of accuracy\n\n…can’t trust 10th digit anyways because the model almost always has some slight mis-specification.",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic05_mc_rates.html#footnotes",
    "href": "w03_ppl/topic05_mc_rates.html#footnotes",
    "title": "Monte Carlo convergence rate",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor SNIS, the bias is not zero (because we have a ratio), but the squared bias decays faster than the variance term as \\(M \\to \\infty\\) so the argument is essentially the same as simple Monte Carlo.↩︎\nIn particular, Simple Monte Carlo and MCMC can often avoid the curse of dimensionality. But not SNIS! Why are we spending time on SNIS then? Because it can be used to approximate arbitrary posterior distribution, while simple Monte Carlo cannot, and it is much simpler than MCMC, so a good starting point pedagogically. However we will jump to MCMC later in this course.↩︎",
    "crumbs": [
      "A first look at PPLs",
      "Monte Carlo convergence rate"
    ]
  },
  {
    "objectID": "w03_ppl/topic04_consistency.html",
    "href": "w03_ppl/topic04_consistency.html",
    "title": "SNIS consistency",
    "section": "",
    "text": "Recap of SNIS’ consistency guarantee.\nProof of consistency.\n\n\n\n\nWe go over this proof as it demystifies the form of SNIS’ weights.",
    "crumbs": [
      "A first look at PPLs",
      "SNIS consistency"
    ]
  },
  {
    "objectID": "w03_ppl/topic04_consistency.html#outline",
    "href": "w03_ppl/topic04_consistency.html#outline",
    "title": "SNIS consistency",
    "section": "",
    "text": "Recap of SNIS’ consistency guarantee.\nProof of consistency.\n\n\n\n\nWe go over this proof as it demystifies the form of SNIS’ weights.",
    "crumbs": [
      "A first look at PPLs",
      "SNIS consistency"
    ]
  },
  {
    "objectID": "w03_ppl/topic04_consistency.html#notation-and-setup",
    "href": "w03_ppl/topic04_consistency.html#notation-and-setup",
    "title": "SNIS consistency",
    "section": "Notation and setup",
    "text": "Notation and setup\nSee page on SNIS.",
    "crumbs": [
      "A first look at PPLs",
      "SNIS consistency"
    ]
  },
  {
    "objectID": "w03_ppl/topic04_consistency.html#consistency",
    "href": "w03_ppl/topic04_consistency.html#consistency",
    "title": "SNIS consistency",
    "section": "Consistency",
    "text": "Consistency\nProposition: if \\(\\mathbb{E}_\\pi|g(X)| &lt; \\infty\\), then1 \\[\\hat G_M \\to \\mathbb{E}_\\pi[g(X)],\\] as \\(M\\) goes to \\(\\infty\\).\nProof: first, divide both numerator and denominator by \\({\\color{red} M}\\): \\[\\begin{align*}\n\\hat G_M &= \\frac{\\sum_{m=1}^M W^{(m)}G^{(m)}}{\\sum_{m=1}^M W^{(m)}} \\\\\n&= \\frac{{\\color{red} \\frac{1}{M}} \\sum_{m=1}^M W^{(m)}G^{(m)}}{{\\color{red} \\frac{1}{M}} \\sum_{m=1}^M W^{(m)}}.\n\\end{align*}\\]\nWe will analyze the numerator and denominator separately. Let’s start with the numerator.\nQuestion: use the Law of large number to find the limit: \\[\\frac{1}{M} \\sum_{m=1}^M W^{(m)}G^{(m)}\\to\\; ?\\]\n\n\n\n\n\n\nClick for choices\n\n\n\n\n\n\n\\(\\mathbb{E}_q[W^{(1)} G^{(1)}]\\)\n\\(\\mathbb{E}_\\pi[W^{(1)} G^{(1)}]\\)\n\\(\\mathbb{E}_q[G^{(1)}]\\)\n\\(\\mathbb{E}_\\pi[G^{(1)}]\\)\nNone of the above\n\n\n\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nRecall the LLN: for \\(Z_i\\) with \\(\\mathbb{E}|Z_1| &lt; \\infty\\), \\[ \\frac{1}{M} \\sum_{m=1}^M Z_m \\to \\mathbb{E}[Z_1].\\]\nHere taking \\(Z_m = W^{(m)}G^{(m)}\\) gives: \\[\\frac{1}{M} \\sum_{m=1}^M W^{(m)}G^{(m)}\\to \\mathbb{E}_q[W^{(1)} G^{(1)}],\\] where the subscript \\(q\\) denotes that the random variables \\(X^{(m)}\\sim q\\) in SNIS.\n\n\n\nNow we can simplify the above limit:\n\\[\\begin{align*}\n\\mathbb{E}_q[W^{(1)} G^{(1)}] &= \\int ( w(x) g(x) ) q(x) \\mathrm{d}x \\;\\;\\text{(by LOTUS)} \\\\\n&= \\int \\left( \\frac{\\gamma(x)}{{\\color{red} q(x)}} g(x) \\right) {\\color{red} q(x)} \\mathrm{d}x \\;\\;\\text{(definition of $w$)} \\\\\n&= \\int \\gamma(x) g(x)  \\mathrm{d}x.\n\\end{align*}\\]\nNow the denominator is just a special case where \\(g(x) = 1\\), hence by the same argument we just did: \\[\\frac{1}{M} \\sum_{m=1}^M W^{(m)}\\to \\int \\gamma(x) \\mathrm{d}x = Z.\\]\nNow to combine the convergence of numerator and denominator in one, we use this proposition from probability theory:\nProposition: if \\(S_i \\to S\\) and \\(T_i \\to T\\) then \\(S_i / T_i \\to S / T\\).2\nNow applying that proposition, we get: \\[\\begin{align*}\n\\hat G_M &= \\frac{\\frac{1}{M} \\sum_{m=1}^M W^{(m)}G^{(m)}}{\\frac{1}{M} \\sum_{m=1}^M W^{(m)}} \\\\\n&\\to \\frac{\\int \\gamma(x) g(x)  \\mathrm{d}x}{Z} \\\\\n&= \\int \\frac{\\gamma(x)}{Z} g(x) \\mathrm{d}x = \\mathbb{E}_\\pi[g(X)].\n\\end{align*}\\]",
    "crumbs": [
      "A first look at PPLs",
      "SNIS consistency"
    ]
  },
  {
    "objectID": "w03_ppl/topic04_consistency.html#footnotes",
    "href": "w03_ppl/topic04_consistency.html#footnotes",
    "title": "SNIS consistency",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAs usual, “\\(\\to\\)” will be taken to be “convergence in probability”, or this can be strengthen to “convergence almost sure.”↩︎\nThis is true in probability and almost sure. In the case of almost sure the proof is trivial but outside of the scope of this course.↩︎",
    "crumbs": [
      "A first look at PPLs",
      "SNIS consistency"
    ]
  },
  {
    "objectID": "exercises/ex03.html",
    "href": "exercises/ex03.html",
    "title": "Exercise 3: inference on continuous spaces",
    "section": "",
    "text": "Introduce Monte Carlo integration in continuous spaces.\nImplement importance sampling.\nBuild a universal probabilistic programming language in &lt;30 lines of code.",
    "crumbs": [
      "A first look at PPLs",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex03.html#goals",
    "href": "exercises/ex03.html#goals",
    "title": "Exercise 3: inference on continuous spaces",
    "section": "",
    "text": "Introduce Monte Carlo integration in continuous spaces.\nImplement importance sampling.\nBuild a universal probabilistic programming language in &lt;30 lines of code.",
    "crumbs": [
      "A first look at PPLs",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex03.html#q.1-functions-on-the-unit-interval",
    "href": "exercises/ex03.html#q.1-functions-on-the-unit-interval",
    "title": "Exercise 3: inference on continuous spaces",
    "section": "Q.1: functions on the unit interval",
    "text": "Q.1: functions on the unit interval\nFor this question, use Simple Monte Carlo. The main twist compared to week one is that you will use a continuous random variable.\n\nWrite a function mc_estimate that takes a function \\(f:[0,1]\\to\\mathbb{R}\\) and outputs a Monte Carlo estimate of \\(\\int_0^1 f(x)\\mathrm{d}x\\) using \\(n=10000\\) independent samples from \\({\\mathrm{Unif}}(0,1)\\).\nConsider the function \\(f:[0,1]\\to[0,\\infty)\\) given by \\[\nf(x) = \\frac{1}{\\sqrt[3]{x^2(1-x)}}.\n\\] It is possible to show that \\[\n\\int_0^1 f(x)\\mathrm{d}x = \\frac{\\pi}{\\sin\\left(\\frac{\\pi}{3}\\right)}.\n\\tag{1}\\] Test your implementation of mc_estimate by checking that it produces an answer close to the value in Equation 1.\nThe following integral, known as the sine integral, \\[\n\\int_0^1 \\frac{\\sin(t)}{t} \\mathrm{d}t.\n\\] does not admit a closed-form expression. Estimate its value using mc_estimate(f).",
    "crumbs": [
      "A first look at PPLs",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex03.html#sec-simPPLe",
    "href": "exercises/ex03.html#sec-simPPLe",
    "title": "Exercise 3: inference on continuous spaces",
    "section": "Q.2: implementing SNIS for simPPLe",
    "text": "Q.2: implementing SNIS for simPPLe\nIn this question, you will write the function posterior that we used in the PPL introduction.\n\nFirst, install the package distr, which allows us to work with distributions as objects—a necessary ingredient of every PPL. Load or install it using\n\n\nif (!require(distr)){\n  install.packages(\"distr\")\n  require(distr)\n}\n\n\nRead this short tutorial on distr. Nothing to submit for this item.\nRead the “scaffold code”, and use distr and two of the functions below to create a fair coin, flip it, and to compute the probability of that flip:\n\n\n\nex03_scaffold.R\n\nsuppressPackageStartupMessages(library(distr))\n\n## Utilities to make the distr library a bit nicer to use\n\np &lt;- function(distribution, realization) {\n  d(distribution)(realization) # return the PMF or density \n}\n\nBern = function(probability_to_get_one) {\n  DiscreteDistribution(supp = 0:1, prob = c(1-probability_to_get_one, probability_to_get_one))\n}\n\n## Key functions called by simPPLe programs\n\n# Use simulate(distribution) for unobserved random variables\nsimulate &lt;- function(distribution) {\n  r(distribution)(1) # sample once from the given distribution\n}\n\n# Use observe(realization, distribution) for observed random variables\nobserve = function(realization, distribution) {\n  # `&lt;&lt;-` lets us modify variables that live in the global scope from inside a function\n  weight &lt;&lt;- weight * p(distribution, realization) \n}\n\n\nComplete the implementation of the function posterior:\n\nposterior = function(ppl_function, number_of_iterations) {\n  numerator = 0.0\n  denominator = 0.0\n  for (i in 1:number_of_iterations) {\n    weight &lt;&lt;- 1.0\n    # update numerator and denominator\n  }\n  return(numerator/denominator)\n}\n\nTest your program by checking that you can approximate the posterior probability of the fair coin obtained in exercise 1, Q.2.",
    "crumbs": [
      "A first look at PPLs",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex04.html",
    "href": "exercises/ex04.html",
    "title": "Exercise 4: the joy of probabilistic inference",
    "section": "",
    "text": "Make sure to read the simPPLe setup page before you begin.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex04.html#q.1-logistic-rocket-improvement",
    "href": "exercises/ex04.html#q.1-logistic-rocket-improvement",
    "title": "Exercise 4: the joy of probabilistic inference",
    "section": "Q.1: logistic rocket improvement",
    "text": "Q.1: logistic rocket improvement\nConsider the Ariane 1 data we used this week,\nsuccess_indicators = c(1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1)\nand the model described in the same page.\nRecall that we discussed a model where the reliability of the rocket changes in time. This will allow us to incorporate, for example, the fact that engineering teams implement fixes based on past launches and therefore the probability of success should increase.\n\nWrite a function called logistic_regression containing a simPPLe probabilistic programming description of the model described in class. Your function should return a vector containing 3 elements in the following order:\n\nthe intercept (\\(\\in \\mathbb{R}\\)),\nthe slope (\\(\\in \\mathbb{R}\\)),\na prediction if one more launch would have been successful (1) or a failure (0) (\\(\\in \\{0, 1\\}\\)).\n\nFollow the instructions in the appendix below to get some helper functions. Use these functions to reproduce the lecture’s bivariate posterior plot over the intercept and slope parameters.\nEstimate the probability that the next launch is a success given the data under the logistic model.\nCreate a variant of the same model but where the slope is set to zero. Estimate the probability that the next launch is a success given the data under this simplified model.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex04.html#q.2-choosing-a-model",
    "href": "exercises/ex04.html#q.2-choosing-a-model",
    "title": "Exercise 4: the joy of probabilistic inference",
    "section": "Q.2: choosing a model",
    "text": "Q.2: choosing a model\nYou debate with your friend whether the logistic model or the simplified model (with slope equals to zero) should be preferred. To stop that debate, write a unified model which gives probability 1/2 to the simplified model, and 1/2 to the logistic model. Estimate the posterior probability that the logistic model is preferred under the unified model given the same data as in Q.1.",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Exercises"
    ]
  },
  {
    "objectID": "exercises/ex04.html#sec-utils",
    "href": "exercises/ex04.html#sec-utils",
    "title": "Exercise 4: the joy of probabilistic inference",
    "section": "Appendix",
    "text": "Appendix\nFor Q.1.2, you will need to copy the following code and paste it in a file called simple_utils.R. We have demonstrated the use of these functions in the lectures.\n\n\nsimple_utils.R\n\n\nposterior_particles = function(ppl_function, number_of_iterations) {\n  weight &lt;&lt;- 1.0\n  dimension = length(ppl_function()) \n  samples = matrix(0, nrow = number_of_iterations, ncol = dimension)\n  weights = rep(0, number_of_iterations)\n  for (i in 1:number_of_iterations) {\n    weight &lt;&lt;- 1.0       # reset the weight accumulator\n    sample = ppl_function()\n    samples[i,] = sample\n    weights[i]  = weight\n  }\n  return(list(samples=samples, weights=weights))\n}\n\ness = function(particles){\n  w = particles$weights\n  return(effective_sample_size(w))\n}\n\neffective_sample_size = function(w){\n  (sum(w)^2)/sum(w^2)\n}\n\nrepresentative_sample = function(snis_output, percentile=0.9999){\n  ess = effective_sample_size(snis_output$weights)\n  idx_ordered_weights = order(snis_output$weights, decreasing = TRUE)\n  acc_norm_weights = cumsum(snis_output$weights[idx_ordered_weights])/sum(snis_output$weights)\n  reduced_sample_size = max(round(ess), max(which(acc_norm_weights &lt; percentile)))\n  idx_subset = idx_ordered_weights[1:reduced_sample_size]\n  list(samples = snis_output$samples[idx_subset,], weights = snis_output$weights[idx_subset])\n}\nweighted_scatter_plot = function(\n    snis_output, \n    base_color_hex = hcl.colors(1, palette = \"viridis\"),\n    plot_options = list(xlab=\"Param 1\", ylab=\"Param 2\")\n){\n  base_color = col2rgb(base_color_hex)/255\n  \n  # find the subset with almost all the mass\n  snis_subset = representative_sample(snis_output)\n  \n  # linear transform of weights to [0,1]\n  extreme_weights = range(snis_subset$weights, na.rm = T)\n  alphas = (snis_subset$weights-extreme_weights[1])/diff(extreme_weights)\n  \n  # create colors with transparencies and plot\n  points_color_alphas = rgb(base_color[1],base_color[2],base_color[3], alphas)\n  call_args=c(\n    list(x=snis_subset$samples[,1:2], col=points_color_alphas), \n    plot_options\n  )\n  do.call(plot, call_args)\n}",
    "crumbs": [
      "The joy of probabilistic modelling",
      "Exercises"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "",
    "text": "Bayesian inference is a flexible and powerful approach to modeling reality, making optimal predictions from data, and quantifying uncertainty in a coherent manner. Thanks to their versatility, Bayesian methods are now widely used in virtually all fields of science, engineering, and beyond.\nIn STAT 447C, you will:\n\ndesign probabilistic models to approach real-world inferential problems;\nperform inference using Bayesian modelling languages;\ncritically assess, debug, and iteratively improve Bayesian workflows;\ndevelop and analyze custom posterior approximation machinery.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "",
    "text": "Bayesian inference is a flexible and powerful approach to modeling reality, making optimal predictions from data, and quantifying uncertainty in a coherent manner. Thanks to their versatility, Bayesian methods are now widely used in virtually all fields of science, engineering, and beyond.\nIn STAT 447C, you will:\n\ndesign probabilistic models to approach real-world inferential problems;\nperform inference using Bayesian modelling languages;\ncritically assess, debug, and iteratively improve Bayesian workflows;\ndevelop and analyze custom posterior approximation machinery.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#lecture-time-and-place",
    "href": "syllabus.html#lecture-time-and-place",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Lecture time and place",
    "text": "Lecture time and place\nLecture dates: January 9, 2024 to April 11, 2024. Detailed schedule\nTuesday and Thursday, 9:30-11:00. FNH Building, Room 40.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#teaching-team",
    "href": "syllabus.html#teaching-team",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Teaching team",
    "text": "Teaching team\n\nAlexandre Bouchard-Côté (Instructor)\nMiguel Biron-Lattes (TA)\nAli Mehrabian (TA)",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#prerequisite",
    "href": "syllabus.html#prerequisite",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Prerequisite",
    "text": "Prerequisite\n\nProbability: STAT 302, MATH 302 or equivalent. I will do a review of the relevant concepts, but Bayesian statistics is entirely built on top of probability theory so prior exposure to probability is the key prerequisite for this course.\nBasic background in linear algebra (e.g. matrix multiplication, eigenvectors) and calculus (see STAT 302’s prerequisites for example)\nComputing: we will use R in the homework and during lectures. If you know another programming language but not R, you can still take this course but be prepared to spend a bit of extra time to get familiar with the R syntax. We will have special office hours sessions at the beginning of the term to help you doing that.\n\nCome talk to me at the end of the first lecture if you are unsure about your preparation for this course.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Software",
    "text": "Software\nAll software used is free and open source. Some key tools we will use:\n\nR\nRStudio\nRStan\n\nWe assume you have a laptop on which you can install these tools, if not, you may be able to borrow one from UBC library.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#textbook",
    "href": "syllabus.html#textbook",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Textbook",
    "text": "Textbook\nNotes will be provided and complemented with readings from the following freely available textbook:\n\nBayesian Data Analysis, Third Rdition. Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin. PDF freely available.\n\nAdditional readings and case studies will be drawn from other textbooks that are either freely available or available within UBC VPN:\n\nBayesian essentials with R, Second Edition. Jean-Michel Marin and Christian Robert. PDF available via UBC library. Solution to exercises.\nBayes Rules! Alicia A. Johnson, Miles Q. Ott, Mine Dogucu. HTML freely available\nDoing Bayesian data analysis: a tutorial with R, JAGS, and Stan, Second Edition. John K. Kruschke. PDF freely available.\nProbability and Bayesian modeling. Jim Albert and Jingchen Hu. PDF/HTML/EPUB freely available.\nStatistical Rethinking, Second Edition. Richard McElreath. HTML available via UBC library.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#assessments",
    "href": "syllabus.html#assessments",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Assessments",
    "text": "Assessments\nClick on each item for details.\n\nParticipation: 15%\n\nWeekly reading assignment: each week ask and answer one question about the readings or lectures on Piazza.\nIn-class iClicker questions: only participations points (unless your score is indistinguishable from random). Setup iClicker Cloud on Canvas.\n\nHomework: 15%\n\nWeekly.\nReleased and submitted on Canvas.\n\nQuizzes (2 x 20%): 40%\n\nIn-class.\nDates: Tuesday February 27, Tuesday March 26.\n\nFinal project: 30%\n\nFor the reading assignment and homework, we will drop the lowest week. For the iClicker, we will automatically skip up to two missed lectures. Keep these for sick days/unforeseen circumstances. No need to ask for permission/provide doctor’s note, this will be done automatically for everyone.\nAdded on Jan 10: For exercise grading, I will take the \\(\\max(\\text{mean}(e_1, e_2, ...), \\text{mean}(e_2, e_3, ...))\\), where \\(e_1, e_2, e_3, \\dots\\) are the scores for the different exercises. The same applies for clicker participation points. (This was put in place to help a couple students travelling in the first week, but will be automatically applied for everyone so no need to request it).\nAdded on Jan 15: Once in a while, I will post some “challenge questions”. These are not essential for learning the material and can be skipped. Submit your answer at any time. For each that you successfully solve, a week of participation activity will be waived (it does not have to be the same week you submit the challenge question). I will not post solutions for the challenge questions.\nAdded on Jan 21: Since a few more people arrived in the second week, I will extend the Jan 10 waiver above to cover the first two week, i.e. using \\(\\max(\\text{mean}(e_1, e_2, ...), \\text{mean}(e_2, e_3, ...), \\text{mean}(e_3, ...))\\), so you can still get full marks if you do not do exercises and/or participation/clicker in weeks 1 or 2.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#office-hours",
    "href": "syllabus.html#office-hours",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Office hours",
    "text": "Office hours\n\nInstructor office hour: Thursdays, 3:30-4:30, ESB 3125\nTA office hour: Fridays, 11:00-12:00, ESB 3125\n\nAvailable by appointment if you are unable to attend drop-in hours.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-communication",
    "href": "syllabus.html#course-communication",
    "title": "Syllabus: STAT447C Bayesian Statistics",
    "section": "Course communication",
    "text": "Course communication\n\nAnnouncements\nCourse announcements will be posted on Canvas.\n\n\nQuestions\nUse Piazza for questions about the material, logistics, etc. Use public posts as much as possible so that other students can learn from the discussion.\nUse private piazza questions if, and only if the question is about a personal matter.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "w00_intro/topic03_high_level.html",
    "href": "w00_intro/topic03_high_level.html",
    "title": "High-level picture",
    "section": "",
    "text": "Construct a probability model including\n\nrandom variables for what we will measure/observe\nrandom variables for the unknown quantities\n\nthose we are interested in (“parameters”, “predictions”)\nothers that just help us formulate the problem (“nuisance”, “random effects”).\n\n\nCompute the posterior distribution (condition on the data)\nUse the posterior distribution to (decision theory):\n\nmake prediction (point estimate)\nestimate uncertainty (credible intervals)\nmake a decision",
    "crumbs": [
      "Introduction",
      "High-level picture"
    ]
  },
  {
    "objectID": "w00_intro/topic03_high_level.html#bayesian-recipe-high-level-picture",
    "href": "w00_intro/topic03_high_level.html#bayesian-recipe-high-level-picture",
    "title": "High-level picture",
    "section": "",
    "text": "Construct a probability model including\n\nrandom variables for what we will measure/observe\nrandom variables for the unknown quantities\n\nthose we are interested in (“parameters”, “predictions”)\nothers that just help us formulate the problem (“nuisance”, “random effects”).\n\n\nCompute the posterior distribution (condition on the data)\nUse the posterior distribution to (decision theory):\n\nmake prediction (point estimate)\nestimate uncertainty (credible intervals)\nmake a decision",
    "crumbs": [
      "Introduction",
      "High-level picture"
    ]
  },
  {
    "objectID": "w00_intro/topic03_high_level.html#plan",
    "href": "w00_intro/topic03_high_level.html#plan",
    "title": "High-level picture",
    "section": "Plan",
    "text": "Plan\n\nFirst week: probability essentials (foundations for steps 1 and 2 of the Bayesian Recipe)\nSecond week: steps 1, 2, 3 for one specific discrete probability models\nThird week and beyond: step 1, 2, 3 for arbitrary models",
    "crumbs": [
      "Introduction",
      "High-level picture"
    ]
  },
  {
    "objectID": "w00_intro/topic03_high_level.html#first-step-of-the-recipe-constructing-a-probability-model",
    "href": "w00_intro/topic03_high_level.html#first-step-of-the-recipe-constructing-a-probability-model",
    "title": "High-level picture",
    "section": "First step of the Recipe: “constructing a probability model”",
    "text": "First step of the Recipe: “constructing a probability model”\n\nWhat is a model?\nWhat is a probability model?\nExample (week 2): building a probability model for the rocket launch problem.",
    "crumbs": [
      "Introduction",
      "High-level picture"
    ]
  },
  {
    "objectID": "w00_intro/topic03_high_level.html#what-is-a-model",
    "href": "w00_intro/topic03_high_level.html#what-is-a-model",
    "title": "High-level picture",
    "section": "What is a model?",
    "text": "What is a model?\n(Scientific) model: A simplification of reality amenable to mathematical investigation.\n\\[\\text{Reality} \\xrightarrow{\\text{Art + Scientific method}} \\text{Model} \\xrightarrow{\\text{Mathematics}} \\text{Prediction}\\]\n\nIn this course “mathematics” will be Bayesian analysis/probability theory.\nBayesian analysis/probability theory assume a model as starting point.\n\nTo create a first model is a bit of an art. It comes with data analysis experience.\nThen after we start with an initial model we can improve it by checking predictions against reality.",
    "crumbs": [
      "Introduction",
      "High-level picture"
    ]
  },
  {
    "objectID": "w00_intro/topic02_what.html",
    "href": "w00_intro/topic02_what.html",
    "title": "What?",
    "section": "",
    "text": "MAP estimators (maximum a posteriori)\nposterior means\nBayes rule\nmodels where some unknown quantities are treated as random\nnone of the above\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nAll these popular answers are misleading and/or very incomplete:\n\nMAP estimators (maximum a posteriori)\n\nMAP is seldom used by expert Bayesians (mode is misleading in high dimensions)\n\nposterior means\n\nthe posterior mean is often undefined (e.g. Bayesian analysis over combinatorial objects such as graphs)\n\nBayes rule\n\nBayes rule is intractable in most practical situations (we use MCMC/variational methods)\n\nmodels where some unknown quantities are treated as random\n\ntrue for Bayesian models, but also for many non-Bayesian models, e.g., random effect models\n\n\nSo… what is Bayesian Analysis?\n\n\nBayesian Analysis: statistical discipline centered around the use of Bayes estimators\nBayes estimators: for data \\(Y\\), unobserved \\(X\\), loss \\(L\\), and possible actions \\(A\\), the Bayes estimator is defined as:\n\\[\\operatorname{arg\\,min}\\{ \\mathbb{E}[L(a, X) | Y] : a \\in A \\}\\]\nNote: you are not expected to understand this equation at this point!\n\n\n\nThe primary objective of this course is to understand Bayes estimators:\n\nWhy they are so powerful.\nTheir limitations (model misspecification, computational challenges).\nImportant special cases (posterior means, credible intervals, MAP).\nHow to do it in practice\n\nhow to build models\nhow to approximate conditional expectations.",
    "crumbs": [
      "Introduction",
      "What?"
    ]
  },
  {
    "objectID": "w00_intro/topic02_what.html#poll-what-characterizes-bayesian-analysis",
    "href": "w00_intro/topic02_what.html#poll-what-characterizes-bayesian-analysis",
    "title": "What?",
    "section": "",
    "text": "MAP estimators (maximum a posteriori)\nposterior means\nBayes rule\nmodels where some unknown quantities are treated as random\nnone of the above\n\n\n\n\n\n\n\nClick for answer\n\n\n\n\n\nAll these popular answers are misleading and/or very incomplete:\n\nMAP estimators (maximum a posteriori)\n\nMAP is seldom used by expert Bayesians (mode is misleading in high dimensions)\n\nposterior means\n\nthe posterior mean is often undefined (e.g. Bayesian analysis over combinatorial objects such as graphs)\n\nBayes rule\n\nBayes rule is intractable in most practical situations (we use MCMC/variational methods)\n\nmodels where some unknown quantities are treated as random\n\ntrue for Bayesian models, but also for many non-Bayesian models, e.g., random effect models\n\n\nSo… what is Bayesian Analysis?\n\n\nBayesian Analysis: statistical discipline centered around the use of Bayes estimators\nBayes estimators: for data \\(Y\\), unobserved \\(X\\), loss \\(L\\), and possible actions \\(A\\), the Bayes estimator is defined as:\n\\[\\operatorname{arg\\,min}\\{ \\mathbb{E}[L(a, X) | Y] : a \\in A \\}\\]\nNote: you are not expected to understand this equation at this point!\n\n\n\nThe primary objective of this course is to understand Bayes estimators:\n\nWhy they are so powerful.\nTheir limitations (model misspecification, computational challenges).\nImportant special cases (posterior means, credible intervals, MAP).\nHow to do it in practice\n\nhow to build models\nhow to approximate conditional expectations.",
    "crumbs": [
      "Introduction",
      "What?"
    ]
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Final project",
    "section": "",
    "text": "Caution\n\n\n\nPage under construction: information on this page may change.",
    "crumbs": [
      "Final project"
    ]
  },
  {
    "objectID": "project.html#overview",
    "href": "project.html#overview",
    "title": "Final project",
    "section": "Overview",
    "text": "Overview\nThe course project involves independent work on a topic selected from a menu of project themes. These projects leave freedom for creativity within constraints designed for pedagogical and fair evaluation.",
    "crumbs": [
      "Final project"
    ]
  },
  {
    "objectID": "project.html#logistics",
    "href": "project.html#logistics",
    "title": "Final project",
    "section": "Logistics",
    "text": "Logistics\n\nTeams of maximum 2 people are encouraged, in which case you should outline the final report who did what. Expectation will grow linearly in the group size.\nSubmit on canvas, a pdf document of maximum 5 pages/person (i.e. max length is 10 for groups of 2 people), excluding references and appendices. The appendix can have arbitrary length but may not be read in detail during grading.",
    "crumbs": [
      "Final project"
    ]
  },
  {
    "objectID": "project.html#project-timeline",
    "href": "project.html#project-timeline",
    "title": "Final project",
    "section": "Project timeline",
    "text": "Project timeline\n\nFriday, Mar 8: prepare proposal, freeze teams, each team sends a 1 page abstract submitted on Canvas.\nFriday, April 19: due date for the reports.",
    "crumbs": [
      "Final project"
    ]
  },
  {
    "objectID": "project.html#core-guideline",
    "href": "project.html#core-guideline",
    "title": "Final project",
    "section": "Core guideline",
    "text": "Core guideline\nEvery project should contain a component where Bayesian inference is applied to a real problem and a real dataset.\nIn addition, each team should pick one of the “project themes” listed below, exploring topics building and going beyond what we will cover during the course. If two project proposals are too similar, I reserve the right to assign changes to one of the projects (typically the one with the last proposal submission date).\nAfter selection of a project theme, you should start hunting for a few real-world candidate datasets appropriate for the selected theme. Two potential datasets should be listed in the proposal. The final report should analyze at least one real dataset.\nSome resources:\n\nVanderbilt Biostatistics datasets\nTidyTuesday\nInter-university Consortium for Political and Social Research\nWHO mortality data\nThe World Bank Data\nMore…\n\nYou should not pick a dataset that has already been analyzed using the same approach as you. Provide references for the closest analyses of the same data and explain how they differ from yours.",
    "crumbs": [
      "Final project"
    ]
  },
  {
    "objectID": "project.html#menu-of-project-themes",
    "href": "project.html#menu-of-project-themes",
    "title": "Final project",
    "section": "Menu of project themes",
    "text": "Menu of project themes\nRoughly in increasing order of complexity. During grading I will take into account the complexity of the selected project theme. For example, if considerable coding is required in the project, it may be possible to use only synthetic data instead of real data (consult me and document this request in the proposal).\n\nGoing further on… (more details can be provided upon request)\n\nBayesian regression and classification (e.g. sparsity, hierarchical structure, etc)\nmodel selection (advanced computational approaches to Bayes factors, alternatives to Bayes factors, comparisons)\ntime series and state-space models\nspatial models\ncross-effect models\nBayesian non-parametric models\ndeep generative models\ntopics models\nvariational inference\n\nA careful and scientific comparison of a Bayesian estimator with another one, either Bayesian or non-Bayesian. Review the literature on both sides so as to be fair and critical to both sides of the comparison. State and defend the criteria you use. Consider calibration and M-open setups. Examples:\n\nBayesian vs frequentist… regression/classification, feature selection, density estimation, survival analysis, …\nIs there some structure that can be exploited (e.g. informed by the data types for the covariates/features, groups of related features i.e. feature templates, hierarchical approaches, etc), to get better Bayesian methods on these generic classes of inference problems?\n\nA Bayesian inference method over a non-standard data type. Acquire or write an efficient posterior inference method, either using a PPL or from scratch. Develop a novel Bayes estimator and implement it. Benchmark the Bayes estimator on synthetic data, comparing the performance with a naive baseline such as MAP. Examples:\n\nTypes of graphs such as matchings\nPhylogenetic trees or networks\nMultiple sequence alignments\nClustering or feature matrices\n\nCreate a twist on an existing MCMC sampling algorithm, or a novel one. Show it is invariant with respect to the distribution of interest. Benchmark the performance of the method against one baseline using best practices.",
    "crumbs": [
      "Final project"
    ]
  },
  {
    "objectID": "project.html#rubric-for-the-project-proposal",
    "href": "project.html#rubric-for-the-project-proposal",
    "title": "Final project",
    "section": "Rubric for the project proposal",
    "text": "Rubric for the project proposal\n\nBasic requirements\n\nTeam is identified.\nThe proposal identifies which of the project themes it will address.\n\nTwo real-world candidate datasets appropriate for the selected theme are clearly described (e.g. a URL, showing the structure or head of a dataframe).\nA short summary of potential approaches to tackle the project theme.\nIf it is a team project, the proposal contains a short plan for ensuring the two team members will contribute roughly equally.\n\nAs long as the team submits a reasonable project proposal, I will give full grade (5/5) (along with some feedback). Late submission within 2 days will receive 4/5, and 0/5 after the grace period, but I can still provide feedback past the grace period but no later than April 1st. Details of the project can change after submission of the proposals. Larger changes are allowed but with my permission, so they should not be discussed at the last minute, i.e. before April 1st ideally and certainly before the last lecture.\nTotal: 5%",
    "crumbs": [
      "Final project"
    ]
  },
  {
    "objectID": "project.html#rubric-for-the-final-report",
    "href": "project.html#rubric-for-the-final-report",
    "title": "Final project",
    "section": "Rubric for the final report",
    "text": "Rubric for the final report\n\nBasic requirements (5%)\n\nThe report fits within the prescribed page limits.\nThe report follows best practices of technical writing.\nIf it is a team project, a short paragraph clearly explains and quantifies the contributions of each team member.\n\nProblem formulation. (15%) The report clearly describes:\n\na real-world inference task/problem,\nsuccinct but sufficient context (e.g. biological terminology) needed to understand the problem,\nthe key modelling/methodological/challenge, clearly associating it with one of the items under “menu of project themes” above.\n\nThe report contains a literature review: (10%) relevant literature is cited and properly summarized.\nData analysis (40%)\n\nA Bayesian model is precisely described (e.g. using the .. ~ .. notation)\nImplementation code in the appendix (e.g. using Stan)\nPrior choice is motivated. If appropriate, several choices are compared or sensitivity analysis is performed.\nCritical evaluation of the posterior approximation. An appropriate combination of diagnostics, synthetic datasets and other validation strategies.\n\nProject theme: methodological/theoretical aspect of the project (20%)\n\nIs the approach sound?\nCreative?\n\nDiscussion (5%)\n\nDoes the report describe key limitations?\n\n\nTotal: 95%",
    "crumbs": [
      "Final project"
    ]
  }
]